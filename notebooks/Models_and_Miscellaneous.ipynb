{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('../src')\n",
    "from src import utils\n",
    "from src import generators\n",
    "import imp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df\n"
     ]
    }
   ],
   "source": [
    "if torch.tensor(np.zeros((0,3,3,3))).shape[0] == 0:\n",
    "    print(\"df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Mode - CNN_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=None):\n",
    "        \n",
    "        super(MVCNN,self).__init__()\n",
    "        pad = 1\n",
    "        \n",
    "        self.cnn = nn.Sequential(nn.BatchNorm2d(1),\n",
    "                                     nn.Conv2d(1,32,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.BatchNorm2d(32),\n",
    "                                     nn.Conv2d(32,32,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2,2), \n",
    "        \n",
    "                                     nn.BatchNorm2d(32),\n",
    "                                     nn.Conv2d(32,64,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.BatchNorm2d(64),\n",
    "                                     nn.Conv2d(64,64,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2,2),\n",
    "                                     \n",
    "                                     nn.BatchNorm2d(64),\n",
    "                                     nn.Conv2d(64,128,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.BatchNorm2d(128),\n",
    "                                     nn.Conv2d(128,128,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2,2),\n",
    "        \n",
    "                                     nn.BatchNorm2d(128),\n",
    "                                     nn.Conv2d(128,256,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.BatchNorm2d(256),\n",
    "                                     nn.Conv2d(256,256,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2,2), \n",
    "        \n",
    "                                     nn.BatchNorm2d(256),\n",
    "                                     nn.Conv2d(256,256,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.BatchNorm2d(256),\n",
    "                                     nn.Conv2d(256,256,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2,2),\n",
    "                                     \n",
    "                                     nn.BatchNorm2d(256),\n",
    "                                     nn.Conv2d(256,512,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.BatchNorm2d(512),\n",
    "                                     nn.Conv2d(512,512,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2,2))\n",
    "  \n",
    "        self.fc1 = nn.Sequential(nn.Linear(8192, 1024), \n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Dropout(0.8),\n",
    "                                     nn.Linear(1024, 96),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Dropout(0.9),\n",
    "                                     nn.Linear(96, 1))\n",
    "\n",
    "        self.fc2 = nn.Sequential(nn.Linear(8192, 4096), \n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Dropout(0.8),\n",
    "                                     nn.Linear(4096, 4096),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Dropout(0.9),\n",
    "                                     nn.Linear(4096, num_classes))\n",
    "        \n",
    "    def forward(self, x, batch_size, mvcnn=True):\n",
    "        \n",
    "        if mvcnn:\n",
    "            view_pool = []\n",
    "            # Assuming x has shape (x, 1, 299, 299)\n",
    "            for n, v in enumerate(x):\n",
    "                v = v.unsqueeze(0)\n",
    "                v = self.cnn(v)\n",
    "                v = v.view(v.size(0), 512 * 4* 4)\n",
    "\n",
    "            pooled_view = view_pool[0]\n",
    "            for i in range(1, len(view_pool)):\n",
    "                pooled_view = torch.max(pooled_view, view_pool[i])\n",
    "\n",
    "            output = self.fc(pooled_view)\n",
    "        \n",
    "        else:\n",
    "\n",
    "            x = self.cnn(x)\n",
    "            x = x.view(-1, 512 * 4* 4)\n",
    "            output = self.fc2(x)\n",
    "    \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since patients have varying images, create single images where the channels occupy the slices of the patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new() received an invalid combination of arguments - got (NoneType, int), but expected one of:\n * (torch.device device)\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mNoneType\u001b[0m, \u001b[31;1mint\u001b[0m)\n * (object data, torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mNoneType\u001b[0m, \u001b[31;1mint\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-92239081e971>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmvcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMVCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-52dbad35b7d3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_classes)\u001b[0m\n\u001b[1;32m     68\u001b[0m                                      \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                                      \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                                      nn.Linear(4096, num_classes))\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmvcnn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv36/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: new() received an invalid combination of arguments - got (NoneType, int), but expected one of:\n * (torch.device device)\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mNoneType\u001b[0m, \u001b[31;1mint\u001b[0m)\n * (object data, torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mNoneType\u001b[0m, \u001b[31;1mint\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "mvcnn = MVCNN().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(mvcnn.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/alex/Dataset 1/Dataset - 1.xlsx'\n",
    "df = pd.read_excel(file_path, sheet_name='Feuil1')\n",
    "\n",
    "edss = df['EDSS'].tolist()\n",
    "p_id = df['Sequence_id'].tolist()\n",
    "channels = 1\n",
    "resize = 299\n",
    "normalization = 'min-max'\n",
    "\n",
    "patient_information = [(p_id[i], edss[i]) for i in range(df.shape[0])]\n",
    "train_patient_information = patient_information[:int(0.9*len(patient_information))]\n",
    "valid_patient_information = patient_information[int(0.9*len(patient_information)):]\n",
    "base_DatabasePath = '/home/alex/Dataset 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_inst = generators.SEPGenerator(base_DatabasePath, \n",
    "                                                channels=channels,\n",
    "                                                resize=resize,\n",
    "                                                normalization=normalization)\n",
    "\n",
    "train_generator = generator_inst.generator(train_patient_information)\n",
    "valid_generator = generator_inst.generator(valid_patient_information)\n",
    "\n",
    "#dataloader = torch.utils.data.DataLoader(train_generator, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On_Going_Epoch : 1 \t | Iteration : 50 \t | Training Loss : 4511.05859375\n",
      "On_Going_Epoch : 1 \t | Iteration : 100 \t | Training Loss : 2339.1357421875\n",
      "tensor(7.8825, device='cuda:0')\n",
      "tensor(7.8826, device='cuda:0')\n",
      "tensor(8.5348, device='cuda:0')\n",
      "tensor(10.2445, device='cuda:0')\n",
      "tensor(18.1271, device='cuda:0')\n",
      "tensor(18.1641, device='cuda:0')\n",
      "tensor(19.9259, device='cuda:0')\n",
      "tensor(20.5781, device='cuda:0')\n",
      "tensor(20.6151, device='cuda:0')\n",
      "tensor(28.4977, device='cuda:0')\n",
      "tensor(203.7557, device='cuda:0')\n",
      "tensor(211.6382, device='cuda:0')\n",
      "tensor(970.9899, device='cuda:0')\n",
      "tensor(985.4875, device='cuda:0')\n",
      "tensor(999.9852, device='cuda:0')\n",
      "tensor(1000.0223, device='cuda:0')\n",
      "tensor(1000.0593, device='cuda:0')\n",
      "tensor(1820.6040, device='cuda:0')\n",
      "tensor(1831.5441, device='cuda:0')\n",
      "tensor(1842.4841, device='cuda:0')\n",
      "tensor(1853.4242, device='cuda:0')\n",
      "tensor(1864.3643, device='cuda:0')\n",
      "tensor(1864.4012, device='cuda:0')\n",
      "tensor(1864.4382, device='cuda:0')\n",
      "tensor(1872.3208, device='cuda:0')\n",
      "tensor(1926.3999, device='cuda:0')\n",
      "tensor(1960.1279, device='cuda:0')\n",
      "tensor(1993.8560, device='cuda:0')\n",
      "tensor(2176.1489, device='cuda:0')\n",
      "tensor(2197.5427, device='cuda:0')\n",
      "tensor(2212.0405, device='cuda:0')\n",
      "tensor(2226.5383, device='cuda:0')\n",
      "tensor(2241.0361, device='cuda:0')\n",
      "tensor(2241.0732, device='cuda:0')\n",
      "tensor(2244.3406, device='cuda:0')\n",
      "tensor(2278.0686, device='cuda:0')\n",
      "tensor(2311.7966, device='cuda:0')\n",
      "tensor(2345.5247, device='cuda:0')\n",
      "tensor(2345.5618, device='cuda:0')\n",
      "tensor(2497.3787, device='cuda:0')\n",
      "tensor(2498.9541, device='cuda:0')\n",
      "tensor(2502.2214, device='cuda:0')\n",
      "tensor(2542.0071, device='cuda:0')\n",
      "tensor(2581.7927, device='cuda:0')\n",
      "tensor(2905.2920, device='cuda:0')\n",
      "tensor(6808.9893, device='cuda:0')\n",
      "tensor(6835.3154, device='cuda:0')\n",
      "tensor(6837.0254, device='cuda:0')\n",
      "Epoch : 1 \t | Training Loss : 2339.1357421875 \t | Validation Loss : 142.4380340576172 \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exception' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/JFRDataChallenge/src/generators.py\u001b[0m in \u001b[0;36m__extract_DCMImage\u001b[0;34m(self, dcm_path)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydicom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdcmread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdcm_path\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# Read dcm file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpixel_array\u001b[0m                                 \u001b[0;31m# Exctact image from dcm files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv36/lib/python3.6/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mdcmread\u001b[0;34m(fp, defer_size, stop_before_pixels, force, specific_tags)\u001b[0m\n\u001b[1;32m    879\u001b[0m         dataset = read_partial(fp, stop_when, defer_size=defer_size,\n\u001b[0;32m--> 880\u001b[0;31m                                force=force, specific_tags=specific_tags)\n\u001b[0m\u001b[1;32m    881\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv36/lib/python3.6/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mread_partial\u001b[0;34m(fileobj, stop_when, defer_size, force, specific_tags)\u001b[0m\n\u001b[1;32m    757\u001b[0m                                \u001b[0mstop_when\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_when\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefer_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m                                specific_tags=specific_tags)\n\u001b[0m\u001b[1;32m    759\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv36/lib/python3.6/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mread_dataset\u001b[0;34m(fp, is_implicit_VR, is_little_endian, bytelength, stop_when, defer_size, parent_encoding, specific_tags)\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mraw_data_elements\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_data_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-6f8289f3e3b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtotal_TrainLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mt_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mimage_3D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/JFRDataChallenge/src/generators.py\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(self, patient_InfoDatabase, max_slices, dark_matter, shuffle)\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mdcm_image\u001b[0m               \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__extract_DCMImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_dcm_FilePath\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;31m# extract image from .dcm file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0mpreproc_image\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreproc_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdcm_image\u001b[0m\u001b[0;34m)\u001b[0m                                                 \u001b[0;31m# preprocess image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mtransform_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreproc_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformation\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# transform the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/JFRDataChallenge/src/generators.py\u001b[0m in \u001b[0;36m__extract_DCMImage\u001b[0;34m(self, dcm_path)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mexcept\u001b[0m \u001b[0mexception\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exception' is not defined"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "train_iterations = 100\n",
    "valid_iterations = len(valid_patient_information)\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_TrainLoss = 0\n",
    "\n",
    "    for t_m, t_item in enumerate(train_generator):\n",
    "\n",
    "        image_3D, label = torch.tensor(t_item[0], device=device).float(), torch.tensor(t_item[1], device=device).float()\n",
    "        output = mvcnn(image_3D, 1)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_TrainLoss += loss\n",
    "\n",
    "        if not (t_m+1)%50:\n",
    "            print(\"On_Going_Epoch : {} \\t | Iteration : {} \\t | Training Loss : {}\".format(epoch+1, t_m+1, total_TrainLoss/(t_m+1)))\n",
    "\n",
    "        if (t_m+1) == train_iterations:\n",
    "            total_ValidLoss = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for v_m, v_item in enumerate(valid_generator):\n",
    "                    image_3D, label = torch.tensor(v_item[0], device=device).float(), torch.tensor(v_item[1], device=device).float()\n",
    "                    output = mvcnn(image_3D, 1)\n",
    "                    total_ValidLoss += criterion(output, label)\n",
    "                    print(total_ValidLoss)\n",
    "                    if (v_m + 1) == valid_iterations:\n",
    "                        break\n",
    "                    \n",
    "            print(\"Epoch : {} \\t | Training Loss : {} \\t | Validation Loss : {} \".format(epoch+1, total_TrainLoss/(t_m+1), total_ValidLoss/(v_m+1)) )                   \n",
    "\n",
    "            torch.save(mvcnn, './' + 'vgg_' + str(epoch) + '.pkl')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_ValidLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./vgg_9'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "c = torch.randn(90, 512, 4, 4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n"
     ]
    }
   ],
   "source": [
    "#torch.randn(90, 1, 299, 299)\n",
    "for n,v in enumerate(c):\n",
    "    \n",
    "    v = v.view(1, 512*4*4).to(device)\n",
    "    print(n)\n",
    "    if n:\n",
    "        pooled_view = torch.max(pooled_view, v).to(device)\n",
    "    else:\n",
    "        pooled_view = v.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(image, transformation='original', angle=30):\n",
    "    \"\"\"\n",
    "    Function to generate images based on the requested transfomations\n",
    "    Args:\n",
    "    - image             (nd.array)  : input image array\n",
    "    - transformation    (str)       : image transformation to be effectuated\n",
    "    - angle \t\t(int)\t    : rotation angle if transformation is a rotation\n",
    "    Returns:\n",
    "    - trans_image       (nd.array)  : transformed image array\n",
    "    \"\"\"\n",
    "\n",
    "    def rotateImage(image, angle):\n",
    "        \"\"\"\n",
    "        Function to rotate an image at its center\n",
    "        \"\"\"\n",
    "        image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "        rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "        result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "        return result\n",
    "    \n",
    "    # Image transformations\n",
    "    if transformation == 'original':\n",
    "        trans_image = image\n",
    "    elif transformation == 'flip_v':\n",
    "        trans_image = cv2.flip(image, 0)\n",
    "    elif transformation == 'flip_h':\n",
    "        trans_image = cv2.flip(image, 1)\n",
    "    elif transformation == 'flip_vh':\n",
    "        trans_image = cv2.flip(image, -1)\n",
    "    elif transformation == 'rot_c':\n",
    "        trans_image = rotateImage(image, -angle)\n",
    "    elif transformation == 'rot_ac':\n",
    "        trans_image = rotateImage(image, angle)\n",
    "    else:\n",
    "        raise ValueError(\"In valid transformation value passed : {}\".format(transformation))\n",
    "\n",
    "    return trans_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The agumenter ought to be able to do the following:\n",
    "- Get list of patient paths and their respective scores (make sure to do the validation and test splits before)\n",
    "    - Select a random augmentation (flag='test')\n",
    "    - Select a patient path and his/her corresponding score\n",
    "    - With each .dcm file do following: \n",
    "        - read image\n",
    "        - normalized image\n",
    "        - resize image\n",
    "        - get percentage of white matter (%, n) and append to list\n",
    "        - transform image\n",
    "        - store in an array\n",
    "    - yield image_3D (top 70 images with white matter), label\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SEP_generator(object):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 resize,\n",
    "                 normalization,\n",
    "                 transformations)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "class ImageBaseAug(object):\n",
    "    def __init__(self):\n",
    "        sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "        self.seq = iaa.Sequential(\n",
    "            [\n",
    "                # Blur each image with varying strength using\n",
    "                # gaussian blur (sigma between 0 and 3.0),\n",
    "                # average/uniform blur (kernel size between 2x2 and 7x7)\n",
    "                # median blur (kernel size between 3x3 and 11x11).\n",
    "                iaa.OneOf([\n",
    "                    iaa.GaussianBlur((0, 3.0)),\n",
    "                    iaa.AverageBlur(k=(2, 7)),\n",
    "                    iaa.MedianBlur(k=(3, 11)),\n",
    "                ]),\n",
    "                # Sharpen each image, overlay the result with the original\n",
    "                # image using an alpha between 0 (no sharpening) and 1\n",
    "                # (full sharpening effect).\n",
    "                sometimes(iaa.Sharpen(alpha=(0, 0.5), lightness=(0.75, 1.5))),\n",
    "                # Add gaussian noise to some images.\n",
    "                sometimes(iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)),\n",
    "                # Add a value of -5 to 5 to each pixel.\n",
    "                sometimes(iaa.Add((-5, 5), per_channel=0.5)),\n",
    "                # Change brightness of images (80-120% of original value).\n",
    "                sometimes(iaa.Multiply((0.8, 1.2), per_channel=0.5)),\n",
    "                # Improve or worsen the contrast of images.\n",
    "                sometimes(iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5)),\n",
    "            ],\n",
    "            # do all of the above augmentations in random order\n",
    "            random_order=True\n",
    "        )\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        seq_det = self.seq.to_deterministic()\n",
    "        image, label = sample['image'], sample['label']\n",
    "        image = seq_det.augment_images([image])[0]\n",
    "        return {'image': image, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trails (Pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.0976e+22, 1.8515e+28, 4.1988e+07],\n",
      "        [3.0357e+32, 2.7224e+20, 7.7782e+31],\n",
      "        [4.7429e+30, 1.3818e+31, 1.7225e+22],\n",
      "        [1.4602e-19, 1.8617e+25, 1.1835e+22],\n",
      "        [4.3066e+21, 6.3828e+28, 1.4603e-19]])\n",
      "tensor([[0.3337, 0.6211, 0.9639],\n",
      "        [0.1094, 0.2283, 0.4058],\n",
      "        [0.6591, 0.8595, 0.0782],\n",
      "        [0.7474, 0.8065, 0.0429],\n",
      "        [0.4577, 0.5123, 0.5054]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([[5.5000, 3.0000]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 1.6513, -0.3198, -1.5212],\n",
      "        [-1.4167, -0.5110, -1.1456],\n",
      "        [ 0.9274,  2.0594, -1.2510],\n",
      "        [ 0.0256, -0.2712, -0.4079],\n",
      "        [-0.0939, -1.1903,  1.3387]])\n"
     ]
    }
   ],
   "source": [
    "## TENSORS\n",
    "\n",
    "# create an 'un-initialized' matrix\n",
    "x = torch.empty(5, 3)\n",
    "print(x)\n",
    "\n",
    "# construct a randomly 'initialized' matrix\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "\n",
    "# construct a matrix filled with zeros an dtype=long\n",
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)\n",
    "\n",
    "# construct a tensor from data\n",
    "x = torch.tensor([[5.5, 3]])\n",
    "print(x)\n",
    "\n",
    "# Create a tensor based on existing tensor\n",
    "x = x.new_ones(5, 3, dtype=torch.double)\n",
    "print(x)\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.3659, -0.1678, -0.7175],\n",
      "        [-0.5564, -0.1421, -0.5350],\n",
      "        [ 1.0469,  3.0384, -0.9379],\n",
      "        [ 0.9468,  0.2249,  0.0415],\n",
      "        [ 0.0893, -0.8271,  1.6718]])\n",
      "tensor([[ 2.3659, -0.1678, -0.7175],\n",
      "        [-0.5564, -0.1421, -0.5350],\n",
      "        [ 1.0469,  3.0384, -0.9379],\n",
      "        [ 0.9468,  0.2249,  0.0415],\n",
      "        [ 0.0893, -0.8271,  1.6718]])\n",
      "tensor([[ 2.3659, -0.1678, -0.7175],\n",
      "        [-0.5564, -0.1421, -0.5350],\n",
      "        [ 1.0469,  3.0384, -0.9379],\n",
      "        [ 0.9468,  0.2249,  0.0415],\n",
      "        [ 0.0893, -0.8271,  1.6718]])\n",
      "tensor([[0.7146, 0.1521, 0.8037],\n",
      "        [0.8603, 0.3689, 0.6106],\n",
      "        [0.1195, 0.9790, 0.3132],\n",
      "        [0.9212, 0.4961, 0.4493],\n",
      "        [0.1832, 0.3632, 0.3331]])\n",
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
      "tensor([1.0785])\n",
      "1.0785350799560547\n"
     ]
    }
   ],
   "source": [
    "## OPERATIONS\n",
    "\n",
    "# Addition syntax 1\n",
    "y = torch.rand(5, 3)\n",
    "print(x + y)\n",
    "\n",
    "# Addition syntax 2\n",
    "print(torch.add(x, y))\n",
    "\n",
    "# Addtion output towards a tensor\n",
    "result = torch.empty(5,3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)\n",
    "\n",
    "# Addition in place\n",
    "y.add(x)\n",
    "print(y)\n",
    "\n",
    "# Any operation that mutates a tensor in-place is post-fixed with an _.\n",
    "x.copy_(y)\n",
    "x.t_()\n",
    "\n",
    "# Resizing tensors\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1,8)\n",
    "print(x.size(), y.size(), z.size())\n",
    "\n",
    "# Use get value off a one element tensor\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## NUMPY BRIDGE\n",
    "\n",
    "# Torch tensor to numpy array\n",
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "\n",
    "# Numpy array to torch tensor\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0785], device='cuda:0')\n",
      "tensor([2.0785], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## USING CUDA\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")           # Cuda device object\n",
    "    y = torch.ones_like(x, device=device)   # Directly creates a tensor on GPU\n",
    "    x = x.to(device)                        # \n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAUTO-GRAD\\n- The autograd package provides automatic differntation for all\\nopeations on tensors. \\n- A define-by-run framework i.e backprop defined by how code \\nis run and every single iteration can be different.\\n\\nTENSOR\\n- torch.tensor is the central class of the 'torch' package.\\n- If  one sets attribute '.requires_grad()' as 'True', all \\noperations on it are tracked. \\n- When computations are finished one can call'backward()' \\nand have all the gradients computed.\\n- Gradient of a tensor is accumulated into '.grad' attribute.\\n- To stop tensor from tracking history, call '.detach()' to detach \\nit from computation history and prevent future computation \\nfrom being tracked\\n- To prevent tacking histroy and using memory, wrap the code \\nblock in 'with torch.no_grad()'. Helpful when evaluating a model\\ncause model has trainable parameters with 'requires_grad=True'\\n- 'Function' class is very important for autograd implementation\\n- 'Tensor' and 'Function' are interconnected and buid up an acyclic\\ngraph that encodes a complete history of computation.\\n- Each tensor has a '.grad_fn' attribute that references a 'Function'\\nthat has created the 'Tensor' (except for tensors created by user)\\n- To compute derivates, '.backward()' is called on a Tensor. If \\ntensor is a scalar, no arguments ought to be passed to '.backward()'\\nif not, a 'gradient' argument ought to be specified.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "AUTO-GRAD\n",
    "- The autograd package provides automatic differntation for all\n",
    "opeations on tensors. \n",
    "- A define-by-run framework i.e backprop defined by how code \n",
    "is run and every single iteration can be different.\n",
    "\n",
    "TENSOR\n",
    "- torch.tensor is the central class of the 'torch' package.\n",
    "- If  one sets attribute '.requires_grad()' as 'True', all \n",
    "operations on it are tracked. \n",
    "- When computations are finished one can call'backward()' \n",
    "and have all the gradients computed.\n",
    "- Gradient of a tensor is accumulated into '.grad' attribute.\n",
    "- To stop tensor from tracking history, call '.detach()' to detach \n",
    "it from computation history and prevent future computation \n",
    "from being tracked\n",
    "- To prevent tacking histroy and using memory, wrap the code \n",
    "block in 'with torch.no_grad()'. Helpful when evaluating a model\n",
    "cause model has trainable parameters with 'requires_grad=True'\n",
    "- 'Function' class is very important for autograd implementation\n",
    "- 'Tensor' and 'Function' are interconnected and buid up an acyclic\n",
    "graph that encodes a complete history of computation.\n",
    "- Each tensor has a '.grad_fn' attribute that references a 'Function'\n",
    "that has created the 'Tensor' (except for tensors created by user)\n",
    "- To compute derivates, '.backward()' is called on a Tensor. If \n",
    "tensor is a scalar, no arguments ought to be passed to '.backward()'\n",
    "if not, a 'gradient' argument ought to be specified.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n",
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n",
      "tensor([ -388.7856,   198.8780, -1300.0267], grad_fn=<MulBackward0>)\n",
      "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "## TENSORS\n",
    "\n",
    "# Create tenor to track all operations\n",
    "x = torch.ones(2,2, requires_grad=True)\n",
    "print(x)\n",
    "y = x + 2\n",
    "print(y)\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z, out)\n",
    "\n",
    "## GRADIENTS\n",
    "\n",
    "# Peforming backprop on 'out'\n",
    "out.backward()\n",
    "print(x.grad)\n",
    "\n",
    "# An example of vector-Jacobian product\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "print(y)\n",
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "print(x.grad)\n",
    "\n",
    "# Stop autograd from tracking history on Tensors \n",
    "# with .requires_grad=True \n",
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "with torch.no_grad():\n",
    "    print((x**2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-847c9ce0eed7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not callable"
     ]
    }
   ],
   "source": [
    "image.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.5959, -1.3052, -0.6488,  ..., -1.0006, -1.8247,  1.6126],\n",
       "          [-1.0831,  1.6789, -0.2507,  ...,  1.9883,  0.0440, -1.0205],\n",
       "          [ 1.3978, -0.5599,  0.9209,  ...,  1.3029,  1.1875, -3.1398],\n",
       "          ...,\n",
       "          [-0.0280, -1.8147,  0.7449,  ..., -1.1217, -1.8393, -0.7728],\n",
       "          [-0.6970, -0.3968,  0.6772,  ..., -1.6072,  0.3949,  0.0676],\n",
       "          [-0.9794,  0.6049, -0.0923,  ...,  0.6333, -1.1131,  0.2632]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n## NEURAL NETWORKS\\n\\n- Can be constructed using 'torch.nn' package\\n- 'nn' depends on 'autograd' to define models and differentiate\\nthem. \\n- 'nn.Module' contains layers and a method forward(input) that \\nreturns the 'output'.\\n- Training procedure:\\n    - Define neural network that has some learnable parameter\\n    - Iterate over a dataset of inputs\\n    - Process input through the network\\n    - Compute loss\\n    - Propagate gradients back into the network's parameters\\n    - Update weights\\n\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "## NEURAL NETWORKS\n",
    "\n",
    "- Can be constructed using 'torch.nn' package\n",
    "- 'nn' depends on 'autograd' to define models and differentiate\n",
    "them. \n",
    "- 'nn.Module' contains layers and a method forward(input) that \n",
    "returns the 'output'.\n",
    "- Training procedure:\n",
    "    - Define neural network that has some learnable parameter\n",
    "    - Iterate over a dataset of inputs\n",
    "    - Process input through the network\n",
    "    - Compute loss\n",
    "    - Propagate gradients back into the network's parameters\n",
    "    - Update weights\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        \n",
    "        # An affine operation \n",
    "        self.fc1 = nn.Linear(16*6*6, 128)\n",
    "        self.fc2 = nn.Linear(128, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def num_flat_features(self, x):\n",
    "        \n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "            \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[-0.2323, -0.2449, -0.2866],\n",
       "           [-0.1146,  0.0728,  0.2426],\n",
       "           [-0.0343, -0.0685, -0.3318]]],\n",
       " \n",
       " \n",
       "         [[[-0.2328,  0.0704,  0.2253],\n",
       "           [-0.1530, -0.0996,  0.2698],\n",
       "           [ 0.2488, -0.3037, -0.2377]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1622, -0.2684,  0.2374],\n",
       "           [ 0.0469,  0.3276,  0.0163],\n",
       "           [-0.3135, -0.2353,  0.0664]]],\n",
       " \n",
       " \n",
       "         [[[ 0.3103, -0.2125,  0.0187],\n",
       "           [-0.1651, -0.1872,  0.2033],\n",
       "           [ 0.0383, -0.2781, -0.0507]]],\n",
       " \n",
       " \n",
       "         [[[-0.1093, -0.0654,  0.1340],\n",
       "           [-0.3097,  0.1266, -0.1893],\n",
       "           [ 0.0642,  0.1337, -0.2085]]],\n",
       " \n",
       " \n",
       "         [[[-0.1382,  0.3026, -0.3094],\n",
       "           [-0.2960,  0.0430,  0.1208],\n",
       "           [-0.1313, -0.1435, -0.1754]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2984,  0.2190, -0.1588, -0.0237, -0.3073,  0.2563],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 5.0677e-02, -7.0059e-03,  1.2598e-01],\n",
       "           [-6.8708e-02, -1.1695e-02,  1.0934e-01],\n",
       "           [ 8.5356e-02,  8.8093e-02,  2.3657e-02]],\n",
       " \n",
       "          [[ 3.5343e-02,  8.5800e-02,  4.0235e-02],\n",
       "           [-1.0251e-01,  4.1901e-02,  3.3277e-02],\n",
       "           [-1.8783e-02,  1.0008e-01,  1.0457e-01]],\n",
       " \n",
       "          [[-1.1562e-01, -1.2782e-01,  6.0216e-02],\n",
       "           [-1.0805e-01,  1.0134e-01, -6.0400e-02],\n",
       "           [ 6.2367e-02,  1.0473e-02,  4.7283e-02]],\n",
       " \n",
       "          [[ 9.8647e-02,  3.3933e-02, -1.2275e-01],\n",
       "           [ 9.9141e-02,  5.5291e-02, -1.0286e-01],\n",
       "           [-6.5298e-02,  3.4106e-02, -1.2872e-01]],\n",
       " \n",
       "          [[ 1.1609e-01,  1.3096e-01, -1.2101e-01],\n",
       "           [-1.8285e-02,  9.0087e-02,  1.3035e-02],\n",
       "           [ 7.6760e-02,  4.2259e-02, -3.5746e-02]],\n",
       " \n",
       "          [[-7.8460e-02, -1.1147e-01,  5.5694e-02],\n",
       "           [ 4.2177e-02, -1.0834e-01,  1.3013e-01],\n",
       "           [ 4.3505e-02, -2.2817e-02, -5.9212e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 8.9866e-02, -1.3675e-02,  4.2399e-02],\n",
       "           [ 8.1415e-02,  1.0176e-01, -4.8715e-02],\n",
       "           [-5.5192e-02, -1.0516e-01,  9.3510e-02]],\n",
       " \n",
       "          [[-6.4511e-03,  4.1209e-02, -1.2695e-01],\n",
       "           [ 6.5402e-02,  4.2608e-02,  8.3386e-03],\n",
       "           [ 5.0690e-02,  8.7353e-02, -4.9614e-02]],\n",
       " \n",
       "          [[ 1.2287e-01,  7.3029e-04,  4.9661e-02],\n",
       "           [ 1.3460e-01, -1.1223e-01, -1.3450e-01],\n",
       "           [ 7.9590e-02, -1.1647e-01, -1.1250e-01]],\n",
       " \n",
       "          [[-3.5949e-02, -7.2334e-02,  9.7394e-02],\n",
       "           [-9.3889e-02, -8.6084e-02,  1.1556e-01],\n",
       "           [ 1.0713e-01, -9.5371e-02, -1.2734e-01]],\n",
       " \n",
       "          [[ 2.5443e-02,  9.3968e-03, -1.6298e-02],\n",
       "           [ 2.0422e-02, -1.1049e-01,  3.8863e-02],\n",
       "           [ 2.6462e-03, -3.5771e-02, -3.8682e-03]],\n",
       " \n",
       "          [[-8.4029e-02, -1.3128e-02,  4.6753e-02],\n",
       "           [-2.5356e-02,  1.0490e-01,  2.7658e-02],\n",
       "           [ 1.2821e-01, -4.4079e-02,  2.2260e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 4.4288e-02, -1.1133e-02, -1.6846e-02],\n",
       "           [-8.8196e-02, -3.7915e-02, -7.9137e-02],\n",
       "           [-1.9844e-02,  1.2614e-01,  2.1225e-02]],\n",
       " \n",
       "          [[-8.7153e-02,  1.0362e-01,  8.5783e-02],\n",
       "           [ 4.2241e-02, -6.5613e-02,  4.4175e-02],\n",
       "           [-1.2573e-01,  1.0048e-01, -7.0435e-02]],\n",
       " \n",
       "          [[-5.1451e-02, -7.8574e-02,  9.2554e-02],\n",
       "           [ 3.5050e-02,  8.2833e-02, -1.2620e-01],\n",
       "           [-1.7440e-02,  7.2521e-02,  9.6820e-02]],\n",
       " \n",
       "          [[ 1.2787e-01, -3.8891e-02,  2.6664e-02],\n",
       "           [ 9.4598e-02, -6.4243e-02,  4.9233e-02],\n",
       "           [ 2.9556e-02,  5.7823e-02, -9.3619e-02]],\n",
       " \n",
       "          [[-1.0877e-01,  6.0811e-02, -4.3056e-02],\n",
       "           [ 1.0397e-02, -1.3402e-01,  5.0004e-02],\n",
       "           [-6.7294e-02, -5.8732e-02,  9.5499e-02]],\n",
       " \n",
       "          [[-3.1827e-02, -7.6012e-02,  8.1954e-02],\n",
       "           [-1.8342e-02, -1.1787e-01, -6.3469e-02],\n",
       "           [-7.7043e-02,  4.1834e-02, -2.5755e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.0324e-01, -1.0692e-01, -1.8144e-02],\n",
       "           [ 9.2271e-03,  6.8801e-02, -7.9206e-04],\n",
       "           [ 3.7765e-02, -1.3412e-01, -7.9073e-02]],\n",
       " \n",
       "          [[ 2.8056e-02,  4.4513e-03, -1.3417e-02],\n",
       "           [ 3.3560e-02, -3.2798e-02, -5.0256e-02],\n",
       "           [ 6.0082e-02,  7.2572e-02, -1.0778e-01]],\n",
       " \n",
       "          [[ 9.9453e-02, -3.2227e-02,  1.2189e-01],\n",
       "           [-5.4900e-02, -9.8429e-02, -9.6943e-02],\n",
       "           [-3.9690e-02, -8.4047e-02, -4.8242e-02]],\n",
       " \n",
       "          [[ 8.0768e-02, -4.7462e-03,  1.1920e-01],\n",
       "           [ 2.9423e-02, -6.2966e-02,  2.3959e-02],\n",
       "           [-1.0216e-02, -1.0689e-02, -6.7494e-02]],\n",
       " \n",
       "          [[-1.1826e-01, -1.9751e-02,  9.6605e-02],\n",
       "           [ 6.1158e-03, -9.8206e-02,  1.1485e-02],\n",
       "           [-3.1351e-02, -9.3071e-02, -2.3761e-02]],\n",
       " \n",
       "          [[ 1.2871e-01,  4.4970e-02,  3.4212e-02],\n",
       "           [ 3.7320e-02, -4.4461e-02,  1.0974e-01],\n",
       "           [-2.1259e-02,  1.1357e-01, -9.1831e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.2543e-01,  1.0812e-01, -2.9979e-02],\n",
       "           [ 6.3051e-02, -1.2248e-01, -1.2886e-01],\n",
       "           [ 3.2365e-05, -7.5357e-02,  1.3676e-03]],\n",
       " \n",
       "          [[ 1.3418e-01, -9.6795e-02,  1.0443e-01],\n",
       "           [-2.9344e-03,  9.1968e-02, -3.8967e-02],\n",
       "           [ 1.1719e-01, -1.1143e-01, -6.5353e-02]],\n",
       " \n",
       "          [[-1.0607e-01,  3.5183e-02,  5.2084e-02],\n",
       "           [ 6.3845e-02,  5.8421e-02, -5.9610e-02],\n",
       "           [ 1.1303e-01,  1.2018e-01, -1.1633e-01]],\n",
       " \n",
       "          [[-5.1220e-02, -9.3407e-02,  2.2942e-02],\n",
       "           [ 1.1722e-01,  8.3131e-02, -1.1630e-01],\n",
       "           [-4.8341e-02,  3.3950e-02, -1.3156e-01]],\n",
       " \n",
       "          [[ 4.5607e-02, -2.0505e-03,  8.6989e-02],\n",
       "           [-8.9246e-02,  5.0506e-02, -1.3067e-01],\n",
       "           [-1.2369e-02,  1.0685e-01, -5.7137e-03]],\n",
       " \n",
       "          [[ 6.7140e-03,  9.4750e-02,  1.3118e-01],\n",
       "           [-8.1159e-02,  4.6466e-03,  3.0833e-02],\n",
       "           [-5.3341e-02,  4.6939e-02, -1.0097e-01]]],\n",
       " \n",
       " \n",
       "         [[[-7.4202e-02, -2.2915e-02,  1.1638e-01],\n",
       "           [ 6.2923e-03,  9.4744e-02,  1.5566e-03],\n",
       "           [ 4.4014e-03, -4.4594e-02, -1.0213e-01]],\n",
       " \n",
       "          [[ 1.0920e-01, -6.6726e-02, -4.0483e-02],\n",
       "           [ 1.1281e-02, -5.2111e-02,  9.3913e-04],\n",
       "           [ 2.3376e-02, -9.8804e-04,  6.4026e-02]],\n",
       " \n",
       "          [[ 1.2293e-01,  6.9748e-02, -6.1644e-02],\n",
       "           [ 1.2266e-01,  1.0219e-01,  5.5179e-02],\n",
       "           [-1.0250e-01,  8.0548e-02, -6.5759e-02]],\n",
       " \n",
       "          [[ 1.0126e-01, -1.7483e-02, -7.6261e-02],\n",
       "           [ 8.5605e-02, -7.9225e-02, -5.3478e-02],\n",
       "           [ 1.1626e-01,  9.8868e-02,  1.0645e-01]],\n",
       " \n",
       "          [[ 1.6967e-02,  1.7661e-02, -7.3789e-02],\n",
       "           [-1.0260e-01, -2.3413e-02, -9.7209e-02],\n",
       "           [ 9.6753e-02,  1.1587e-01,  8.2934e-03]],\n",
       " \n",
       "          [[-6.9221e-02,  4.8992e-03, -1.6911e-03],\n",
       "           [-5.7334e-02, -9.8769e-02, -3.4438e-02],\n",
       "           [ 1.1318e-01, -4.0737e-02,  1.1218e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.7093e-02,  5.9818e-02, -1.2317e-01],\n",
       "           [-1.1194e-02,  3.1023e-02, -8.8556e-04],\n",
       "           [ 2.2283e-02, -5.4551e-02, -6.6703e-02]],\n",
       " \n",
       "          [[-1.1339e-01, -3.6911e-02,  6.3602e-02],\n",
       "           [ 1.1359e-01,  4.2459e-02, -9.8496e-02],\n",
       "           [-4.2377e-02,  5.9902e-02,  1.0108e-01]],\n",
       " \n",
       "          [[ 7.8722e-02, -1.6140e-02,  1.1092e-02],\n",
       "           [-6.5572e-02, -7.4538e-02,  1.2886e-01],\n",
       "           [ 5.3450e-02,  6.8772e-02,  4.4029e-02]],\n",
       " \n",
       "          [[-9.5221e-02, -4.9372e-03, -7.0891e-02],\n",
       "           [-4.9979e-02, -1.0890e-01,  1.2093e-02],\n",
       "           [-9.8347e-02, -1.5342e-02,  1.2492e-01]],\n",
       " \n",
       "          [[ 5.0384e-02,  5.7323e-02,  3.6806e-02],\n",
       "           [-1.8906e-02,  1.0045e-01, -2.0887e-02],\n",
       "           [-2.9929e-02, -1.1949e-01,  2.9443e-03]],\n",
       " \n",
       "          [[ 1.3011e-01,  8.5083e-02, -9.2143e-02],\n",
       "           [-1.2865e-01,  8.4350e-04, -1.3391e-01],\n",
       "           [ 1.0460e-01,  2.7664e-02,  8.6602e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 6.8172e-02,  7.1116e-02,  7.5417e-02],\n",
       "           [-1.2855e-01, -4.1635e-02,  1.1367e-01],\n",
       "           [-1.3590e-01, -1.2686e-01, -1.0454e-01]],\n",
       " \n",
       "          [[-1.2493e-01,  2.4598e-02, -7.5786e-02],\n",
       "           [-5.3796e-03,  5.1973e-02,  9.1519e-02],\n",
       "           [-2.4136e-02, -1.2708e-01, -1.3515e-01]],\n",
       " \n",
       "          [[-8.5956e-02,  6.9122e-02, -2.4102e-02],\n",
       "           [-1.3152e-01, -4.0719e-02, -1.2839e-01],\n",
       "           [-2.5968e-02,  9.1037e-02, -1.3553e-01]],\n",
       " \n",
       "          [[-6.4655e-02, -2.3611e-02, -5.0629e-03],\n",
       "           [-1.0141e-01, -9.8850e-02, -3.9673e-03],\n",
       "           [ 7.7350e-02, -1.1521e-01, -1.0210e-01]],\n",
       " \n",
       "          [[-4.5495e-02,  1.7019e-02,  1.1969e-01],\n",
       "           [ 6.6003e-02,  8.3824e-02,  8.9536e-02],\n",
       "           [-7.0403e-02,  8.6154e-02, -1.2006e-01]],\n",
       " \n",
       "          [[ 1.7452e-02,  2.5404e-02, -9.3191e-02],\n",
       "           [-8.2743e-02,  1.2791e-02,  2.6185e-02],\n",
       "           [-5.3506e-02,  6.1667e-02,  4.5171e-02]]],\n",
       " \n",
       " \n",
       "         [[[-8.6245e-02,  8.3401e-02,  3.1066e-02],\n",
       "           [ 1.3508e-02, -9.8324e-02, -1.1112e-01],\n",
       "           [ 1.0109e-01,  1.0952e-01, -6.6852e-02]],\n",
       " \n",
       "          [[ 7.0986e-02, -2.6133e-02, -1.4540e-02],\n",
       "           [-1.0860e-01, -1.2459e-01, -6.9826e-02],\n",
       "           [-1.2481e-01, -5.7419e-02, -7.5938e-02]],\n",
       " \n",
       "          [[ 5.9534e-02, -8.3661e-03, -8.0395e-02],\n",
       "           [ 6.6728e-02, -1.0573e-01, -3.0892e-02],\n",
       "           [-7.1364e-02, -2.9114e-02, -4.3751e-02]],\n",
       " \n",
       "          [[ 1.0073e-01,  4.2678e-02, -9.9324e-02],\n",
       "           [-1.0965e-01,  1.5529e-02,  1.3545e-01],\n",
       "           [ 9.6430e-02,  8.9465e-02, -1.2305e-01]],\n",
       " \n",
       "          [[ 1.3555e-01, -4.7653e-02, -7.5783e-02],\n",
       "           [ 9.2733e-02,  5.6043e-02, -3.0358e-03],\n",
       "           [ 1.1098e-01,  6.8892e-02,  6.9102e-02]],\n",
       " \n",
       "          [[ 1.2795e-01, -1.2694e-01,  6.6125e-02],\n",
       "           [-8.7669e-02, -8.1497e-02, -7.7170e-02],\n",
       "           [-3.6409e-02,  4.4003e-02,  1.6329e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.1474e-01, -9.5133e-02, -7.1940e-02],\n",
       "           [-4.3974e-02,  1.9977e-02,  1.2374e-01],\n",
       "           [ 1.2142e-01, -1.3340e-01, -7.8477e-02]],\n",
       " \n",
       "          [[-3.9066e-03, -5.1585e-02,  1.2476e-01],\n",
       "           [-5.8531e-02, -1.0125e-01,  6.1029e-02],\n",
       "           [-1.1530e-01,  6.5650e-02, -1.2309e-01]],\n",
       " \n",
       "          [[-1.1189e-01,  7.2549e-02, -6.6518e-02],\n",
       "           [-4.3009e-04, -9.6248e-02,  2.6542e-04],\n",
       "           [ 3.3452e-02, -1.0639e-02, -3.8961e-02]],\n",
       " \n",
       "          [[-7.7812e-02, -4.2023e-02,  6.0354e-02],\n",
       "           [ 7.5043e-02,  1.3367e-02,  7.3270e-03],\n",
       "           [-9.3137e-02, -3.0136e-02,  1.0763e-01]],\n",
       " \n",
       "          [[-1.2620e-01, -1.2378e-02, -5.8109e-02],\n",
       "           [ 7.7335e-02,  1.2369e-01, -1.0825e-01],\n",
       "           [-2.5342e-02,  5.6346e-02, -9.3716e-03]],\n",
       " \n",
       "          [[-3.8192e-02,  2.3217e-03, -1.3381e-02],\n",
       "           [ 1.0059e-01,  1.3571e-01,  5.8859e-02],\n",
       "           [-7.4427e-02,  9.3367e-02,  1.2881e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 3.2590e-02,  6.4496e-03, -8.8185e-02],\n",
       "           [ 6.8915e-02, -8.2533e-02,  5.0870e-02],\n",
       "           [ 1.8932e-02,  3.5037e-03, -9.9120e-02]],\n",
       " \n",
       "          [[-9.0856e-02, -1.0427e-01,  2.1469e-02],\n",
       "           [-4.2588e-02, -8.1355e-03,  3.0959e-02],\n",
       "           [ 4.5268e-02,  9.5205e-02,  1.2931e-01]],\n",
       " \n",
       "          [[ 1.3182e-01,  2.7778e-03,  8.2869e-02],\n",
       "           [-4.0744e-02, -4.6075e-03, -7.6832e-02],\n",
       "           [-1.6563e-02, -7.7690e-02, -8.5096e-02]],\n",
       " \n",
       "          [[-6.1972e-02, -2.3258e-02, -8.9495e-02],\n",
       "           [-1.0460e-02, -1.2923e-01,  1.2195e-02],\n",
       "           [ 3.3663e-02, -1.2670e-01, -1.1414e-01]],\n",
       " \n",
       "          [[-4.4403e-02,  2.7649e-02,  1.1171e-01],\n",
       "           [ 9.6757e-02, -6.5990e-02, -9.9527e-02],\n",
       "           [ 6.9867e-02,  1.2035e-01, -2.4514e-02]],\n",
       " \n",
       "          [[-9.2715e-02,  6.5514e-02,  8.5359e-02],\n",
       "           [-3.8310e-02,  3.7347e-03,  2.6944e-02],\n",
       "           [-8.6540e-03,  1.7884e-02, -4.5517e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.3403e-01,  1.2425e-01, -9.6135e-02],\n",
       "           [-9.5450e-02,  2.1220e-02,  1.1061e-01],\n",
       "           [-5.8931e-02,  6.2115e-02,  2.3354e-02]],\n",
       " \n",
       "          [[ 1.2031e-01,  1.3601e-01,  8.6819e-02],\n",
       "           [-8.0729e-02, -6.6756e-02,  6.5286e-03],\n",
       "           [-9.7196e-02, -1.8831e-02,  8.5729e-02]],\n",
       " \n",
       "          [[ 1.3351e-01, -8.3688e-02,  1.2977e-01],\n",
       "           [-4.4937e-02, -1.0815e-01, -6.7634e-02],\n",
       "           [ 2.2112e-02,  1.2544e-01,  1.5766e-02]],\n",
       " \n",
       "          [[ 6.7129e-02,  5.4678e-02,  1.3254e-01],\n",
       "           [ 3.8362e-02,  7.6426e-02, -7.9170e-02],\n",
       "           [ 1.2075e-01, -1.0000e-01, -7.0553e-02]],\n",
       " \n",
       "          [[ 7.6140e-02, -5.8494e-02,  1.0831e-01],\n",
       "           [ 2.0384e-02,  8.3657e-02,  5.7968e-02],\n",
       "           [-9.4595e-02, -6.3552e-02, -5.5863e-02]],\n",
       " \n",
       "          [[ 6.2199e-02, -1.1925e-01,  6.3086e-02],\n",
       "           [ 1.1441e-02,  4.4917e-02, -1.5430e-02],\n",
       "           [ 9.5200e-02,  1.4095e-02,  3.0177e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 8.3197e-02, -8.9163e-02,  5.2861e-02],\n",
       "           [-6.7959e-02, -1.4142e-02, -8.9195e-02],\n",
       "           [-1.8395e-02,  1.0678e-01,  1.1417e-02]],\n",
       " \n",
       "          [[-5.7739e-02,  5.6376e-02, -8.6604e-02],\n",
       "           [-2.5989e-02,  3.0727e-02, -1.3107e-02],\n",
       "           [-1.2315e-01, -1.2329e-01,  1.0545e-01]],\n",
       " \n",
       "          [[ 2.7866e-02,  7.9189e-02, -9.4072e-02],\n",
       "           [ 2.8545e-02,  1.0528e-01,  8.4278e-02],\n",
       "           [-7.4636e-02,  1.3131e-01,  2.4488e-02]],\n",
       " \n",
       "          [[ 1.3452e-01,  5.7057e-02,  2.9416e-02],\n",
       "           [-3.9325e-02,  5.8016e-02,  1.1291e-01],\n",
       "           [-7.7780e-02,  8.9286e-02,  8.4746e-02]],\n",
       " \n",
       "          [[-1.7593e-02,  9.8178e-02, -8.1899e-03],\n",
       "           [ 9.7410e-02,  4.3882e-04,  1.1667e-01],\n",
       "           [ 2.7000e-02,  6.7770e-02, -1.2625e-01]],\n",
       " \n",
       "          [[-7.0586e-02, -3.2327e-02, -6.5452e-02],\n",
       "           [ 7.3590e-02, -6.6263e-03,  2.5401e-03],\n",
       "           [ 8.2093e-02,  7.4595e-03,  1.0516e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 9.7235e-02, -3.5810e-02,  1.0159e-01],\n",
       "           [-2.1013e-02, -6.4958e-02, -5.2283e-02],\n",
       "           [ 2.8656e-02, -1.1786e-01,  1.1373e-01]],\n",
       " \n",
       "          [[-7.2538e-02, -6.8093e-02,  1.0754e-01],\n",
       "           [-4.9739e-02,  1.0711e-01,  1.6838e-02],\n",
       "           [-9.4187e-02,  6.0704e-02, -2.6398e-02]],\n",
       " \n",
       "          [[ 1.0893e-01, -2.4366e-02, -1.1429e-01],\n",
       "           [ 7.6843e-02, -2.8448e-02, -1.1462e-01],\n",
       "           [-8.0136e-03,  2.4406e-02, -5.0574e-02]],\n",
       " \n",
       "          [[ 1.2997e-01, -8.8817e-02, -1.2123e-01],\n",
       "           [ 2.2068e-02, -7.0485e-02, -8.2768e-02],\n",
       "           [ 1.1658e-01,  6.4940e-02,  8.4461e-02]],\n",
       " \n",
       "          [[ 7.8588e-02, -8.3426e-02,  1.3328e-01],\n",
       "           [ 6.4958e-02,  2.9859e-02, -4.6384e-02],\n",
       "           [-1.1415e-02, -8.2749e-02,  3.5654e-02]],\n",
       " \n",
       "          [[ 8.4803e-02, -1.0131e-01, -6.5937e-02],\n",
       "           [ 4.1671e-02, -1.2863e-01, -3.4415e-02],\n",
       "           [ 1.3212e-01, -7.5758e-02,  8.4648e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.1131e-01,  4.6475e-02, -2.1738e-02],\n",
       "           [ 4.6435e-02,  6.8189e-03, -6.9435e-02],\n",
       "           [-8.7066e-02, -1.3097e-01, -1.3598e-01]],\n",
       " \n",
       "          [[-9.8882e-02, -2.3478e-02, -1.0694e-01],\n",
       "           [-1.3534e-01,  7.0492e-02,  1.0954e-01],\n",
       "           [ 1.1095e-01,  1.0074e-01,  6.4609e-03]],\n",
       " \n",
       "          [[-8.0681e-02,  7.0255e-02, -1.1718e-01],\n",
       "           [-1.1329e-01,  1.1351e-01,  1.2830e-02],\n",
       "           [-4.4354e-02,  4.7222e-02,  3.2928e-02]],\n",
       " \n",
       "          [[ 7.3529e-02, -1.7808e-02,  4.5901e-02],\n",
       "           [ 3.3151e-02, -1.1857e-01, -7.9140e-03],\n",
       "           [ 6.1218e-02,  3.2154e-02, -2.2320e-02]],\n",
       " \n",
       "          [[-9.6191e-02, -2.0720e-02, -7.0684e-02],\n",
       "           [ 9.1742e-02, -1.0270e-01,  6.6208e-02],\n",
       "           [ 6.8274e-02,  6.7086e-02,  7.8010e-02]],\n",
       " \n",
       "          [[-8.2397e-02, -1.3201e-01, -9.1560e-02],\n",
       "           [-7.6929e-02,  5.8333e-03,  8.3993e-02],\n",
       "           [-1.8500e-02,  1.2551e-01,  1.2407e-02]]],\n",
       " \n",
       " \n",
       "         [[[-7.6399e-02,  2.9177e-02,  3.0598e-02],\n",
       "           [-6.0404e-02,  7.7427e-02,  8.4198e-03],\n",
       "           [-1.1329e-01, -1.1051e-02, -3.2964e-02]],\n",
       " \n",
       "          [[ 1.1835e-01,  7.9650e-02, -1.3317e-01],\n",
       "           [ 3.4938e-03,  1.2881e-01,  9.0918e-02],\n",
       "           [-6.1714e-02, -9.1292e-02, -8.7525e-02]],\n",
       " \n",
       "          [[-2.1953e-03,  2.1589e-02,  7.5277e-02],\n",
       "           [-1.1467e-01, -1.1076e-01,  9.2585e-03],\n",
       "           [-7.8942e-02,  7.4926e-02,  8.9980e-02]],\n",
       " \n",
       "          [[-1.4577e-02, -1.2941e-01, -1.3362e-01],\n",
       "           [-9.8392e-02,  9.2981e-02, -3.0608e-02],\n",
       "           [ 8.4951e-02,  5.6254e-02,  2.8894e-02]],\n",
       " \n",
       "          [[-1.2375e-01,  2.6504e-02, -6.4677e-02],\n",
       "           [-1.0755e-01,  5.3256e-02, -2.4231e-02],\n",
       "           [ 2.4829e-02,  8.7724e-02, -1.9183e-02]],\n",
       " \n",
       "          [[ 1.3206e-01,  7.9942e-02,  8.1519e-02],\n",
       "           [ 1.0054e-01,  7.4570e-02,  6.3062e-02],\n",
       "           [-5.7720e-02,  5.3729e-02, -1.0196e-01]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0629,  0.0833, -0.1094, -0.1266,  0.1209, -0.0210, -0.0764,  0.0994,\n",
       "          0.0624, -0.0343,  0.0199,  0.0023,  0.0815,  0.0068, -0.0844,  0.1048],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-3.4460e-02, -3.1237e-02,  3.2563e-02,  ..., -3.0982e-02,\n",
       "           7.0512e-03,  9.0388e-03],\n",
       "         [-4.3852e-03,  2.8116e-02,  2.0799e-02,  ..., -3.9396e-02,\n",
       "          -7.9644e-03,  3.3868e-02],\n",
       "         [-3.6996e-02, -1.2014e-05,  1.4957e-02,  ..., -3.7597e-02,\n",
       "           1.1264e-02,  6.2808e-03],\n",
       "         ...,\n",
       "         [ 3.0903e-02, -2.1472e-02, -5.0272e-03,  ...,  4.6019e-03,\n",
       "           2.9418e-02, -1.9054e-02],\n",
       "         [-4.8765e-03, -6.3021e-04,  2.9659e-02,  ..., -4.2267e-03,\n",
       "           3.5933e-02, -3.6643e-02],\n",
       "         [-1.2638e-03, -3.6584e-02, -1.1511e-02,  ..., -3.1438e-02,\n",
       "           8.8240e-03,  7.7171e-03]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0278, -0.0384,  0.0320,  0.0036,  0.0324, -0.0011, -0.0376, -0.0373,\n",
       "         -0.0322, -0.0256,  0.0101,  0.0189, -0.0319, -0.0281,  0.0196,  0.0336,\n",
       "          0.0161,  0.0027,  0.0244,  0.0029, -0.0266,  0.0272, -0.0085,  0.0300,\n",
       "          0.0126, -0.0310, -0.0316,  0.0363, -0.0295, -0.0355, -0.0172,  0.0304,\n",
       "         -0.0049, -0.0108,  0.0219,  0.0284,  0.0316,  0.0130, -0.0304,  0.0088,\n",
       "         -0.0019,  0.0321, -0.0084, -0.0117,  0.0289,  0.0201, -0.0148, -0.0359,\n",
       "          0.0237,  0.0116, -0.0395,  0.0109, -0.0157, -0.0386,  0.0079,  0.0004,\n",
       "          0.0185,  0.0298, -0.0398, -0.0360, -0.0329, -0.0073,  0.0108,  0.0223,\n",
       "          0.0237, -0.0267, -0.0360,  0.0275,  0.0290,  0.0087,  0.0082, -0.0285,\n",
       "         -0.0203, -0.0167,  0.0201,  0.0039,  0.0227,  0.0216, -0.0347, -0.0198,\n",
       "          0.0365, -0.0059, -0.0350,  0.0009, -0.0245, -0.0311,  0.0246, -0.0191,\n",
       "         -0.0309,  0.0242,  0.0201, -0.0396, -0.0185,  0.0314,  0.0025, -0.0272,\n",
       "          0.0342,  0.0016, -0.0078, -0.0295,  0.0091, -0.0393,  0.0357, -0.0369,\n",
       "         -0.0307,  0.0399,  0.0145, -0.0094,  0.0073,  0.0310,  0.0181,  0.0397,\n",
       "          0.0134, -0.0400, -0.0231, -0.0273,  0.0140, -0.0248,  0.0020, -0.0119,\n",
       "         -0.0353,  0.0232, -0.0083, -0.0053,  0.0109,  0.0361, -0.0355,  0.0087],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0538,  0.0446, -0.0454,  ..., -0.0602, -0.0864, -0.0287],\n",
       "         [ 0.0529, -0.0616,  0.0152,  ..., -0.0770,  0.0724, -0.0047],\n",
       "         [ 0.0732,  0.0773,  0.0585,  ...,  0.0774,  0.0466, -0.0204],\n",
       "         ...,\n",
       "         [ 0.0619, -0.0850, -0.0428,  ..., -0.0539, -0.0132, -0.0160],\n",
       "         [ 0.0531,  0.0751,  0.0636,  ...,  0.0342, -0.0324,  0.0199],\n",
       "         [-0.0869, -0.0487, -0.0754,  ...,  0.0459,  0.0436,  0.0855]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0117,  0.0528, -0.0818,  0.0512,  0.0528,  0.0528, -0.0630, -0.0013,\n",
       "         -0.0298, -0.0693,  0.0212,  0.0100,  0.0713,  0.0030, -0.0860,  0.0193,\n",
       "         -0.0140,  0.0350, -0.0835,  0.0686,  0.0642,  0.0429,  0.0297,  0.0148,\n",
       "          0.0309,  0.0240, -0.0125, -0.0149, -0.0555, -0.0595, -0.0325,  0.0358,\n",
       "          0.0831, -0.0844, -0.0163,  0.0026,  0.0708,  0.0728,  0.0489,  0.0187,\n",
       "          0.0071, -0.0250, -0.0850,  0.0716,  0.0874,  0.0812,  0.0861,  0.0279,\n",
       "         -0.0407,  0.0631,  0.0866, -0.0219, -0.0218,  0.0503,  0.0089, -0.0883,\n",
       "         -0.0226, -0.0211,  0.0159,  0.0252, -0.0671, -0.0490,  0.0764,  0.0229,\n",
       "         -0.0556,  0.0860,  0.0616,  0.0283,  0.0624,  0.0241,  0.0766,  0.0869,\n",
       "         -0.0839, -0.0017, -0.0778, -0.0574,  0.0124, -0.0503,  0.0354, -0.0210,\n",
       "         -0.0447, -0.0643,  0.0404, -0.0630], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 2.2471e-02,  5.1913e-02,  2.1445e-02,  3.8549e-02,  6.6405e-02,\n",
       "           5.4470e-02,  3.3684e-03,  1.0888e-01, -2.0764e-02, -1.0115e-01,\n",
       "           2.3744e-02,  8.5670e-02, -3.8348e-02, -4.6471e-02, -8.2935e-02,\n",
       "          -4.9388e-02, -2.4305e-02,  7.5483e-02, -8.0920e-02,  8.0953e-04,\n",
       "          -1.0262e-02,  1.5403e-02, -6.3578e-02, -4.8863e-02, -1.0231e-01,\n",
       "           6.8085e-02, -7.6927e-02,  3.0900e-02,  4.1488e-03,  2.7587e-02,\n",
       "           2.8296e-02, -1.7715e-02,  4.1103e-02, -5.7465e-02, -6.5199e-02,\n",
       "           9.7490e-02,  4.4215e-02,  2.9443e-02, -1.1407e-03,  8.8414e-02,\n",
       "           5.6601e-02,  1.0266e-01,  4.3837e-02,  2.5547e-02, -6.1302e-02,\n",
       "          -7.9849e-02,  2.9247e-02, -7.1102e-03, -3.4043e-02, -5.3798e-02,\n",
       "          -2.2694e-02, -1.8206e-02,  3.0547e-06,  1.0268e-01, -1.5478e-02,\n",
       "          -4.3101e-02, -4.4714e-02, -4.8606e-02, -1.2352e-02, -6.5770e-03,\n",
       "          -9.7107e-02,  6.9239e-02,  9.6643e-02, -7.4844e-02,  9.9958e-02,\n",
       "           6.4974e-03,  5.0112e-02, -2.3131e-02,  3.6227e-02, -1.0308e-02,\n",
       "           9.5811e-02,  9.3209e-02,  7.9550e-02,  3.1073e-02,  4.0399e-02,\n",
       "           4.7882e-03, -1.0815e-01, -1.0711e-01,  1.0521e-01, -7.3132e-02,\n",
       "          -2.1229e-02,  1.9402e-02,  6.6231e-02,  4.7909e-02],\n",
       "         [ 8.5375e-02,  5.2760e-02, -2.7306e-02, -1.7024e-03,  1.8398e-02,\n",
       "           2.1834e-02, -5.7708e-02, -7.4290e-02, -5.2661e-02,  8.1045e-02,\n",
       "          -9.6415e-02,  5.0656e-02,  2.5158e-02, -8.5377e-02, -5.1232e-03,\n",
       "           1.1909e-02,  9.4411e-02,  3.2326e-02, -8.7600e-02,  9.4281e-02,\n",
       "           1.3903e-02, -2.2879e-02, -6.5229e-02,  6.5901e-02, -9.0636e-02,\n",
       "          -1.4861e-02,  5.2488e-02,  9.7005e-02,  4.8277e-02,  4.2573e-02,\n",
       "           3.1578e-02,  6.4337e-02,  4.2650e-02,  1.6391e-02,  4.2735e-02,\n",
       "           9.0867e-02,  4.2335e-02, -5.2954e-02, -1.4391e-02, -1.7345e-02,\n",
       "          -1.0692e-01,  9.7673e-02,  7.3393e-02, -3.1346e-02, -1.3487e-02,\n",
       "          -7.3486e-02, -7.0565e-02, -3.8590e-02, -6.9765e-02,  9.7058e-02,\n",
       "          -6.5031e-03, -8.9672e-02, -6.9440e-02, -6.4875e-04,  7.0040e-02,\n",
       "          -6.9802e-02, -1.0185e-01, -1.5614e-02, -5.1543e-02, -5.6824e-02,\n",
       "           8.5023e-02,  4.0171e-02,  1.0585e-01, -2.3178e-02, -2.3256e-02,\n",
       "          -9.6643e-02,  6.0632e-03, -2.1820e-02, -7.6304e-02, -5.7729e-02,\n",
       "          -3.4441e-02, -7.6699e-02, -5.9325e-02,  3.9778e-02, -3.3389e-02,\n",
       "          -2.2263e-03,  1.8624e-02, -9.8534e-02, -3.3689e-02,  8.4132e-02,\n",
       "          -5.2844e-02, -1.0324e-01,  1.1850e-02, -1.0216e-01],\n",
       "         [ 9.5913e-02, -9.4385e-03, -1.0471e-01, -8.7327e-02, -9.9339e-02,\n",
       "          -2.5430e-02,  8.2544e-02,  7.1679e-02,  4.7262e-02, -8.8388e-02,\n",
       "           1.9147e-02,  8.8955e-02,  8.2329e-02,  3.0970e-02,  2.7289e-02,\n",
       "          -1.4847e-02,  5.8958e-02,  7.7990e-02,  9.8464e-02, -4.5166e-02,\n",
       "          -2.3275e-02, -8.8904e-03,  9.7745e-02, -1.7626e-02,  7.6103e-02,\n",
       "           7.1216e-02,  7.8042e-02,  8.2760e-02,  6.7225e-02, -1.3383e-02,\n",
       "           2.3514e-02,  3.0534e-02,  2.5931e-02, -1.0185e-01,  9.4210e-02,\n",
       "          -1.2600e-02, -7.8335e-02,  6.9334e-02,  9.9303e-03, -7.2512e-02,\n",
       "          -1.0832e-01,  2.1772e-02,  2.5353e-02,  7.7941e-02,  9.0982e-02,\n",
       "          -7.0343e-02,  1.0022e-01,  1.9562e-02,  3.2548e-02, -2.3769e-02,\n",
       "           1.0497e-01,  2.5819e-03,  8.1001e-02,  4.2366e-02,  9.4409e-02,\n",
       "           1.4560e-02, -3.2515e-02, -9.0691e-02, -9.5946e-02,  8.6136e-02,\n",
       "          -1.0527e-01,  3.4020e-03, -1.9192e-02, -5.3631e-02, -7.4770e-02,\n",
       "          -1.0052e-01,  6.9377e-02, -8.5394e-03,  7.6282e-02,  6.5076e-02,\n",
       "          -7.6005e-02,  6.5704e-02, -2.5069e-02, -1.5905e-02, -1.0521e-01,\n",
       "          -8.3958e-02,  3.3666e-02,  1.9177e-02,  1.0525e-01,  2.4816e-02,\n",
       "           6.6416e-02, -8.6203e-03,  7.1068e-02, -7.4564e-02],\n",
       "         [ 6.4200e-02, -1.5210e-03, -2.3213e-02, -8.7832e-02,  3.0533e-02,\n",
       "           9.9848e-02, -2.0492e-02,  9.0690e-02,  4.3599e-02, -9.1908e-02,\n",
       "          -1.1705e-02, -6.0372e-02, -4.7652e-02, -4.1403e-02, -4.8416e-02,\n",
       "          -3.7678e-02, -2.8518e-02,  1.0442e-01, -6.7777e-02,  8.3431e-02,\n",
       "           5.6746e-02, -3.7980e-02, -3.0380e-02,  2.4074e-02,  2.1109e-02,\n",
       "          -5.0548e-02, -9.4986e-02,  4.0530e-02, -1.0011e-01, -4.2586e-02,\n",
       "           7.8721e-02, -1.5337e-02,  7.3632e-02,  9.8233e-02, -1.2413e-02,\n",
       "          -6.8360e-02, -9.4982e-03, -2.5169e-02,  5.1581e-02, -1.3797e-02,\n",
       "           8.4682e-02, -5.5275e-02,  6.1848e-02,  6.2847e-02, -7.0526e-02,\n",
       "           8.7223e-02, -8.2129e-02, -5.9675e-02, -2.6585e-02, -1.1536e-02,\n",
       "           6.5164e-02,  5.6901e-03, -7.3319e-02,  1.5612e-02, -9.5779e-02,\n",
       "           2.5136e-02,  4.3362e-02,  6.0402e-02, -1.1131e-02, -1.7714e-02,\n",
       "          -2.9092e-02,  1.2687e-02,  5.9566e-03,  3.7162e-02, -1.2682e-02,\n",
       "           7.5038e-02, -2.5425e-02, -8.0818e-02, -4.0374e-02,  6.7540e-02,\n",
       "           3.9898e-02, -3.3309e-02,  4.4232e-02, -6.7806e-02,  2.3395e-02,\n",
       "          -1.0869e-01,  9.5670e-02, -2.4117e-02, -8.2839e-02, -8.7247e-02,\n",
       "           1.2804e-02, -2.6953e-02, -5.0961e-02, -4.9031e-02],\n",
       "         [ 8.5564e-02,  7.9346e-02, -1.4050e-04,  2.2765e-02,  1.9030e-02,\n",
       "           4.7810e-02, -3.0615e-02, -9.2810e-02, -3.7900e-02,  2.7877e-02,\n",
       "          -8.2024e-02, -2.0819e-03,  4.4147e-02,  1.1396e-02, -1.6456e-02,\n",
       "           1.7524e-02, -1.0243e-01,  6.5692e-02,  7.8648e-02, -3.7204e-02,\n",
       "           9.3380e-02,  7.3594e-02,  7.9224e-02,  2.5334e-02, -1.0178e-01,\n",
       "          -4.3294e-02,  1.2551e-02,  5.5266e-02, -3.0946e-02,  7.6733e-02,\n",
       "          -6.2562e-02,  8.8645e-02,  1.4065e-02,  1.2202e-02, -1.3598e-02,\n",
       "           5.7762e-02, -5.9006e-02,  7.8954e-02,  3.4596e-02,  1.0667e-01,\n",
       "           3.1955e-02,  9.7381e-02, -2.9386e-02, -6.3983e-02,  1.1778e-02,\n",
       "           4.6166e-02, -5.6063e-02,  8.4528e-03, -1.9790e-02, -2.6810e-02,\n",
       "           2.0825e-02,  6.4371e-02,  4.5211e-02,  4.1211e-02, -3.5133e-03,\n",
       "          -1.0015e-01,  8.2125e-02, -7.7954e-02, -6.2507e-02,  7.1349e-02,\n",
       "           4.9507e-02,  9.9202e-02,  2.8033e-02, -8.6350e-02, -6.4850e-02,\n",
       "           6.3768e-02,  2.9349e-02,  1.9289e-02, -2.7875e-02, -9.3744e-02,\n",
       "           7.2152e-02, -9.6252e-02,  5.7357e-02, -1.6192e-02, -1.7359e-02,\n",
       "          -1.0121e-01,  5.9265e-02,  6.3001e-04,  8.8132e-02,  2.9540e-02,\n",
       "           4.2117e-03, -1.9464e-02, -8.8252e-02, -2.6295e-02],\n",
       "         [ 1.8391e-02, -8.8715e-02,  1.0830e-01, -1.6493e-02,  8.1463e-02,\n",
       "          -8.5146e-02,  5.3596e-02,  1.0751e-01, -3.2042e-02, -1.1753e-02,\n",
       "          -1.4572e-03,  7.6193e-02,  4.6544e-02,  6.1691e-02, -9.5896e-02,\n",
       "           9.0509e-03, -4.7000e-02,  3.3188e-02, -6.3493e-02,  7.5243e-02,\n",
       "          -8.8240e-02, -7.7111e-02,  9.9434e-02,  3.1790e-02,  4.4317e-02,\n",
       "           9.1715e-02, -3.4997e-03, -3.1550e-02, -1.9661e-02, -1.0065e-01,\n",
       "           2.4107e-02,  1.9480e-02, -1.2023e-02,  1.0590e-01, -1.3442e-02,\n",
       "          -4.4965e-02, -9.2721e-02, -1.9616e-02,  1.0523e-01, -8.0834e-02,\n",
       "           1.0189e-01, -9.2507e-02, -5.0330e-02,  1.0666e-01, -1.2121e-02,\n",
       "           4.8981e-02, -1.8661e-02,  1.5877e-02,  9.2737e-03, -9.1709e-02,\n",
       "           9.1289e-02, -4.8634e-02, -1.0116e-01, -5.6269e-02,  6.7687e-03,\n",
       "           8.2345e-03, -8.9448e-02,  1.1936e-02, -6.2071e-02, -1.1753e-03,\n",
       "           6.5258e-02,  4.3018e-02,  8.8777e-02,  9.0500e-02, -8.0602e-02,\n",
       "          -6.1172e-02,  2.7465e-02, -7.2513e-02,  5.2423e-02, -6.9472e-02,\n",
       "          -2.0346e-02,  1.1280e-02, -1.0038e-01,  3.3842e-02, -2.2306e-02,\n",
       "          -4.4038e-02, -1.6887e-03, -1.8865e-02, -9.4898e-02, -6.2127e-02,\n",
       "           4.3937e-02, -1.9065e-02,  8.4172e-02,  2.2195e-02],\n",
       "         [-5.2950e-02, -7.8314e-02,  3.4961e-02,  5.1324e-02, -3.5925e-02,\n",
       "           9.5326e-02,  9.3310e-02, -5.2764e-03,  2.0867e-03,  1.9864e-02,\n",
       "           4.6179e-02,  5.6199e-02,  3.5045e-02, -9.4480e-02,  3.3300e-02,\n",
       "          -4.1561e-02, -3.6381e-02,  6.5066e-02,  3.4312e-02, -5.1597e-02,\n",
       "          -1.7743e-02,  4.3955e-03,  7.9888e-02,  7.2104e-02,  8.4464e-02,\n",
       "           2.0932e-02,  5.2501e-02, -1.2182e-02, -3.8258e-02,  8.9967e-02,\n",
       "          -8.8679e-02, -9.4639e-02,  4.4629e-02, -6.6730e-02, -2.1572e-02,\n",
       "          -1.6268e-02, -4.3135e-02,  7.7435e-02, -2.5762e-02, -9.0533e-03,\n",
       "          -7.6210e-02,  5.8971e-02,  5.1196e-02,  4.8812e-02, -1.0201e-01,\n",
       "          -2.5298e-02,  5.9076e-02, -4.8079e-04, -6.6993e-02, -1.6946e-02,\n",
       "          -6.6879e-02,  4.2864e-02, -6.9516e-02,  7.9694e-02, -7.3207e-03,\n",
       "           4.4930e-02,  9.0680e-03,  7.7129e-02, -9.3400e-02,  7.5584e-02,\n",
       "           4.0523e-02,  6.1011e-02, -4.3119e-02,  2.0370e-02,  4.1596e-02,\n",
       "          -5.7682e-02, -8.0439e-02, -1.8839e-03, -5.1417e-02, -3.8789e-02,\n",
       "           5.2363e-02, -8.0564e-02, -8.7909e-02,  1.5393e-02, -5.2487e-02,\n",
       "           9.8718e-02,  2.1108e-02,  6.8429e-02,  3.5981e-02, -1.0793e-01,\n",
       "          -4.3157e-02, -9.7418e-02, -9.3391e-02, -4.1320e-02],\n",
       "         [-4.8369e-02,  1.0536e-01, -8.6245e-02, -3.8817e-02,  9.5102e-02,\n",
       "           3.4587e-02, -6.2847e-02,  1.0237e-01, -9.7050e-02, -9.2000e-02,\n",
       "          -1.7028e-02, -4.3520e-02,  4.5756e-02,  6.3733e-02, -9.8057e-02,\n",
       "           6.6173e-02, -3.0368e-02,  2.9811e-02, -2.0812e-02,  9.4994e-03,\n",
       "          -2.7319e-03, -6.4039e-02, -2.3647e-02, -1.0738e-01,  1.4213e-02,\n",
       "          -2.7082e-02,  2.0421e-03,  3.2480e-02,  2.2629e-03,  6.7076e-02,\n",
       "           7.3873e-02, -1.8039e-02, -6.8881e-02,  2.7730e-02, -5.8673e-02,\n",
       "           7.9415e-02, -1.7914e-02, -1.0455e-01,  6.0234e-02, -2.2588e-02,\n",
       "           8.0195e-02, -6.6958e-02, -1.8439e-02, -3.2383e-02,  9.0794e-02,\n",
       "           1.0521e-01, -5.5895e-02,  7.8505e-02, -6.3715e-02, -9.6810e-02,\n",
       "           4.1508e-02,  7.3770e-02, -1.1686e-02, -2.3164e-02,  5.0300e-03,\n",
       "           3.2547e-02,  1.0188e-02,  9.0333e-02, -8.8786e-03, -9.7072e-02,\n",
       "          -1.0096e-01, -5.5323e-02,  5.5019e-02, -9.3221e-02,  5.6459e-02,\n",
       "          -6.9756e-02, -4.8363e-02, -2.2039e-02, -4.3112e-02, -9.0672e-02,\n",
       "          -4.2034e-02, -5.2281e-02,  5.1083e-02,  9.5876e-02,  2.1687e-03,\n",
       "           6.8286e-02,  8.9094e-02,  2.8003e-02, -3.8652e-03,  9.9632e-02,\n",
       "          -2.5917e-02, -5.4809e-03, -5.2130e-02, -6.6744e-02],\n",
       "         [-5.6614e-02, -7.4746e-02, -1.9168e-02, -2.0895e-02,  2.7569e-02,\n",
       "          -9.3548e-02, -8.5227e-02,  3.4705e-03,  5.9150e-02,  8.7670e-02,\n",
       "          -6.6330e-02,  3.6895e-02,  4.1939e-02,  2.5958e-02, -1.9840e-02,\n",
       "          -9.1629e-02, -6.9388e-02, -7.0818e-02,  8.7928e-02, -6.2827e-02,\n",
       "           5.1205e-02,  5.7799e-02, -4.4447e-02, -9.0482e-02, -5.3692e-02,\n",
       "          -8.9813e-02,  3.7867e-02, -4.9197e-02,  9.8756e-02,  3.8474e-02,\n",
       "           3.1408e-03, -4.0083e-02, -3.5042e-02, -9.1161e-02,  7.7862e-02,\n",
       "           8.4348e-02, -2.6935e-02, -5.3951e-03, -8.9932e-02, -2.6386e-02,\n",
       "           4.0589e-02,  8.0740e-02,  9.8063e-02,  8.9354e-02, -3.8232e-02,\n",
       "           2.1150e-02, -6.1736e-02, -6.7244e-02,  2.4530e-02, -6.8627e-02,\n",
       "          -2.9529e-02, -4.1388e-03, -9.6257e-02, -1.0752e-01,  1.0898e-02,\n",
       "           4.7047e-02,  1.0894e-01,  5.4280e-02,  7.2350e-02,  9.0557e-02,\n",
       "           1.0478e-01, -4.2303e-02,  2.1031e-03,  6.0066e-02,  1.9577e-02,\n",
       "           2.6306e-02,  4.9684e-03, -6.7448e-02, -1.0171e-01, -1.0546e-03,\n",
       "           2.1576e-02, -1.2149e-02,  8.8664e-02,  7.6305e-03,  1.8351e-02,\n",
       "          -1.9650e-02,  3.5120e-02,  3.7435e-02,  7.4893e-02,  7.2678e-02,\n",
       "          -8.4293e-02,  5.9953e-02,  8.7291e-02,  5.2177e-02],\n",
       "         [-6.7438e-02,  1.0572e-01,  9.8764e-03,  2.9686e-02,  8.5882e-02,\n",
       "          -2.8908e-02,  9.2932e-02,  6.3082e-02,  5.8963e-02, -6.5558e-02,\n",
       "          -8.5089e-02,  2.0406e-03, -1.4812e-02, -6.0931e-02,  6.5314e-02,\n",
       "           1.0688e-02, -8.4089e-02,  6.9356e-02,  1.0655e-01,  7.9482e-02,\n",
       "           2.6835e-02, -9.1708e-02,  9.3114e-02,  6.6377e-02, -5.9897e-02,\n",
       "           8.5362e-02, -5.7642e-02, -2.7873e-02,  1.0137e-01,  4.9767e-02,\n",
       "          -6.2788e-02,  2.8014e-02, -5.1206e-02, -3.7316e-02,  7.9190e-03,\n",
       "           6.4699e-02, -9.7783e-02, -7.6092e-02, -5.0980e-02,  1.0330e-02,\n",
       "           1.6876e-02,  8.8380e-02, -2.0583e-02, -8.6538e-02,  2.0815e-02,\n",
       "           3.7040e-02, -6.0141e-02,  3.0331e-02,  3.7953e-02, -1.6102e-02,\n",
       "           9.2513e-03,  8.3211e-02, -2.2993e-02,  8.0281e-02,  1.0394e-01,\n",
       "          -4.6456e-02, -2.9503e-02,  9.2203e-02,  1.6465e-02, -8.0580e-02,\n",
       "           2.4731e-02, -3.6463e-02,  6.7385e-02,  2.6044e-02,  3.9683e-02,\n",
       "           6.2882e-02,  5.0262e-05, -4.3689e-02,  8.4745e-02,  3.5989e-02,\n",
       "          -1.0103e-01, -8.2279e-02,  9.3759e-02,  6.1091e-02, -1.3357e-02,\n",
       "          -2.7223e-02, -1.0313e-01, -4.1304e-02,  3.6326e-03,  1.0650e-02,\n",
       "           4.5726e-02,  4.8171e-02, -3.0646e-03, -8.2409e-02]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0151,  0.0046,  0.0671,  0.0669,  0.0528,  0.0052, -0.0330,  0.0811,\n",
       "         -0.0213,  0.0367], requires_grad=True)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0743, -0.0684, -0.0404,  0.1276,  0.0089, -0.1240,  0.0720, -0.0330,\n",
      "         -0.1403,  0.0009]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.7660, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Pass tensor throught the network\n",
    "input = torch.randn(1,1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)\n",
    "\n",
    "# Zero gradient buffer of all parameters and backprops with random gradient \n",
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))\n",
    "\n",
    "# Calculating loss\n",
    "output = net(input)\n",
    "target = torch.randn(10)\n",
    "target = target.view(1, -1)\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(output, target)\n",
    "print(loss)\n",
    "\n",
    "# Backprop\n",
    "#loss.backward()\n",
    "print(loss.grad_fn)\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU\n",
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "loss.backward()\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.305\n",
      "[1,  4000] loss: 2.304\n",
      "[1,  6000] loss: 2.304\n",
      "[1,  8000] loss: 2.304\n",
      "[1, 10000] loss: 2.305\n",
      "[1, 12000] loss: 2.304\n",
      "[2,  2000] loss: 2.304\n",
      "[2,  4000] loss: 2.305\n",
      "[2,  6000] loss: 2.304\n",
      "[2,  8000] loss: 2.304\n",
      "[2, 10000] loss: 2.305\n",
      "[2, 12000] loss: 2.304\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 | Iteration : 10 | Training Loss : 10.0\n",
      "Epoch : 1 | Iteration : 20 | Training Loss : 10.0\n",
      "Epoch : 1 | Iteration : 30 | Training Loss : 10.0\n",
      "Epoch : 1 | Iteration : 40 | Training Loss : 10.0\n",
      "Epoch : 1 | Iteration : 50 | Training Loss : 10.0\n",
      "Epoch : 1 | Iteration : 60 | Training Loss : 10.0\n",
      "Epoch : 1 | Iteration : 70 | Training Loss : 10.0\n",
      "Epoch : 1 | Iteration : 80 | Training Loss : 10.0\n",
      "Epoch : 1 | Iteration : 90 | Training Loss : 10.0\n",
      "Epoch : 1 | Iteration : 100 | Training Loss : 10.0\n",
      "Epoch : 1 | Training Loss : 9.9 | Validation Loss : 10.0 \n",
      "Epoch : 2 | Iteration : 10 | Training Loss : 10.0\n",
      "Epoch : 2 | Iteration : 20 | Training Loss : 10.0\n",
      "Epoch : 2 | Iteration : 30 | Training Loss : 10.0\n",
      "Epoch : 2 | Iteration : 40 | Training Loss : 10.0\n",
      "Epoch : 2 | Iteration : 50 | Training Loss : 10.0\n",
      "Epoch : 2 | Iteration : 60 | Training Loss : 10.0\n",
      "Epoch : 2 | Iteration : 70 | Training Loss : 10.0\n",
      "Epoch : 2 | Iteration : 80 | Training Loss : 10.0\n",
      "Epoch : 2 | Iteration : 90 | Training Loss : 10.0\n",
      "Epoch : 2 | Iteration : 100 | Training Loss : 10.0\n",
      "Epoch : 2 | Training Loss : 9.9 | Validation Loss : 10.0 \n",
      "Epoch : 3 | Iteration : 10 | Training Loss : 10.0\n",
      "Epoch : 3 | Iteration : 20 | Training Loss : 10.0\n",
      "Epoch : 3 | Iteration : 30 | Training Loss : 10.0\n",
      "Epoch : 3 | Iteration : 40 | Training Loss : 10.0\n",
      "Epoch : 3 | Iteration : 50 | Training Loss : 10.0\n",
      "Epoch : 3 | Iteration : 60 | Training Loss : 10.0\n",
      "Epoch : 3 | Iteration : 70 | Training Loss : 10.0\n",
      "Epoch : 3 | Iteration : 80 | Training Loss : 10.0\n",
      "Epoch : 3 | Iteration : 90 | Training Loss : 10.0\n",
      "Epoch : 3 | Iteration : 100 | Training Loss : 10.0\n",
      "Epoch : 3 | Training Loss : 9.9 | Validation Loss : 10.0 \n",
      "Epoch : 4 | Iteration : 10 | Training Loss : 10.0\n",
      "Epoch : 4 | Iteration : 20 | Training Loss : 10.0\n",
      "Epoch : 4 | Iteration : 30 | Training Loss : 10.0\n",
      "Epoch : 4 | Iteration : 40 | Training Loss : 10.0\n",
      "Epoch : 4 | Iteration : 50 | Training Loss : 10.0\n",
      "Epoch : 4 | Iteration : 60 | Training Loss : 10.0\n",
      "Epoch : 4 | Iteration : 70 | Training Loss : 10.0\n",
      "Epoch : 4 | Iteration : 80 | Training Loss : 10.0\n",
      "Epoch : 4 | Iteration : 90 | Training Loss : 10.0\n",
      "Epoch : 4 | Iteration : 100 | Training Loss : 10.0\n",
      "Epoch : 4 | Training Loss : 9.9 | Validation Loss : 10.0 \n",
      "Epoch : 5 | Iteration : 10 | Training Loss : 10.0\n",
      "Epoch : 5 | Iteration : 20 | Training Loss : 10.0\n",
      "Epoch : 5 | Iteration : 30 | Training Loss : 10.0\n",
      "Epoch : 5 | Iteration : 40 | Training Loss : 10.0\n",
      "Epoch : 5 | Iteration : 50 | Training Loss : 10.0\n",
      "Epoch : 5 | Iteration : 60 | Training Loss : 10.0\n",
      "Epoch : 5 | Iteration : 70 | Training Loss : 10.0\n",
      "Epoch : 5 | Iteration : 80 | Training Loss : 10.0\n",
      "Epoch : 5 | Iteration : 90 | Training Loss : 10.0\n",
      "Epoch : 5 | Iteration : 100 | Training Loss : 10.0\n",
      "Epoch : 5 | Training Loss : 9.9 | Validation Loss : 10.0 \n",
      "Epoch : 6 | Iteration : 10 | Training Loss : 10.0\n",
      "Epoch : 6 | Iteration : 20 | Training Loss : 10.0\n",
      "Epoch : 6 | Iteration : 30 | Training Loss : 10.0\n",
      "Epoch : 6 | Iteration : 40 | Training Loss : 10.0\n",
      "Epoch : 6 | Iteration : 50 | Training Loss : 10.0\n",
      "Epoch : 6 | Iteration : 60 | Training Loss : 10.0\n",
      "Epoch : 6 | Iteration : 70 | Training Loss : 10.0\n",
      "Epoch : 6 | Iteration : 80 | Training Loss : 10.0\n",
      "Epoch : 6 | Iteration : 90 | Training Loss : 10.0\n",
      "Epoch : 6 | Iteration : 100 | Training Loss : 10.0\n",
      "Epoch : 6 | Training Loss : 9.9 | Validation Loss : 10.0 \n",
      "Epoch : 7 | Iteration : 10 | Training Loss : 10.0\n",
      "Epoch : 7 | Iteration : 20 | Training Loss : 10.0\n",
      "Epoch : 7 | Iteration : 30 | Training Loss : 10.0\n",
      "Epoch : 7 | Iteration : 40 | Training Loss : 10.0\n",
      "Epoch : 7 | Iteration : 50 | Training Loss : 10.0\n",
      "Epoch : 7 | Iteration : 60 | Training Loss : 10.0\n",
      "Epoch : 7 | Iteration : 70 | Training Loss : 10.0\n",
      "Epoch : 7 | Iteration : 80 | Training Loss : 10.0\n",
      "Epoch : 7 | Iteration : 90 | Training Loss : 10.0\n",
      "Epoch : 7 | Iteration : 100 | Training Loss : 10.0\n",
      "Epoch : 7 | Training Loss : 9.9 | Validation Loss : 10.0 \n",
      "Epoch : 8 | Iteration : 10 | Training Loss : 10.0\n",
      "Epoch : 8 | Iteration : 20 | Training Loss : 10.0\n",
      "Epoch : 8 | Iteration : 30 | Training Loss : 10.0\n",
      "Epoch : 8 | Iteration : 40 | Training Loss : 10.0\n",
      "Epoch : 8 | Iteration : 50 | Training Loss : 10.0\n",
      "Epoch : 8 | Iteration : 60 | Training Loss : 10.0\n",
      "Epoch : 8 | Iteration : 70 | Training Loss : 10.0\n",
      "Epoch : 8 | Iteration : 80 | Training Loss : 10.0\n",
      "Epoch : 8 | Iteration : 90 | Training Loss : 10.0\n",
      "Epoch : 8 | Iteration : 100 | Training Loss : 10.0\n",
      "Epoch : 8 | Training Loss : 9.9 | Validation Loss : 10.0 \n",
      "Epoch : 9 | Iteration : 10 | Training Loss : 10.0\n",
      "Epoch : 9 | Iteration : 20 | Training Loss : 10.0\n",
      "Epoch : 9 | Iteration : 30 | Training Loss : 10.0\n",
      "Epoch : 9 | Iteration : 40 | Training Loss : 10.0\n",
      "Epoch : 9 | Iteration : 50 | Training Loss : 10.0\n",
      "Epoch : 9 | Iteration : 60 | Training Loss : 10.0\n",
      "Epoch : 9 | Iteration : 70 | Training Loss : 10.0\n",
      "Epoch : 9 | Iteration : 80 | Training Loss : 10.0\n",
      "Epoch : 9 | Iteration : 90 | Training Loss : 10.0\n",
      "Epoch : 9 | Iteration : 100 | Training Loss : 10.0\n",
      "Epoch : 9 | Training Loss : 9.9 | Validation Loss : 10.0 \n",
      "Epoch : 10 | Iteration : 10 | Training Loss : 10.0\n",
      "Epoch : 10 | Iteration : 20 | Training Loss : 10.0\n",
      "Epoch : 10 | Iteration : 30 | Training Loss : 10.0\n",
      "Epoch : 10 | Iteration : 40 | Training Loss : 10.0\n",
      "Epoch : 10 | Iteration : 50 | Training Loss : 10.0\n",
      "Epoch : 10 | Iteration : 60 | Training Loss : 10.0\n",
      "Epoch : 10 | Iteration : 70 | Training Loss : 10.0\n",
      "Epoch : 10 | Iteration : 80 | Training Loss : 10.0\n",
      "Epoch : 10 | Iteration : 90 | Training Loss : 10.0\n",
      "Epoch : 10 | Iteration : 100 | Training Loss : 10.0\n",
      "Epoch : 10 | Training Loss : 9.9 | Validation Loss : 10.0 \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_TrainLoss = 0\n",
    "    t_m = 0\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        t_m += 1\n",
    "        total_TrainLoss += 10\n",
    "        \n",
    "        \n",
    "#     for t_m, t_item in enumerate(train_generator):\n",
    "\n",
    "#         image_3D, label = torch.tensor(t_item[0], device=device).float(), torch.tensor(t_item[1], device=device).float()\n",
    "#         output = net1(image_3D, 1)\n",
    "#         loss = criterion(output, label)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         total_TrainLoss += loss\n",
    "\n",
    "        if not (t_m+1)%10:\n",
    "            print(\"Epoch : {} | Iteration : {} | Training Loss : {}\".format(epoch+1, t_m+1, total_TrainLoss/(t_m)))\n",
    "\n",
    "        if t_m+1 == iterations:\n",
    "            total_ValidLoss = 100\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 for v_m, item in enumerate(valid_generator):\n",
    "#                     image_3D, label = torch.tensor(v_item[0], device=device).float(), torch.tensor(v_item[1], device=device).float()\n",
    "#                     output = net1(image_3D, 1)\n",
    "#                     total_ValidLoss += criterion(output, label)\n",
    "\n",
    "            print(\"Epoch : {} | Training Loss : {} | Validation Loss : {} \".format(epoch+1, total_TrainLoss/(t_m+1), total_ValidLoss/(9+1)) )                   \n",
    "            break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import png\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pydicom\n",
    "from pydicom.data import get_testdata_files\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "darkmatter_idx = []\n",
    "patient = glob.glob(\"/home/alex/Dataset2/13205/*.dcm\")\n",
    "for n, dcm_files in enumerate(patient):\n",
    "    dataset = pydicom.dcmread(dcm_files)       \t# Read dcm file\n",
    "    image = dataset.pixel_array\n",
    "    row, col = image.shape\n",
    "    dark_matter = np.sum(image == 0) / (row*col)\n",
    "    darkmatter_idx.append((dark_matter, n))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4f71853400>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsvWusbVl23/Wbc67Xfp/XfVTdquqqbpf7EcfdSjqOQ4AksgDbAjn5gJUQgQlBjVDygS9BgS9BiEBAQggJEcmIJEYibxHZQibgOEAgionb7cR2O+5XPbpu1a37Oq/9XI85Jx/GnHPvfev2w1Vd3edUrb90dM/Zd+991t5nr7HG+I//+A/lvadHjx49IvT3+gB69OhxtdAHhR49euyhDwo9evTYQx8UevTosYc+KPTo0WMPfVDo0aPHHt63oKCU+lGl1JeUUl9VSv3Z9+v39OjR4zsL9X7oFJRSBvgy8C8Bd4FfBv6Y9/43v+O/rEePHt9RvF+Zwg8BX/Xev+K9b4C/DvzE+/S7evTo8R1E9j497x3gjZ2f7wK/9xvduVClrxi9T4fSo0cPgDlnj7z3N77V/d6voPAtoZT6HPA5gIohv1f9yPfqUHr0+FDg7/m//fq3c7/3q3x4E3h+5+fnwm0J3vuf9t5/1nv/2ZzyfTqMHj16/HbxfgWFXwZeVkq9pJQqgD8K/Nz79Lt69OjxHcT7Uj547zul1J8G/nfAAH/Je//F9+N39ejR4zuL941T8N7/PPDz79fz9+jR4/1Br2js0aPHHvqg0KNHjz30QaFHjx576INCjx499tAHhR49euyhDwo9evTYQx8UevTosYc+KPTo0WMPfVDo0aPHHvqg0KNHjz30QaFHjx576INCjx499tAHhR49euyhDwo9evTYQx8UevTosYc+KPTo0WMPfVDo0aPHHvqg0KNHjz30QaFHjx576INCjx499tAHhR49euyhDwo9evTYQx8UevTosYc+KPTo0WMP72kZjFLqNWAOWKDz3n9WKXUE/A3gReA14Ce992fv7TB79Ojx3cJ3IlP4Q977z3jvPxt+/rPAL3rvXwZ+Mfzco0ePa4L3o3z4CeBnwvc/A/zh9+F39OjR433Cew0KHvg/lFK/opT6XLjtlvf+Xvj+beDW0x6olPqcUurzSqnPt9Tv8TB69OjxncJ7XTD7z3vv31RK3QR+QSn1W7v/6b33Sin/tAd6738a+GmAqTp66n169Ojx3cd7yhS892+Gfx8Afwf4IeC+UuoZgPDvg/d6kD169Pju4V0HBaXUSCk1id8D/zLwG8DPAT8V7vZTwM++14Ps0aPHdw/vpXy4BfwdpVR8nr/qvf+7SqlfBv6mUupPAq8DP/neD7NHjx7fLbzroOC9fwX49FNufwz8yHs5qB49viPQBpz9Xh/FtUOvaOxx/aDNt3e/PiC8K7zX7kOPHr997J7Uzj79JP9mJ3R4jDIGb2369xs+fjdjiL9r9+c+eOyhDwo9vvvYCQQqL771Cf0NniP2sd/x+N3HOvuNA0+Pp6IPCj2+O3ja1Zp3ntDKGPwTPz/1fnmxd7syBmU0rmnT73jyudLzt807g0SfMST0QaHHu8duKv6UK/E70von7vPk/5vxCIocNRmH53WgNT4Lj8szvNZgFD43eK1QzmMHOWbR4AFlFFiPrluwDrVc487OwVpc00q5kRfvCCDvOL4PcYDog0KPd4cnA8I3CQxAqv3T7UUO1qIHFWo0hCLHTUb43IBRuNyAVuA8PtN4o3CFxmUK5UC3DoB2LMFBz3I5nFyhW0++6NCtQ08q1MEEvVyj5guwDt80+Kb9hllIen0f0sDQB4Ue3z52Tv50lf8m3IC3Fl3IyaqKHFUU8MwNXJljqwxXymPbcYZyHpcreZxW+J2+WLZ26M5jC4038v+qVClTUM7jd+KRLRXrk5Ji7rBFxeBxRzuayX0tFBctZtFg3n6M39S4xXLvmIGnljofliDRB4Ue3xq7J4bev/Iro/HW7QWEeDuAGo9QeY4/nOK1prk1whs5oQG6gcZlAIp86VAO2lEMDuH5HLQjQ7604XYJGjEgdAONsqA7Tz3TZBtHdWZRFlymcJnC1I52JE+4Oaowdcm4yjCrBvP4Er9cYc/O9kuJD0kQeBJ9UOjxTnyDE2K3BQgSGOLPusjBGMkGjMbfuYkdl3Qj+Yg1E4PLFLrzKAddFcqAzpOtPbrbUoLleUc2b2gPSszasjkpMLULAURO8vHdDe0kpxto8oUcq8s1o7dqupFkHhFeK9YnhnzpcJkKmQfMXxyg3IB8OcE0jurVU7hcYB8+3r4PT74vEbtl0wcMfVDosY9vxMp/EyIxZgX65gluNMBXGfXJgGai0Z1c0W0hQUA4AZ8Cgqk9tlQ0E83wQUt9kDF40GGHUnZ0owzdyv2Li452nKE7j8s15aM17awkmzf43FA8WtFNK7JlhzeKbmjwBkwdA8/2WEDKFWU9myNDvlRkN6dkeYZpWuzZ2TsJyQj3RInxAUMfFHoIvsFVURkDTyHklNGowQCKHH/jCDurqEcZi2dzlHCAmNrjtcdrRXlh6QaaYm5DKdDRTAz1TFMsHOV5h9lYinkgFHMdruoWs/F0Q4NuHcWFnKCqc+j5hhxojirWxxmTr28Pv3iwIBtK27IbF5RAPTO4DEZvt2yOMoq5w2tC+QKnnxxQnZWUz0ywpaa4aFH/6Ne/+Xv2AQwMfVD4sOPJD/ZTsoLdkmE3O1AHU3yRs3pxii0lrQcJButjzeTColtPtrI0syyVCJEbKM87uts5ppbbu1FGOzKUZy0aR37RoTcdPtfSSag7sB7lJOq4SYWeb1CzknzlMIuablqhOofXGrXp8FWGWUkgKQJH0Y4NuoN2qMg24XdXCt3Jv+4kx5aS2VSDCrfebN+b+J59gNEHhQ8rniQPY1chiIJgyxnoQSXtw9kEVVXY24d0g5z1zYKuUuQrSe9N48mXDm/g1j+a43NNNymknRj4hEgKVg/WrJ8ZcPT5R6xfOqS4v8QNc6q7Na7MUa3FTkrcMCd7tMDnGfp8DkZD0+LbFgVwfEj1pbcplyswmuKxHCtFji/yFED0qiXLQ2Bzjm5aMaw76pMKEMKTjRCV7QiKuWd9bMh/8PvIHs2xX3v9Ax8MIvqg8GHE0/iBnWAAiOpv575qNsXfOKI9HNBOMrqBxmsJBKZ2uFxhC4VuEdZ/mNONMorTDd24kGChwdQOW2ouXh4JxzCpKE43YBR2mGOHOcW9S3yVY+Zi06eWa1Se7QUEv1iixiN4fIYH/Hotx9u0Uu5swmNHQ8gzlHPYoynKOdrDAc0sY/S1NeUj6CYF9cygO0954Vjd0GQbTzPRtLMCZUfoIt9yC7vZ1AewhOiDwocNOwHhm4l3VF5IhvDMTbqTcUrtlRNyMBKFXku7z2vD4GGLri3r2xXNTLiFblyga4uuLWiFai35hWf0xQvsjVn6f6wnP1ujWgtGozYtalNLENjUokgMabwKnQ4f9QVRFGUMvpFglk7gi8v0WvXlAlWVtM9PhOCcVdjKUN6b480UkNanaWBzqOkqRbbW1LMRU/d9ZI/n2Lv38E/OUzw5ZHXN0QeFDwueEgx2sSc3PjrAPX+brsrY3CzpKo0tVSDmFMo5qkdNEBxJoW4aR3Hvki//uzfI1nDjV2H02gKMQq8a3LBAr6RLoN5+zOYHnseWmureim5W4rMB+eMlWCdBYbnGL1f49Ro1GGy7HMbgg1xZFzn68AAAdzlHFQW+aUQnYaVsUEE8hbW4xRJ/ccnw752jDw/w0zHNxw65+B2HZGtP+bgmm7e0wwHjNxtcoaln8l6t7gwxJwMGmYH7j7CXl+DsVrT1AWpR9kHhw4CnKBGfFhh0kacyobkxSMRhvnSAJl9adOPwRqE6B1qRLRq6cUE2b3n4+2/gc48504zeWApBWHciXQaZW7Aed3qObu5Q3F/ic4OuLa40uDKoH1uLu3GADrxBkiXvSqOnE7AW34ZuxKCCHemyKnJ804K1EiwIwTBURfbRKXpTM1qu6Z49YnNzwPp2xfDNFe1IYVYtrijRHXjtqWcGU3uqskAfziBkKWl0Gz4wgaEPCh90PJHiPjkhGDMEMx6hDmesP35LSDcIMwQWbxTFRUt9lDM4r/FGg1boVSvlwKZj8fKM84/Dzf8PDj//Nm48QLdWTvpVgysz/DCXDsIPvEz+eEl7PJLWYmvla1WDc6jFKvEGPlzxvbUocmmDWsvbP/4C65sKs4HDr3SM/+HX4NYJPDqTTMNUKEBpjd/UcuI2jcitjZGAEkoN88qG0SvA4YzNS0ccf3HN5uYAW4pyUncite4GmuXHppSnA/JNjTs93xNwpcBwzdEHhQ8ivkGNGz+4T51OvHVCezKhHRlsoTCNpzir6SY5upF2oNdFOMlb3DBH1y1ea3xu2Bxqxm8oZr91CVqjnLQFAZloNBq9kZaiLzXqvCa7NNhxicsNZtUIkRi6BQBqMEBZi10st5lNkcPasnpWUZ9Y/MCy+rTlE79SQWdhNMQPSrhcbF94nL8IIitCBuGtk04FiBLzckF+PsKVGcVFm/QS3UBEWFERub5ZkF0eowF3ei6v0e60K695YOiDwgcVu0TYzve6yOVkCLeZowM4PmT90qHcNYPJq8skEy5O5QOuVw2TL22X9sSAYCcletMxfqsTtWJr8XmGKzMJJMZIlpDJyHM3HqCcp332MM0/ZBfSfVBryRQiseitTeUChDmKqsQ+e4MX/84Zr/2RQ9wn17T3B/zWf3GTj/+nFzAoZWS6KgGkLbmuZex6UKIuJftQg4G0NI3Gnp6jjYGLS7KHA/ygxA0LzMKzvjPCZdtsoZnI+7h5ZkyZG9RiKWUKu54OXOvA0Hs0fpDxVFOTQMDFFuTxId3RKIh1PNWpcACuzGQkedWgV7EQd/IVnys3cvU3ivyikW5ElaXMID5PNykwiyY9zlYG1VpU54SbSMe78/0uwlXYL5b4qsRVGVjPi3/7lGZRUJyHj7HWIlpqWtBavvLtdc/nRgLDdCy+DSFw6MBVqKLAPz5DrWs5PucwTShftHRb4lc9M6xvD9E3TxLR6GP2cc3RZwofJDzNfsxZdFXhmjalz946zMkR/nDK5rkpLlOUpzJO7HONN5rs0Rw3HshJ1nZgNG5Y4kO3IZqbxO9h63Hgc43PNE4r2kmObh3dLFy5jRKyMjcQHqfaDrUMrcf1JmUILhCHelDBoEINB7gqJ3/tPv/sLzzLZLbmk3/mlMWnTij+vsLfvYe+eSIahaqUABCyBACsl0CBcA3u+AA9X0rbM7Q8ldH4B49QmWw7zM8zdJPTzDJcpmhHmsEjkWh3A8XmoyeU8wXuYv50Q5lrmDH0mcIHDdrszy3sfC/OQ05S3OMD2uMR3UBjS012uUEv1ui6k/o+njxtJ+VAmCOIGYAd5HijsAMxOVk+W9INDN24wJXZXrtS2e3Eom62V1K96UKmoYUHaFrUaLifjhe5XNXzHD9foFY1vm352HMPWf/WAfULhyyeMeSPVtKB2NR45yTraDv5N34Zhd/NHKoMv1xtpztBvh9UqKZFdRblPLp15Asb1JhBlRlGtruBQY2G6PEoeUckXMOAAN9GpqCU+kvAvwo88N7/QLjtCPgbwIvAa8BPeu/PlGyG+W+BHwdWwL/tvf/C+3PoPfbwFJVivHJFIY8eVOjpBHvnJLDrmupRQ3a5wWuNOxyhV+3eyeOrnPZwgLIeb4QD0K1LTki6caxvimIxW1myixpXZdihPN5sbAoKyvmUHehNh3JO0vTlWjoEVSnWaZCCl3QKnFz1raU7HPH1/3xE8+sjnvllx1v/QsnNz3cigc5zaVFaJ4RqJBKLXMjPVY0bD+huHaBah37jgQShQErq2URKlPVGyqQixwBqNCB70GBWE1bPVsHLQYjHeqYxH79FdXeA/8pr8jqjKAyuZWD4djKFvwL86BO3/VngF733LwO/GH4G+DHg5fD1OeAvfmcOs8c3xTfQ5O8OMelBJaPNxwc0R1XwNwCzbuVkGeaYizUEj0OMwlVZ6iCozqWg4LUEBGU9rtAymrwS1WI3K5OjkrJe+IMdbwO0EmXjLn8QgpZfrqRkiFfcePwHU9Aae+eEs0+N+SPf908ZvqVpRxqXeYZvyExE1CwQOALftilI2IMx3H+EXklL1ZxeooYDef7pWDofxkjLE5KkGudQdQN5FgIZFHMxg4kmMPXMUD8zScctxjN2L1O7TviWQcF7/w+A0ydu/gngZ8L3PwP84Z3b/ycv+CXgIC6b7fHdR8wU9GyCPjnCHoyZf3xGOzIM7zdMvrqQE3w2JHsgcmCskIV2LByAHRe044x2VqSg0I0ydCMzDOtjmX7cKxFal8qE/KIRbcKTsF6kzOt6q0loIqFpt3qCIodNLfMPmw6XwV/7J7+H4tzz4Pd3FOcK9eaD7cxDDCRVJSXHYglGY84XYAzzTx2Tv/EIHzgHdzDGb2o2v+slNp9+QWYorJXHWYu/XEgpsa4x5wvKMwk8gwc15YWlvBBHp/VJjr55ItmGdU8Vh10XvFui8Zb3/l74/m1kryTAHeCNnfvdDbfd4wkopT6HZBNUDN/lYfRI+AZGKHogJ4c9mtLcGNCOtHgXVgaz0qhWam12NQWhVegzjQvzxjFl9kahW5eCgGk8ZiMCJ+XEtGTXOxGtEsdgFjV2XCZmP9X6MVOIzL0x+z4O4X6q7Tj80gbdVWyOFHjFC3/9dZmJiMFAayhy7Fv35bU//yyv/PHbeO159v+9weiNJe7sHDUowTn0cs2X/sOPYo9ajv9hwY14MgdxkyoKIUCnY/ywJLuo8abCa4UthFtIvgzTIWq+eKdi9JppF95z98F775VST9rrfzuP+2ngpwGm6ui3/fgeAd/EODV79jZ+NKC5OUkn9+GvX25LBGSMWNU2cQguGKpGDqEdG7K1SzZoBDdlZT3FWUO2MmQLUSy64HvggwszSGCJkugYEMzZEl8W6M4m5n+XXMTKohcVAhpG46sS1bTYgeHoN+a0s5Ln/vIreKNRzz3D/T9wA4DZay35ec2Df+15vIbF8+K6pJzi1X9doeoRuB9gcM/gSvgXf/xX+We/9Cwf+Vuawf/9a0nUlPZJWIcGVC56Bz8akBsVXq8iW4uTU75ybJ4ZUwF6R4n51O1VVxzvNijcV0o9472/F8qDB+H2N4Hnd+73XLitx3ca36RWjfxBe/uAbpKnK1r1QKYQPSaJj1Tb4SuphUVdKMEjcgbFhVibkSny+bYMcIVGtzL52I2Fude1FXLP6BQMYungMhEzmYu1kH61lAre7Qwu7exm0AMjASEEK9W0sKnJz2v0xYrq4QV2seSNP/NZVi90HH0B8qUnm7e4MgtuTQp3s0Z9rSJbgbk02JHjkx+/y5svzPjhZ1/jRw5+k+6HDH+//CSf+tWJ+DQ0LTbMNujxKPETqipxwxLzeI597oh8adkcZuQrCZq69XTTiuLWDfzZRSqHkuv1NckW3m1L8ueAnwrf/xTwszu3/1tK8MPAxU6Z0eN9hjLywdOHB7jpkG6Shys+lI82tEEroNpwFXQON6lwZYYdFikg7MIbtS0V1m26zWyiT2HIOKyXWYcwFwEEQlHKiCRSiqVAZ1PpoIoitUxxW1t4v1xB28kymLbDj4cyb9G0PPoDz/H2v/9Zmpln/EpGthFr94e/e0Q7yWjHivoIfKd54e/Oef7nH+FKz/MvPaQyLZ++9SZnzZDWZ5w1A4YnKy7+uY+k160Dp+GbZnulb1rM6WVaTlPPjNjMVdt9FN4o/Ehs6rimvMK305L8a8AfBE6UUneBPwf8BeBvKqX+JPA68JPh7j+PtCO/irQk/8T7cMw9wrQjkIxFYx1rTo6xtw+xAwkILtcM7q1RzotvQJhLAHDDQur/1tEelCjrMasOV5p00jtkEYvuPOvbw63pautwuYwo61bKBTvI5eSPuxgyLXbsIVDYMsecIcrDVZhNMDq0AO0ejxDh2xZlrYiRhiX3f98B65tH3PinHZcvZnQHHcvblvWtgqNfV5z80zXrmwXNFO78XxvyX/pN1GCAWyz55F9Ycv77nuMT//HXWLmCXFl+9uFn+A+e+wX+5+r38X/+7s+QLz/K4POvSOay3uxNZ3oCZwFkZ2uGBI5lJN4LXsPmOCdbFJjJGHt6HqTP16tF+S2Dgvf+j32D//qRp9zXA3/qvR5Uj2+BneWqEcoYSXWPD3G5wQ6EF1DOo+uO9nBAvumSOhFIAcFV0k1Q1idy0axaOZkRwZFyHq9zeb5GeAPdWlQr6kTdWlKTMW52MpIp+Fyh647s0WZPdqy03m5qGo/wYepwq0+wMupclbCpefSHnmXw2PF7/p1f45d+14t88ugRn569yf/y6qe58ZflBH39x2RO4uavWIovfJXmhz9F8YWvYm7d4PEfeB5vFHc3B3TO8I9/6eOMX9f8iY++TPbMivbIsj42lM/fRn35tf03uGkhmlNpLS3cRcPqhVHgXExyq3a5QWfb4JYcoa9BQIBe5nz9sDPYFA1HIHQZDqZ0swH1cYnLFYO3N8ntqLh3KWRiSN/9sBSSzvkkNAIpA/LzWurynXkFECGSrp/YAhU8E+QgtlubfKbRtU3Zg9cKNyzRq1r4gTzfeilerFG7z2kdNA1qPJIs4pkbrF6ccfN/exV3fMAX/8sfhH/zktfOj3jtr34fz/3sq1z+8JR6pvnon/sVVJGjpxOYTii/eh/30h3U40uOPv9ISo+fl32V3796BQ7EcUltauzRlMvvn7B6YcTk7Qnd/YfoQSWBa2DkWIxBAXqV0R0OGNxbM39JZkdAujTtrMBnM7I38qS7UMaJY9M14Bb6oHDdED5YrmnRhZBYZjxCTSeycyE3mGab2mPF3CSddLH1qLfzCSAnfDqhQ7Bww7ifUZOFAGHmdbo9iZJ2NApRyyC/SzIEySYCX2FkYaxyQkiyXEnbL2UIIiLCWvx6gyoKzn/nEeOvr/HTMe3JkPHrS8b/mQEM+rUv441h9L/+KmOjUbMJWCfKyBg07z/EGQ2PgPi7RkOYjsXyTWt8kaNfe4uZuy1ajSiuinxCGNkGoO1QdYPqSnl9zmNqkilNWnlnDNBun+MaBATog8L1QuAS4qo2CQy5fMCNjDHbypDNJXvIHl7iB6UMH9UdKs/S1doN8yRTjuWAN/KlawvOY1YN3bTCFTotXWlujWT5itH4XLIQF7kEwlCU82l6shsXQkLWXWiFBpJRa5lTCCd+PHFc02LGBf6l5+kOB3ijmPytX0b/zu9HXS4olyIuoiqFfIwBxFp0yCwiN+HC91Fp6JsWF7wZ3KNTsXIzEhB8nqGrEt58kCTO2Ueew969h55NsI8eY6aSVWAtbjaUkqnMqE5lZ8X8hQrTeGypMbWW57ePk2T7unQh+oGoawa/27aLDHeRizIvkzZifVySLTuR9raS2qtu23GILUhlt12B+G+2aJK/YVQ1mrUNXQxNNm/kyp9pESG1btuehNSNaI+qkK08wX5EoxPn8M5JlhCdmBFuxF5eoh6ekn3hy+S//CXMjePt6x8NtgGhbWG9gRAcfdNsr8pseZatBkJLEC1yGZ6yVgJAkDL78TAFBH9xiX98JhqKYBjrmyYRjXrVyMr7VYstxYwltibjMJgflNeyA9EHheuC3cnHHajxiO7WAc3JEF13uEIzeHuFudjs3c9nJnkhqNaiV+K8bIcZ3UgGmLzZqg/T/EJoJ0YuwRsh2WQWQr7XjUtj1LEdmc2b9PjIOahgz+amQ9Eq5HEjdbHXTVF5gb+4DFf5QoRDbcgOzi8loCxXoTvQJJdnt1wm89YYCPx6nXgBtyuQClbxEDQQIGPW0VthMMCtN2nnhTmRwOSd2zo5hddj6ui5oHAZyejWD0vhRXbFS1c8S4A+KFxLpMBgjDD4uRH1YWgrxhpf1y2+LOTnPEuOSGKhplFWOg7ZUk5ab7ZKRAh6BudT5hBPeJdrukm+03IMPEJ8bLhffFwyXQlXWaxPvf6UOYSUP6baEA1bG9zBZHtMWu8ZvYCQrBiDmU6DrmCrSNz9XrKE0EKIRO2gDE8Sj82m548BIUmow7CUDzslMEr2VZSaZpaJsW3YVxml4krr/UCwM9p+VdEHheuAxCVsV7yb8Uhq45uH4QqlyM9r0RcYmUKUTUtbFWJ0VW5PhiEbyGQGYt2m4GBWjbTUaptaknIM75yHcEEpmTgDrehGknnEQCB3DK3OYS6DUG2XzFlFxmxS6p9W2BcFajZFjUcyFn3voZRCVSmBZGfLtVtvmP/oD2A/sRUfRXmxHo9ELm20BIQdfwZVlXB2IVlL027TfaO3sw+DgVjKBy0F1m4znFbI2eKipbjoWB9nVGfyfuvWy/tdlai8SIYx1yFT6InG6wBnw5DQzgbkSJ6FE704k/mD2P5LV2VAL9eSshsVNAVbHiGft3LlNgricuXQNXBlmIfIsnR/3dq9qcf0O03IGkIHgzAMlWYgQjYROQ3VlCKx3mz2SMaUBTWNdEyKXE7IkNZjrdT+y9VeR2D6G4/h8Rnq8AB3OQ/PIdmGnk72dB2qqiRzygxUh1JKZEZmG3Y3TAcSUw+qd84vtF0wqPW0I3FlKi9s6kB0A3kvYkaUXtcVzxKgDwpXH0/4K8ZsQU3GsKlxuZErtlHkj1ZyvyqTJSy1fMDdaIDatNhxuT1pQcjB4J1gNjbVyPEKiPOJYVdBwhwDRZQ/R52DN4ps3pJfNMkzIQYGW5mUTUTyUkO4IjuxWkNq+3QCWiu3VyW+udgbi+Zykfwi1WiImU7wj88k49jUqURQRSEmKm2QUh8f4ldrCUSDmXAJTYsfDyUgbDYpY/HWoXeWy+qZlDAxS/ClOFurTUd+XtMelMyfyzn+1Uua759IF2KYo9pB+vulDsQVR18+XCOonfrbr9ZyxSTOHYQRaEDPN+gHZ8LQV3kaejKLWkqFcKILqeioTwbCHQTpss9NOtmlwxDq82z7cXGF3rYhgxpyLxiEgNBOtp2OqH9QzuOmQ9xkJAYn0bU5kHJqPEKfHMN6g33rvrRcrcVfzlNm4ddr6bqcnaeUXlUl6mCKGg1DMAklidYQrNpUVaImY1Tm034jAAAgAElEQVRncQdj3PEBarHaKwsIbczERRwdbP0aIsnoXGrtxmzt4CsbFh8d4zU0E42ttmv5lLk+p9r1OdIPI57oOLimlWUu1sLxAW48CLMHog2Icw0+z/DTsZiDtBY7G6QrdDzpCW0zG7wXdStchJnX4bkkE5AswYnvAlseAYRIdLnec2VSYbFLDCC7dmzp9+ttKSF32vUwaLcBICxvEcv3QBjaMEQVlsLok2PpRCB27rFV6dsWNajonr8hJcjtY+EjtMaNBtiDMertx+jHQeQUWqS78E0rnETwaJBjdKlr4XOZ/HS5xgaeZfh2ndSN8TWqQKDu/i2vMvry4RrAtw0qL/aEOGpdo4F2PEoeiz7XsOjQ63qbmrcdUGIuNthJmaTIurVki20WoFdNWuwSNQfl649F64D4LCjnk3Apm7di3b6xSR/htUI7jwtXTluZtGbOFRqTFJBhhZz2QsQRGH0TfBmrChdGl6OOYbcrYRdLkXXHrUxF8Ga8XOBuH+O1lqv4pCK7fy5BZFVjD8Yis/76W2lJLSDZx+77vaNriB2QKHRyB2Mxjw3vlauErNWdZ3MiAbaYi14hTZJCGAevYHfq8oqizxSuMtz+h2r//xzqcpl+FDcjL6z+ZoO7/xA/HYmZySqQZ5En2NEN1LdGwgmksiGYqW46kf6u6v0MwujUaoxaBJDywKxbyQL0jtQZklNTN8q2WoUqk9S7ysVAJexgwBh8WBargpcBxHrc4RbLtKdBygMn6X6ew8FUgtpiLRZsD6Wz4C7nqDD2nLwYKxmc8tH5KXAUcXntbrq/JQllF6YfCkkaORuvt9Jml8nSGN0F8ja2h59GVl5R9JnCVUYckX7CvUcfHuBHA1yZh3VumvakkoWt07EMPd25CV9/W9LvcPVUrcUOc7KFpZ2VqGFO8VDUhD43ezMMGIUdDjCLGj3fyH5GK9OSatPRHQ5wpbQuYwjoxgUmBKBmlmMahx0YsmWXBq0ikenKTJ4v8hWhVUjThE6DS7sUknLTOlSR49Ybsls3ZJx6vkiyZ7Vcox88FnLxkagRMUYERGHrFMuVSJs3mzD5mAvfEDgFf3GJLmSQKWYjwNZopcihZWsVrxXFWUNzWNBMxOoubpFKRrfW4pcNejS6Fsti+kzhiuMdBFWsfwN/ED0Ws3mDXq7TgI/atHAzqPBycVpyZZbakQDtWLoU7VEVnluFwFGIqWrrUOsaNyzFSi0EBDsJZi3BWMVWhm6UYVZtakfqzlO+tZD7rNqkbbCVSapJaXuK3ZpchWVLU9QK7AmQ4jKb3attlHDnuTgdhVakb9utOKlp5OQPcmi/3iQL95RphAEpdzlPQcCMR+lYUnDRWoJjLC+ia5SVQCBlA+gumtLYRP5eh1ZkRB8UriJ2VG+7V5ZdQ1Cfm0QeEtp9bjTA3pht3Y2aFg6mmIcXdLNBsEPb4HJDM83I1pbVHelgNGFWwZU52elSroRGieNxJWSjnm8S066cJ7uUWtysZCAo/p9uLcXpRjwHVh3drMSsOrzR5KcbsrN1ynBUWNqikhvzjr5iUKW027fNdghsUOE3tQSBw5k8blBtrd0XS1n8uiNC8nH/Q3wPQ5cjci/u0enOGvtie9+qTHwCRY4rc9x0mNbjxdJs/PU1m0OdNnYrty2XYMd7MqyYu8rog8JVxBNcQjIRfQpzHT90AKpuMI/nW8nujv+ismFzdG7Y3JSrvi1FcNSOpSPQTXLqW0N8lUs2YKWjoaP7cvh9ykq3Q8xLhZhU1sux2ChW0ju/1+4MWRUp0/C53itZkoR5dxN0eN1CtOo9JyOKXJSIl3PJBpoWF92Swt6GKIjafe/Se2ojnxDW1AVNAjvPT5GL0tE6fFWKdDw3iZiV12FYvDBAd0HJGJyv9/ZdhOe9Drsg+qBwxaGLPPkFRqiqTISgnZRJS6DC8hI3FOdjrFy97Vv3JV1/fIkdF+QLS7aWfQW69bhMUc+MmJDO5UOfXazRi7VIkqNWIdism0WNmdfynBtRPnqj0Ks2LIORerubFLQHZRA3adE9BGfnFAyMDA75QSkiooOp7GwYDeWkDx0XZbRsio7dl6A3sG/d3+oHgrYgejJErwkXBqf8eiPS6ThoVZXymGCwqsejMEchHRBuHguP0bSpbPBaC6cyG7B8cSxy8lxTXkhgrM5scr426+0cBbBf+lxh9EHhquFpV5GoYnzCDNQbLVuL6m0XwE1GANijaSDnPHo2wTye40fiT2BLHRyeRWSzvCXbopqJCmm9yKTdTLIGr7XskgzOTbFMcLmRmtl5zKrFzqqkmQDIL2rJIKKdvJXpS9Va2T4VyM3U3psNpQW6exWH7VBS5BiaBj8d4+eLpDSMnAFsM4x49Y+di3S/KBFv2+1jgu6BMFxFHgbH2hZf5LjJSNbah8CYv3XK9Atv4cqM1a2CzaGhOrM0E522Rz25BOe6aBX67sNVw85SF13kuM0msdZ7lmUhbe9mJXkU3YQMwrN1NjKnl7QvPyfLXN94m7zKyS40l0GKm20806+Le5C/UMxfkqCSrT3lWYPZdLhhRna6RG1qSaEvVzIrMMxRmw4Vx6XPVmG3gzgt2UGedApRy6C6nY3TLmyjGkgXxZwt5WrctsGARTojcegJIyPNFDn+9bvb6cVgqJJ2Z663uoNt6SV+kJ4WHW6P9zOzqSggXSAdq0q4lGHYJbmu8cMSlweJdt1KkKgkA8o2Mm8SV/HJpOT+n3V34/dVb032QeGqYSdTcE0r3gI7vXNVldLXD2292AJUqxrVWXxm0DHl1RraTtaktS32o8+KRbq1HHzhAfZwxOrOENM42pFBtz4N9USPgM1zE6p7C3CO9tkjgFA6SOfDDfNEtkXiUzmHM9sOw66js7IOryWgeS0mp1F6TXSG2lkMq6LOoMhFVLRey1ckXJsWTBhaaprAIei9q/JuB8e3DYxHW71D7FCA/L7JWIhEreV1HR/Ic1mPQv5NbdXAw9hCJQ4hX4lWIUKF5bXRJes6oC8frglS1yFIercbnnw6oXxmwqBOhi9y7MEYdzyFPEMNB2QPLwNH0EGekT28ZPCgpngoFvCxlSYnq2Z1uxRRjvWgNevblSgic9EM2HEhbctQUkQp9O6Epqys3+koxOUwuQktUgkOsq4uEI/WJlGRX64SEbiLXdWh/NyksiFNkrLrVCWKSD3aEUQFvkFaj1q8KTI54aNXQiyVEkworcocO8y3K/a0ZFftUMkG7rXMkhBEWVe9ZNhFHxSuIpx9B2MeiTaeuSkdhV2D1HBV7E4m+CpDL9eyJ3FVi17BOfEhjIYiQDcb4KZDmllOe1QxuLemON3s7YEszztR5lUZ6nKBLYRMbG4M6I5GYiPfWrpDaWu6KhOxU92mbkdi4IOaMs5amLkYlbgyS/sro6LS3TyE4wMhHY8P08muB5UQhOHn3TFnFzoPT16N9/YuWJfKDDMegXVi9XZyCIcz/HSMG8ucSDcusMMCfb6QIFuFy3/osvhcs3ymkCwqYPGsSR6N+UIIWj/f/r+3TiTrVzxAfMugoJT6S0qpB0qp39i57T9RSr2plPon4evHd/7vP1JKfVUp9SWl1L/yfh34BxKxdNBmpwa1STwjhJsIk9rDsEZ9pyWZXQSvw2isYvSeMelWD6DJLmSFXHHWCCEYWozZspO18o3DbILeIDfY28fJQCSby0lfnG72jsGsGiEMhyGD2HTJuUmESmbr3jTMk0NRLC98LoSjWskAFJtavkK3IL4PW1FT3PsoY856PAJjQrdG70uVgzejCd2HdHueJ/9KeRESFKPIK2ZmUdRFGvxyTL+2pD0c0Ew0OrzlXitZDBOD9q4/Q/jb+nbfOv+q4dvJFP4K8KNPuf2/8d5/Jnz9PIBS6lPAHwV+R3jMf6+Uutph8YoiTkTuXVWCeKa9OZHtxzHljmg7Wdd+MBFirBS5sC/Dhzk4KMf7ujInf/sc8/YZetVQfPUe2dma/NGK8vXHYZJS6v+Hv2dKNm/ZPDMUX8dJgR3krF6cSjYQ/R1XtdTbw1z4hjCT4XJDfrZOBGM0NwX2dk+o1tKdTESA9QTUQAalIkGodroy0ak5eTNGodNYiFMf1tMlPUKRw8mhdGSKXDKE2QA7yMVv0nkRcd25KaSt9Zh5GISqsjQgtjnOKeYOUzt0B/nSiYFrrtGPz6WsiccZl9xcd52C9/4fAKff5vP9BPDXvfe19/5VZH3cD72H4/twQ5ukYlRx6MeowODr7e7HXf9Do9DzJWpVY04vUcud2QYQMm25xg9L7HjbuvNai06g7dDnc9xogFnJFa2JMuhwlW/HYppSH+Vka0s3lvVzrsywh6NtOWDCAFF4nB0WQegUfBvCa2lmeXotdlzKfRYr3PGBzHJE+zXYnliwRyjuDjH5MCOhixx7cSmHPh4JoWgMejZJ7kvE/ROQ9BW67uQYJxVq06ZAEKE2kvVIliNcQkQ3UNgi8AzRrTryIbszLFc4MLwXTuFPK6V+LZQXh+G2O8AbO/e5G27r8a2gd/mD/e/1oBLXoKmMMeuNLFgp3jxHL9Z7+yH1ZUh3Oytlw3QUZiKkdPBFLstPtE4LY6nK5OXo794Do4WXsJ78jUesjzMOv1xjLjZUD9aY2sv6+Uw8F9qxGLa4QtJ/O8hFyrzpRI9gthbwInSS4SrdiJApn3fCZ8TAZT3u+ECOAbatx1xatNEAJXYaYuaQgsEO92Bm05Qt6EPhKfa0HmUh/Eo46eMyHFliY0MJpmRqtMrQdYudlOja0k0KWUVfivajOpO/wejuRriG9Ubs6nc7JRFXWOr8boPCXwQ+BnwGuAf817/dJ1BKfU4p9Xml1Odb6nd5GB986KjpRybzXBhuAqSr0FkRL8U2pAsjwIXUyj6Xjc0qrosri8Swq9bS3j7AD2TCEK3h+17YehaGQFPPxOpNL9foixXF6QY939BMdFggI+Yr+YWUDmbdyjEZhd50yXBl1xU6DkXBtiORsovI/O/sY8Q6/HSMOTzcMbE1ezLmaOXugzNT/Hf7HFbcl/IcdzCROYbhVgYeiVO96VInJHVEjEqirmgis7qZS0Aoth0I3clzqU27Xf7C/gzLVce7Cgre+/vee+u9d8D/wLZEeBN4fueuz4XbnvYcP+29/6z3/rM55dPu8qHDHn/gtkIcNRnT3ZjSHYrTkhsWEhjaTuTBZWjFHYylRh5JfeyLXK7Mo+C8pLWcrDtW69npUgaCDib4PEO9+iYUOe3tGbQd9saBiJvC71KdGLf6KsfUclIPv76keuVROqn1qqF+4VBGroHi7mlycNIr8VxwhaYbBb/H0J4ExMJtFmYjwutiOoaTQ9SmFvs2YzAnR+ijgzDNmCf/Qz2boMKEozIGNQu7IqNfQ5HTfuRG4jx8bugmOe1BKUKr3OysuFNJwQihrAjf24Fh+rUlzUTTDRT1TDZPR30HhMzAbcVTT/5tryreVVBQSj2z8+MfAWJn4ueAP6qUKpVSLwEvA//4vR3ihwTO7ivdoqpxPJIrvNkuctWh1ledfXrpcLmQ+4bHYTTmQtqUqgszEkbJPsSmTT9jFDx3G7TGLBrxMRzmjH7tLWmDxgwkOA+lQ61b3GggYp9wNVXWJ88BezxJvf94ZQbxdtzdM2EHJvkaujLbtl3zTOYjRgNxURpJC5SDKepwhj452gaCHZ9FjJF9kdOxWOGPhxI0Q6biAi+jrGzShq1ZjRyQD0Eik5KmzPBVTjcuaEeG9TPSAcrWnmIeBr7K4EMZS4WdTOGqKxkjvqWiUSn114A/CJwope4Cfw74g0qpzwAeeA349wC8919USv1N4DeBDvhT3vvr8U5cMZjZVCzJrBUFo3Ui9qllGCd/+1zUi/Ol8ARBsBR3I6hVLQKli7W0+ayTTEJrXJWRvXIPpTX29jH6rYdytW1EXixeBIru9buoG1PcwQR9uaK9fYDedJiH5zAe0EwUk6/bNMOwenFKcdGyfmFCtrLYWUX24FJO6DITu7ZQqyfPyGjU4jzZ3O3oGYLoaVySna2Cw7SGsWyXiqPhsUziONBam1rs3abjdL/0ug9HSUiVPCV3ZjOSrsJ6zOklvirxJk9+FN5oIUJri2635U+2EdFStgnPs2pEpr0z6r7bYr7q+yS/ZVDw3v+xp9z8P36T+/954M+/l4P6UGLPyt0m6a0aDZOhaJxEBIQnIDgWQRIwRYKRaMRSN9jZAB18C8WFWMN0vDVqqWQtvRCTQ/SDM1xuyD7xMThbivZ/UJI9mtOdTLAv3WT+Qkm22R/6ydaW7GyN6kraWUG2aOhOJqJfCMNbrsogzj4kc1iDWbWpayF7J6Ruj/6T0QCGoLcgz6CzwpGUSFpv9I4jVZhobLtUnuiV+EpCdJcW+/k8LOT1RmMulkkRqjZiMLMrFNN1R3NUJQVoM1WM37J4bWQhz9Il89i4kEYCwE4X4goHBOgVjVcHqfY0yYMwORlrHcoHm7wU/aCUicLLBXHDkbpc4FdSJhBNUsqC/K1TubpDmi+IvILatNgbs9B2y2XY6XBK9mgugebsQgRTi5WUFUGJuLqlmXy9xjy8kHKiyigeraQ80Iry/ormqJJx6U0rS2RWtXROrEtWbHZgkmt09I+MuyztwIiH5KRk88yY7nCIK3PJPMJOyljzR98I2YoVshej6E7G21HuWZnKBG+UWNMHmXgkGGPnxZdFmjg1bz5i89xULNeOKlym0J2nnhkOvtqyeDZHOWTAbG0lc2nawHUY9Gi0zylc4XYk9ANRVwsuKvbCVR9Q0zHeObpJjllb8TiIg0+LNf7GkWxMzoyQadkTH7idujz2483pJfZoinJuqx1wDpfLvIQ5X2y7GE2LP5TBJNW08PiM1/+N7xcZ9OuP5Yq6WKHDqLErM8yiobkxSGm5nQ1QraM7GpGdLmmemW79C7VKm6fsIJfR6pDS5+c1NgQZ3YogiNgtCLV/czLEG1mZR9hl8eTIcjeS0sVsbPieZKxqwoYpXXdgvZQHOgSGzKBaGZ/Olh22Mum4VzcyygtHN9CSHSAGK2bVSaawa9rypICxzxR6fNsI8mY9CE7DwWEYrZOk2M2GMsOQZ5IhhNp6V6qbSC7rZfYhrFv3QZ+A1pjzxfbqCMErUchGNxUiz7fBIi1MW9J2cPOY9kZHeaokK7lcYG8fBw9HJ+VDa7cLYghp+fmC7HQpAWK3jm/ddguV87LbctGkDdje7A6MC6LQyWvxpowntg3S6VgiuMBjRJERiA5ht0OgwhKcNGDWutRp8cNSlunkIq4yG0s7CgRwB96AqT3dQGNql0xnfNvuDXDFLCGZ5fSZQo/fDrx1YiwKaeuxr6S1mJ2thViswocVkk1Y0ijkZeituzQN6UcDIeaiLby1QsRZJ3boWuMmVepqeK2xR1PMw3PsszdQX36N7ge/D91aNjcHfPK/egyIfZq9c4J5PMceT+gOh2QPLnGzIfmjFd3hgG5oaMcl9fEtvIHxV86T7Fm3wVW6tZiQ8hetpbkxwKyt7IoIuxOiL0PcJdFNCrJ5k4JJe1CmOY38ot5L82Nm4ArpNMTnNAsphVRrZQ29c7jJCDsbYL5yl/bTL1G8eQ5Fjm7FM8HUjmxlQyDwzJ/LqM7ExWry6jJY0tm9FX9xEMrbEAyueKbQB4UrDG+39umy1q3bIRaDf+K6xmdG9kW23VbEBCL+sVsZL223DRCbGj8aoJoWN5Udk91sIGYqgD6X3Ql6VeOaluyLr6KmEwb/7NWtInA0lKvwoERtOrT1omMIlvAQ0nQtAqd8EU7wixVqKB6QRegq+Fxv1YSNZBzNrdHe+2FWrZB8gSRMnYRIWOYGn2lsMHTJ11Iu7LorRw5hbyTauq2AC4TMvXlM8ea5EJnDMrVK65nB5SotkhUfBYLbkkKHv0H6+4WZhxQQrgH6oHBFoeKW5WK7q1AmJGup41vRIdB2MChRD0/xN47Q53MWn7nD4M2lZAExABRC0KmNmK+4g7GcHANpX5pVLS2+0WC7WSruNviBl7G56CSWv/sOzVhz8KUF+mIlxOByLaarTkqdSFhmlwZXiIlLdfcSrGP90iHKeQZfebg1M3njbbqXn6M5KiQFbxzLj03JF3Y7NBU0A3GBrW6dzB8Y8X7QrcMOM6npAQqNK+T2SCjGTdq67iB8by7WyVEq8izx/faV6BOiG3U3yZPlmu5kklJ3svwllSGQVJRxb8SuE9R1QM8pXDGksdo0OBPIwXm9lSITlpHEr7ZDDQfpw9yONKsXRjvcgkMtVqJdiANA1kvK3HYSLBYr8XUE4R8GpWQazqHfeiiptvW0Q838I1rS/k7cm30VjFeLXMi5tx+L3fxQ1srZOBMxG9ANwt7FTY0rM+pbQ1Y/9FEWLwywpQrbqS35QoxQXaETr6BXrdi6tdtgkc2bNOYceYpushVIZfMGs2jQdYdeNWQPLoORi8csanFGalpRcwY3ah1GwO1AnsesZFTcrG1yaraFjEcXcwkI+Xlwo9rUW6HSrr18wFX3UoA+KFwd6DgJufUNcI1ImbEeOynpbh2kkeIot43eCbGs8NMRk1eXmNpvRU3TEfb2sZzEgW/wuUktTfXmA5krOL0Mx6LxZSFBJc/SOjZVNxz85gXrZy2nnyzpXr+LPp9LBrMOpimzId1Hnwmj2or6sCBfdKzvjKlPqrRS7cGPvcT5J8aUj9ZU91ZMv7Zg+OYKs+rET7JxFA8WabsUkEoM2S4lZGUkFSOxGbs0ZmPluVZt0jj43Agp67Ybut3xgZi6xPfUqMDHyAyHaDvk92xOCtqRpjzvaEeK5e0cr8FliuaoQj++TP4LusiT18OT9vJXHX1QuCrYkTlH9yA9qPDTEco5zKpJwiXVtLhJJXqF0SB1HnQtnYbs/rkIckK3Qa1raV8WOW5Y4vMMc3opeyKnY1nNvpT/V+s6yZ79aLDdwrQKm6daS3a8YXMUjjssU4muTuIb2bB8cYKtDKOvnFK8eU75aEM+72hHmmaiKS9cauXZcUF9IpLh2A0x65ZuJrdFH8qU1putO9S2wxHMY+ftdvqTnS1OUZptXXKPtmMxZ1Vxr0XkXozGzsJynKHwJS6X2YZs7akPMnQHtpDSwdSObNlJdrfjERk5hb1AcMVJRug5hSsHZTQubEHWo1Go7Y1wAWG9mpsOhawLwcBncgX0mQm8QU321bfwN+TMjctM1KZGBZ7AHYxFqFTkuFEhg1J5hgtDSDEIAEkYJFZkHe2iwB6J25GsqNtOuZqLDXZWMfkn97aPL3LM2RI9LKmM8AHNTJ5zdWdI9aihON3Qzkq6gSFfdLhCy4mGBAPVOXy2LSXiMJVZ22QrL+IjGXM2mzAZarftRozC3j5M5YPedCnQRBdqAD80YcW8LMI1TlymlBPxUzMpmLzR0EzDMWws2dkKv6mxcVt2mNzcm468BgEB+kzhaiF+aLTBnBzLgE+33boUt0zry9V2gjAgjhmrTfBMOJjKwNMuGx47FIAOAqW0KPVygVquZXtTFBZVOXHTchwfBlCFxc3arT9A2NrsDsZhRNvLvEHkJZCJR69FlQmQzztxK2o9y2dL7FDs4MuzLUfQjWTNu+yfNIk4jMImqeP9jhpRoeebVAa44Afpc40bD9J7pVqbxs9jdqVXbcoq0qboMPbdTSu6SUE9E2KzOrM0UxFBmdphLjaoMym9npx1uE5Kxog+U7hK0HJl0UUu24z2Rqm3KTpB0w87waALnYTQb0/j0dhtuzKWAmF8Oi43AYQ3ALGDD+PYyWQE9vT/WWG5c3KOfvE5/OUC9/xN9HwTSod6awF/ucRPg8FJUAjq185kyjHMF3QnY8pHYljiClljl8/bPZv5qFEwmyBHbp1IlttgDruRkWZprw6lHFjVUBZBfxGCl1PbwSqCFX0UbbH1moxekYR9kN1AU1x2VKcd8+cLhg86vIbqcSvchnN457YuTztbsl0cn77iQ1C76DOFKwi3CfsQp5O9E1d1QVfvtoYqafQZ0mgzwaocpHRQdSNip0AcxlIDJPtIG5/CeLJarJL9WDcbpN/vSpmbcG8NeH58xtlnbyafAl/JVKNq2rSxyh1PUyByowHdyQT3sTs0L92U33/vAdmDS8zZkvLrZ5RvLSjvr8B5ykcbivvLoFhsZe4jOE27KiN/tJLpyU0nzlKXC2g7GR+326Cowgat2Gp8h2U7YjevorKzyrbW7cFGrrjssKUO6+FE2uw1SX2pzi7xoWyA7Zbs62C99jT0QeEqwe1/iPxytfVfDGm+z0waCZb7anzcLRACRAwMtF1qY0b+QK3r1KmI+yb1udiQR3cmQDZMa032aJ46C+ZiDUYxuK/JlePyJR1KEhmF7ibiuRCPNWoiosehbi3NUUU7yWRF3Cc+kgat0mN23Kl9MEclrLw36zYIlUKQXNfbLkwV/BYCdnkO8rAhev5OvYBkC9tN3kBqg7pck180wXdBpNLRZck0ooxMLljXoKvw7aIPClcFWtqR6ccw/9DNBuIQFBeVJPMOnXQBGJ1cmBLOL5NTcVxNT55J5tC0uNlQHJ1vHspz5eLE3N2cJrNUFcoQNxqgH5yJm5NWHHzF8qsP7rB6uWb9wgwd5ijK+0vcwSQpA+1M1JO+ymiOKuqTQRASwfr2kG5SiFls04qb1Pkc5Zw4TF+I9Zt5PEfXLXouFnDZW6dkb51u/RudE4I1jouHDMgdjNGBI4kZggsqStV22HGZOhByrJUImzYdNgifbGWYvzgQoVSmcLkKtvSizjSrFnW5pLv/cG8BDTzFaemalA7QB4WrgV3T1ihjNnKyy4hx6KuHIai43CXC50ZOxvXO1XE63o5Q51kaA1bLteyDXEm3Ie6F1Ms1qmlDXz8MQEXm3Ci5EueG7OElXaVY1wW3bl3QTEKbz2jOPzUTm7PJCDsW8lDcoVSaOcgWjRiqrC3dwIj78/kl+mIlpc3lEr8K5cDlAj9foM7ElVpdLlUAqSgAACAASURBVLbbomIAiKPjm3f6fLrRQGzZc0M3LpI+wQ13gmd0WdpxgMrWNkmiywsbWqDh7+Ng9FYtOohFjd9s3iFISi7Tri8fenwHkLYcWYsaDdOyVn2+2GYDev/Pps8XqY6XOYQ6TU56rVFLGaQCpNR4fLbtSESD1yJPOyqB7dSl0ahVjRsNcLnm1T9+h8UdzdFkycVSMgc/HdFNcg5+80KWxDohAIsHC+zxhPpE5hWyhQwwFacb6SAsOuqTCv/CbeExwhYrNRxIUDyYBlt72QJNWB0PiB6gaWE6lpM8rpGLxx1k0dFwNX+0wg6L0HqUE749HCRTWVca2knO6oWRZDOdwxYy/RjnHLxWVI+lhMkeXEo3KOgSImIbcte09TplCdAHhasBt914JP86GFR7JGO80rPT91bBeQiQ2hy22UIk2sIQVcosjJZgE7mHSGI27d7VNm6VUst1MmxpZhnHX7TkC89br5xQ3xsyvrvh7o+e8PAHC/TlCrWuufzkoSx1CctVspUNNbpJC2bMqpUgkSvZdlWJqMrNhrjRIHUt/OF0uz8z8ihxMWw4Xr2qt47XgzLZsrtKSiJv9J43ZHRi8kYl/iAKokDGqS8/OkB3XrKZUm/bj6tWOh6dxS9XYQ2d29ElXA93pW+GPih8r6G38/XRdUkVubD6eUY3FW5B1Y2c8EYGjnh8Jn6EdSOzB9Pxtp6ejOTkCFyCWotfo1qupZ8e5NNpUUy4r69KqevXcaS4k2DUdtS3Rkx+5U0m/89XufiE5/C5CyavGO7+oSGbmx40uOmQ9iM3mP7GYxFLWScipAtJt5V1YSW9ww7ztGQmWzSpS+Li1T0YpnqtZdcjpOCWiNIox16uU8dBnV0GoVaLWYkdXNw50U1ymlkubs0uEIVhPZ4tw1Rn62knOcOHnQxZlYps7SjmVtyVFjXZw0v84zPZSBXW+sWyT4edFAnXMDj0QeF7iSd61+nDFMxaxWtwu6RVnIhFaqyqCn843ZYSMaMYDSRQBDMVYLsB6WCMHw/D5qXR1h4+tjKdrIDf5SuUc7jZULQCbSsGqcc1Rnsuf2dD9UOPef4XGm7+So36+tuYi01YyJqL9iCX8evsgfTwzbqVJbStIz+vk008SOaTXazTrgWxWcvkGNsuZUW+LOT4p+OkxPRtkEKPh9JarYLh6qbDa5XajOWjDas7QwibtesjkTmbWsoF5WSWIfEg4fiU9SIdb7u03zIdtzF76+oSrmFAgF689L1HDAyx/jQGfXKUUt5kBBKdi+PItNGJNEwGK1oDIkzSyzX2eCLtvDoLE5Em1NzvXHAaLd784XQ7jbmpoSpxswHFvUvUcICdVOSvVhw8+4jj/y7HnG+wxzntrMS/cDs5OyvnKO4vZQXdo8fyut6C+vd/kiyOL8cTDbZX+8ygrROe4KuvicX94Uxanw9PZRu1c5IRBK7BF7nY0IUAhg3brbXCXEgbMls0QIEd5lSPZGrS65ziomP5/BDlJEuQToMJwihLFrwcs7O1vJazc+xymf52sWTYKx2uOfpM4XuFXUZamx15bBQSFWk9uz4PDPuO5ZofDSSbCEz6Xo8+BRCbFHxJ7Qjback8SwRl3AlB24HWMkFJmKsIV7/muSM2Nwd4DXdPDzAPz2Wu4c3/v713jbEsu+77fmufx33Xo6sf8xRnRqEsU0ZCEmOFhmR/kCDb4odQBhSD+WAzgQAmjgxYgPOBtoFABvIhDmIJDhDYoEEBlCGEUmQJIoIEiCQTCBJYZChphs9QHHKGmunp6e563ar7PI+982Htve+5t6tnesiu7urp8wcKdevcW/ece6rOOmuv9V///z7ZeBnHjkE5CmY6x+4fqCeDX3P3vn1bWYmzQi3rvTZjfWkrznZwrFmFq62Sgo7Gui1mUjZa6NlBD5nOsdv9VV0lujypmUs9zKPBTHMUOyg59W4VOAP5uNRx6HGpA1CjjGRWKXnq+BS3WKg2QnPJF2oZj/iSoYk2U3jIWN1pvCvx7rZeILXTab/araYVjRq7xIKbV0ZyaYLMtUOgKGL2oHTlSum+rAqRge9gt/pejdkToLzgiHnzNvbKJczplPTmMXY0IHv5O+SDPnuj5zg9HkF9W1+/NSS5vk/99GVYVCqv3g0Xy0oJqp5MkfkCc2sfuazDWvVVf3F3U7i0hZktqd93jZMfHnDp9hXNMooSKOHaZTg41u4EaFALYjC1WxUbgy9k5Yuo1pGNlywv90gWNcV2SrGdYkpHMdKsoHer0NHovmCqlGxq6RyV6qB14xa2KNa4CDF4bwqoPOIBAdpM4eEguD95u7OYJfR6WtjzlXPQgZ01/kFA4BH4O7xLk9iCA6LFW8gEZKGzD7aRUbjUZyHBfdkXG+ttdWIyp9M47EQicO0ybjqj7ghJwWpdHVyha4eZzpm+sLOa6mTlY2F63ahy7BZLKEqyoznJrFQVZ0/bTt88ZPvbelyyvRWFSmSuPpAhKIYOiet1VhOREMVSMKLkJN/xCKPWpnSIv3bzU9+CtY5sWtM7qBm+saBzVOjS7fgE1wwIto7FxKbZy3sJ9+IQ9Szw68A11BHq0865fyEil4DfBJ5DXaL+tnPuSEQE+BfAR4EZ8J875/7kfA7/EUSjd72m25ck6pNoLXUnJd33U4z9DtRZvMDEazKSpZGyHEafzUzVmezOSNPdQW9Fk04kqj8HoxOp/DIkSzBHJ8ouXCxJF0vc1T2ctdiGFHx1bUB6ecTJCwI+WXFeLk78PtzBEb3rQ6rLKvdmP/Jj5K/cwE1na3oR9W0VfzVHx5gkwQDlX/4LVE8PyY8KsjcPmf3FJ8hOS8yXjtX4xtO+A3dBvCEOWYozPZ21wKs4B8MZiLJttR+4MpVDastyJ42aDjYzKs4y0TkJc+sothw30cwYotnLI0ZQejvcS6ZQAf/QOfcB4CPAL4rIB4BPAX/onHs/8If+Z4CfRT0k3w98EnWobhHQYLmFu43ZHmGuXta79LBDMllSPOmNUWeaJUSBkDxbdQx8cS2axnqHJLFqGCtFI8sImgLBOMXTl0HJT25X9xeo0YGzkByeIG8dkL15qBX4t465/HLNpW/WUXFJylo1Hk4X8OTVqHRU7nQoRynHP/k+8HqFyXCgk6C9bmOasMYVJdkffYP+tw/UUarboXNT7eKSp65pVT/PtOtirdeSrGMgcFkS6xPBd9MsKsqdTlRp6hwVJItaPSKAweszsnHhVZpK0qM5ye1j5NXr2JNT6mbL0WcEpttdSbU3/56PGJX57fCOQcE5dyPc6Z1zp8A3gaeBjwGf9S/7LPBz/vHHgF93ij8CdjYMaR9fNApUd6CsvE6gekZ2Xr29Ek5NTBwNpuGCHIlLYXJy6kVIQ0bgg0Yce/aFPCnrVScjSMSfTFdDSU0ev9E7s5vOyG9OwVqqrtqvu+kstgKBFS+iDN6QJdmpjhwXf/EZ3A89hSsKJM+w8wW2KP00YaONdzReHUOiMmeBpERRqh2bZ2lqtlDHfVKvvBdCB0RHm1X3Ucp6pdpUq9Cq1Jb0aKYiMKdTXFnqcsGPrstm69GPQz+qE5D3gndVUxCR54APAV8Erjnnbvin3kKXF6AB4/XGr73ht22+1ydF5Msi8uWSM9bM72U0LOIS33Kze1t+KlD/sV2+mjh0G7TmUGyUslobpXbdTkznCc+hnQDxys+yWMZaBN6ROqo4QwwSwYouUI+5uqfLgzxjsWdIF07T+EAvDtONG9OOybwk35+RHc11MOonfgyzNYqfP1xckhgkz33m4HRu4fo+vT8f6xwHRLkz57Ul7N6WLqG6nRgok8myoYuQ0PnzIz3lncSrQevz+Y0TkuOJznrcuA0396nfvIk9PF7jIITjBGLWcNbf8r2Eew4KIjIE/i3wS865k+ZzzjmH1hvuGc65TzvnXnTOvZjReedfeC+gsXRYGYU0/qlqhzmZaVFsMov6h2Ei0KWeZxCCRTdTLkFt9W4a9BVCkPC+D4EZKHPvS+mXD8opsNqBCMECVtJui/VOBWhWYlMl+NT7hzqjEVSHfEuz2upS7vao+ysL9+W1gd69a6eko0ZAcHWNLUqVMmuu13dVjyHuP0lUPn2+UKWoRRkl7MP34FRlJnNdzmSpshDHy2gnJ7Ol/s5iiTk4ph6fRBk155cy4e9zT3/P9xjuKSiISIYGhN9wzv2O33wzLAv891t++3Xg2cavP+O3Pd7YoDNLYpDtLczWKEqVuUzHodPxnOrZKwAq0BoYhlmqdYBEL2hzMtOZgV4H9nYA4lCT3VEr9iD8Kn4dXu8M9UIddVWK3Y8T29FApxAhDl3pYJJ3mzqZIm8dgLXkJ47ltpBcuwJJwsFPPUdxdUi9N2L2/j2K7YxymFL1VOPw8C8Nme+l3P7LW5hlTXV5uKopNE+RHwQzp9OVKtLN/ZVStfdTCI7cyl1YCdBgjBZo8UsrX2QNmZI5Xagh7mSmGcdi6YPpehchZARhWePqeiW9/xjgHYOC7yZ8Bvimc+5XGk99HviEf/wJ4Pca2/+uKD4CjBvLjBYNhCq6i+3HiurSwFOZNd3XIaKgHWhX8mkocWetxdjJCcawUtZRjSjqBvhBocUzI6phDjtbKma63dX2Y+7VmcIaP9jMhWVGX41iRm+U7HyniN2AuqPW8ap6LHQOlmoAc2tO3U+pcyhG6qpUjZRUFTgFkiQaIIJ/ZlHEJZDt6/mx2329a2+m9Y1lVZyL8PwIWRaxlSpFqdmB/2xu6kVWxyfYyXRNx6JZRxDfejzT//E9miXAvZGXfgL4O8BXReQlv+0fA/898Fsi8gvA94C/7Z/739F25CtoS/K/uK9H/KjhLoUoXT+blQFLIrgkUav3RCgvdclQE5hYUPQmsaDdCLPQAak4Ig2xFoC1uGE/qi6Jt0UzZUVvPKO6PKK8OtLCW+00q/Csx7h88L4Ra3TqLKX7J6/qDERiqF94ip1vL8heu0n5whOkc8v0mS692yWzp/vYFHa+W9J944SDF/c4fSZjq3Yku9swmcaiY/BJEK8aVXtGp33uKV12bG/hxifxNW58gksSPY8A0xmSZcg0WRVorZKoXJooiWtyrIVRr4EJ0KQoN2sHQFxGvJfYiveCdwwKzrn/G1aWhhv46TNe74Bf/AGP672DRg+7yV4kSdaoyc4IUlrKy30VIqkdZqmKRJGME7QHfcsPWLuruyzVfn6aAIknNRHt2ZL5EjvsRWIUsPJlzFXdidlcL65wXGd9pqt7+j1JVKLN+zOYWYkb6eBROil0Hf/mbU3Vi4LLJ1MO/+qzSjM+mWyMHOvFLomqS1WjjOx4qQYwpdWJSNBZiLqGXpf68JhkONCMC3CLBQz7KryyNUTmFebgJLZOXRgaG5+ufZxmbSPA5NkdakqPQ0CAltF4/mjMNYS7keQ50u3EOkJg2+Hv2lLWpONlNENRVWVVDFLZdv/zqKvrZq/bKGW10nPM0pU462xJcjxZ8RIWFcmsoNjOyF+9RbY/W8mv+dqE9Ua0GBONaIMIK2UV2YXue2/o1GG3Q3mpizOqTGT+7M9xL/9/uMlUawF1jT06Zud3X6L7R3+GPTxWj4v5AklMXD7ozvXiTY6mOiUaugm1je1CN5lqDaIoqd58S5+fL/S4up3Y2owdi7LU7xtkpMg/yDOS4QCTZzFrWR3P4xEMAtqgcJ4w6+loRL6qJbhsNXCk/oYFMltSD3OShjV806sg6AUE52nwHYMg7mqMFulgXaWpkWHYTjCFGVFe7utxBN1DP1Pgup0VVTlXVqXLM+x2X1PyrQHm8h69t/RCs5khH5dkB1PqkxO9uIpydcf1xbsVKWhlqWbni9XAU1GqHFpVr47z5FS7NZ4jYIsS6WkhNNneWsmiJQa3WKqMfF2vOA61l6uv60i3bhYXVUG7WAsG8fnNSdb3ONqg8ABh8kzT3yRZiawG+7NFpVlDN2X5Q7vUPd+vD/MMgWjkbd+wVmnNno/gUk/7tdrCjAEE1Ep9Z6jUXf9+Yh39106w/UyXK2Ud6xsxAHjNxOAlYUcDv99CR5RvHeAGPdJvv0G9NyI/XJC9eQRvvIXpdjfowJZNbFb510hBoMe8VAn3EDDCrIhqGBS6FPDZAEmi8mh+uCsUJu3JKRRlXDa4oohLOVfrLIMZDHyQWlm+PQ6chLPQBoUHgNh6C/+kT13B9TuqHhxqA4moS1Ft6dw4Jb+tZJ9gbea8sUn0PYRIQIqy7zSmIMNd3ztMA9i9nahZWFzqUu32ogJSYEE2h6/EWtVfvLK1Gq4K3pTjGe6JKzpDMehrUEvU0i5kQpstx3DRN+/QJnYhTGxJkiSRUxBUrEOACRRpQDkSzeGkbgd7coo7mWi7cTpbTU423J9dbXFlEZWubFHGGYc76giPIdqgcI642wSdWZZxSaAFxlpFQYByp6Oy7t006iFUw/wOl+mo0tzJYrXd9jvRqs359mIIDqpd4Mk7XvUoPZqvjnWpy5aQwbhMx7E5OFbx2IbfhEsTOBpT7fa05jCdaYF0/1Rbn95PIgqYsr6Eag5GNTOI+DhTvwczmWuhca5cAja7A950JWQRztq4hIiqz2cUD11d+8ygviODObPb8JhkCAFtUDhHhLuijQy5RO9mPgDUfZVbK3dViry4NiC/PVfFoNMl1VZX1ZdmZUzbY43AF/vMZB5pyzHYBKVjbxRTj7SoWV0aqH+CH7ISazGlVb+G7b5XLdLsw9w60sDS76lmQ+BAAByNmf34C9hc1Zkky6JwCYBsjbSY2hgLB9aHh2DlzNyo9Mv2Fq7Xoe5p7UJKq0ItWY6dTrVzEzo4NOTU6xrmC72gCy0qkmerJcNmrcAvG8L7NMeh7zjexwxtUDgvnFWUyjPwngtqL1+ql8KkoB51VNzUqmEpifgxXqfSYX4yEtDaQkOvMPo7+JqC3RmujGCAZKbvjxEdaLo0wIWLwcuiAUoLjqPWCbJYKgXaS8RHYZbnnmSxm9D52uva5ksSyqG2QKtBijs5jXfht1uXh+cCT0HyTLsVmY46B0enOFXZ7TYGkuwdJq6Bohw7FL6zEYJIKGyujs02WIt31jwel8LiJlrlpXNEc7zWgaa/DVNTlyXIrMT62kG13aG6pr4DdTdRE9Nb87i0SGaiXQeIw0nQmJb049Xis4igpyCLkjTIsvU7pON5dEgyYy9hFuYlep2Vucyy8G7TmnGUV0cU2xmDb+1z6csL3BN7mOMJpx98kmKoEm7d7x1HIZU7ZM8DzEb2YEI2ZTHbI+ZPDunsz1m8bwdTWLLERKGTcHdvXtDgZdHqOvIY3HwRjyFg8ziilNr8jKLiY4w2UzgP+BbW5kBNINmItSsPhEAkSkRn+qcVdVclwsSCmRUkp0v1dPQDQICy/AqtE8iy0A6FH1222319jacpB+p0eVm3h3ZlCBJAw7a9od4U7O69rVyxnZHOVyYxeCbkfE8vvOJKD27cQjxtORC1NguOm+cq6BNInsHeLslCay3JvFa2pSc36XvaRpegXn357MHN53E2YjMg3FHjaQSvMP8QHj+OtYSANiicF7ytPKyEOVypI8rhzh/4CXVfvRZtJ/WejDO9GEDt10Yd7FDJRHbYUxKTtdR7I21PZr4oOZlF0k4YanKDHtlbx0hZkY6Xfg4iJxnPo/OU6+SY8cxPS5aY8UyVnBp+jVJW9F8/VU0FgNpqrSLPyE8tu18bx2MOk47NQmKYH5AsX9VXGmxG0+tSffhHmPzoJcxSLdnmV3OyW6er9D92IFaj5wFrRjqbf4owV7Hxe7b5fg3Rm8cd7fLhPGBX/2SwYTYaugceUqsQSHpasLzcJa/UKMUlQt1Rv4LsqEEq8vMPrmGfHtqJADIaxrV4mGGwg95KzHRRIZ0UWSwx3Qy742XTtvvaDelmUb4tBIfymT3KUUbvT7+nHIBaPSDsk1twfEL3cBt564DuyQy7WfH3F6SdTBuK1U3tBH8hJlpH6ByW0fuhe1BGZWfJ89V72Bpb3NndiUXHBsJSZnPbXbUVA0npMc0SoA0K5wNz51pa8lwvlixV5yLv/GS8GlBxqUs+1jtXMitJjqZ0jGH+/C5puOiDCxLKaIzWb3682Q37etcP+gt+alDKGhYV1W6PpHYkkyXlU5cwvuVJrcuZpKz1ff0xh0CRvXFAulhin9JxbvPmbSTLyK8fI90OnZdfwz1xBffq62vrePG1AEDFZPIMGfSjOGwynlNd9gIq1pHfOIHjE5Z/6VkWl1J2/v0bSkv2RKX4vll+5l09dHnOYiU2h54kMY/tXMO9oA0KDxKJiprUYaahVum19LSguNT1cmE6AFRd3dI7eCraq5+t1ITEqllK4qnNLnAaGgpLQVHJjrpazTfqm5jAmpJTCC7p4TTKu0tR+iEqITmZ6exDIEc1Rrc5GscCqpnOqTcFTfGZQq+Lu3JJl0EdvUjrboLsdKJYKonAwRH1C0+pDkMq2KPjSGZ6N6SiZsZw9hTkxhKjSWF+jGsJAW1QOA+EbgMNF+LQditKTFlTp4a6H3wKvPy4dZQ7GdXVDv3rM2RR0X+tjKk/xyfQv6IBgDp2CqKNuzeDjc7UidH2Z3B8QmnMZlkqVyF4SDQl07uZkqAyQzKeUz6xQzqeqzza8QQ3azAlQbsd3S7u+AT5Cy9gbh/q9i0VeZm+/xKdAy2UZsH5ejrTjMEXIOtvf5fk2lVu/yc/gqlg+ztzBv/P9xoMSLV1b1Kn7+bI9E4BYXO7npDHs/V4N7RB4Txwx6j0yhIOoO5liHXY3ESl4Wy8xHZSykFCOreqSjzUgmR+S9WEgmVaUC6Od3wvt+Z2RkqN9m3GKOA66EVRU6U5Gwj2bqxmHQCVg9vqg9WpzOTUC8GWlc5X9HtxDkOyDAa+o7I1RE6nlC88CUY4/aEuvYOKwXePcd+7jmyNtNDqB5/cZKoZxtYI+1c/xOlTHTpjS/egJP3W69Tjk7X2Y2hbBkRp9Y1zflZA0L+FufP3YU0ir4WiDQrnhQYtF/w/Ya0ahunRXJmKVg1LnBE/8SiMvnWEM4bJ+7fp7ut6vB52VFPA6ypEx6fTxSpIhBrDMlkRmfwygrLSroXvbhhr1bfB8xmAyISkrJDZEuPlytgaRrOYaCvnVaFdqbMabjpDuh3KF55QrwXr2PndlzC7O3zn7z3P5Zd32f7iG1QvPMHrP9OnHFmSuWAKof+WY/fPlux89ZByb6AZ02hIUlus102UxKgcWnNa0dZaW9iQSTuLTg33MNPwmC8ZmmiDwnnA/+M2hVnF1xNcWWL7KjdWDdKYJQBkt06ZP79L5+ZMlw/WqWyah9YS8tVyIjD6wjj0oKd39GylrxCFWYB0f6Lvbx3J7fHaIctiufJ72D/CXd5VCvNkFsVJ8ExHF1SOMs0wZNCPAqly/RbsbvPqpz7M4umSFz5XUA4TXvmvfojLL1vyYxV9vfrHlmyqPIS6m1BcHSrD0wcxGoXE0DLc7AzEgGA2uxDJeiZgVoNPZ3YXmvWEFm1QOBds/JOG8VxAe+6l5y8UBrP0Q1GoSGs6raiHufdBVGZjdjTXYmGWYLMElxrvmmxW2QCsBp78bEMYYLLbfSVLAcbvO0ilA9pmLEqYzmA01CXF/lGcMCR0ABKVfJNuQxDFK0vbgWYii4/8MJ2DJf03Hd1bGbc+BBjY+6rFpsLyksNUwvSaoXegilPZ1IInbIVzdMe6f2NuYu1cb2gdrC0tzDonIb7ujCDTQtGSl84DjYEfWBUbdWrPkhxrjSCZlbjUUI1yiktdZk/3SU8WWnDczqlGuUqp93Mvx+ZIZkWciVD2YUO8NEvXhqFgxUpMv3uDartDvj8juT1WmfV+T4eZFktdCnS72Fv7q6q/93zUOYL5SsEIL32WGHVi9q5ULjGIdUyf6ZJNtXA6vG7ZerVm/IJhuS1094X8GDpjR50LSaHOTc54t+hlFaXj187n3db8Zzk0bUjprz2/yVZsA8IdaIPCeaFh+BJ1GVEST7B5TyZLpFLyUjKvqXOh3O3pssI65f1PvP3ZpW6cdgzLhSjkWq86COALh94HQZaFWto/sad6jH5yEryWo7/4ZdDXC74xyOTqWmnDdR0FUqXb9a+zKmgy6OO6qY5MA+msJptaTAXZDOqOUA4M6RzqrjIgTAXOrL7bzCCWWPNYs3e/l4u36bzVzBCsl2ZvL/x3hXb5cI64g1Y7X2jfflnirJddN6LCqYnQu10itSO/Pae81KUapKTTCttNycZLHSfuZ2BTstf3cVuD9eGqsl4pOgH1dp+6l5G9NabeHZD/+T52NKC6PCR740CVlDwt2t68jfR6yPYWjE8an8GLmngCkds/WBVQfUszeesIEkN1bQepDdlphTNC/2bF/EpGUjjSuQbFcuDnKhKhTjQo1N2EZFGTv3KD6sZb7z6lP+u1bSD4vtFmCueFO+oKqzFimc7VDWpWYjNDelqQzCpcogSj4koPU1gNCLnBpYa6l5HMS3VNXlTYnRGUlSo+d9SJKU5Q1jbSqdOjOa7jZx18mp9MlhoQ4rHVyHCgk4iHx0opnq47JsVOQK8XDWF1X3WcogzLh2ReYir1b0znjnRuMZXDGchPLfmpJVnq9nThMKXVILF/qB4MzeVC2yp84GgzhXPGJsfe1TVSW7WK73VIJ6mm96lyFkxpKUcZ5SjFZkI28czAZaX8hspGLUdGHcyiIr19ooW+flBN0ovTzApsJ1PVJe8FUV3bQUqrnhH4oqHXL5Q8i7MKyeU96sPjxufwoqlFqdOK84UWJ3vdqPKU7p+qqKsROjdn2H5G52CJ7SQMv7fQ4GVXovFSW9Kbug+7f6hzE9AWAR8y7sUh6lkR+YKIfENEvi4i/8Bv/2URuS4iL/mvjzZ+5x+JyCsi8i0R+Rvn+QEuOu5g3Xm+givLOLYMIJWl6msASRY12WkVA4JYp3fhSl2S1TXZYhaaKQRnaYnfXRyWiiQnL76SjOfKZvQu1YFGGiflMQAAGIxJREFUHMRImhLqQcOwyRKUPPNzCH50eTLVtuXBkWYkt8ekt0+iWIwpaxWGXVSk+xMdAz+ckr15SDJRHUV78/Yq8whoA8JDw71kChXwD51zfyIiI+CPReT3/XO/6pz7H5svFpEPAB8Hfgx4CvgDEfkR59zj9RcOhcaGJVmAK0tkNISFpv4uMdhOQvfWnOJSlzr3d/pK2Y5mVlJtawAxS6hGOi9RXuqS36ypr+3459QjoR52MLUD60lR3RSbDDU4dDPK3R75N9/A7WwpL6EsGxOL60rGZnu0ljG4efPPWJJsb6n8ep4jtw9xO1tKrz6ZqePU6cLbxivhiVsHutwA3M3bawzEtXPXLhseGu7FIeoGcMM/PhWRb3KGtXwDHwM+55xbAq+KyCvAjwP//j4c7yOHsyb5zHyhaXuv42cedEkxe7pPOtdMoO4Y8qMFy70O9ZN9kqX19m4rLURTWMzpFNfdXu2gdlG8JVjQBX+IepiTHfjaQL+nF2aewZSYMdAYFpIkWZmurH2mhiCrzyySJEFMB3dwpCStxMDpRLsVi8VKdLUoYvBp4o5ZhDZLeGh4V4VGEXkO+BDwRb/p74vIV0Tk10Rk1297Gni98WtvcEYQEZFPisiXReTLJcvNp9+zCA5RrlSlZTMrokZi78acdFqRLC3d/YJyOycpLOmsxhRB1t2pMlGmMujL56/o0FNZR4KTWVQ69Wh1xNrMlphlSf7qLardPvmNE72L+wGq2E2o61hTML1unBeI2gcegVhket34O9ZzGuJr/BLE7h+o7uJkij08Vn/GXi++T/M9I9qA8FBxz0FBRIaoHf0vOedOgH8J/DDwQTST+OfvZsfOuU875150zr2Y0XnnX3hUccY/eD0+wR4eazodDFyW6ptQdxPqjtFhKeuoc4MprQqiJkLd18JkNUgpdzqYZY3t59Tec9J2U2xfJx2VEp2pvRxQPntZRWGB6Qs7lO+7onf1J/bU+8CLnqrRSkM9KZqn2KhZoB+kXsmsoxwMN1/ody+PFkRWIRi5mMZMw4baUTu2fCFwT0FBRDI0IPyGc+53AJxzN51ztXPOAv8aXSIAXAeebfz6M37bY4/oWxjMTMpqzdat7qeeYCRRpxCgGqRk40JblpmJTtHptKLyhq6gWgumVCkzsyxjBhKei6rOgEvAzPwY8qJUH8WogbhiZIaL2hUFkmckl3ZW77nm2eAv5ua8AiEzWtnHrRGjNicdW1wI3Ev3QYDPAN90zv1KY/uTjZf9LeBr/vHngY+LSEdEngfeD3zp/h3yo4+oNbhYKOvQ8wuy8VIv9nnN/GqHuuMv9o2W5fyKrvFnT6hISTXKqUaZzkUYobjcp7g6jKQmaqcFTR8YqksDureWFFd6uoSwFp55AvHBKqgTiTddXTt2L5sujTrDHf4Ojfdoft6zXtMOI1083Ev34SeAvwN8VURe8tv+MfCficgHUbfy14D/EsA593UR+S3gG2jn4hcfu87DJhqajU2pMmqVWAvGsHUvixoLdS7kp1YDgkGNV4BiKyUpvAbD1FfugxGLEap+js0MZCoJ7xKDqSvlOQw7JL5VmZwqf8DujKJbtRkNEa93ECTXHatWYVQu8j+vhpZW2YXpdaFYH2def2199rKhLS5eGIhz7p1fdc7YkkvuP5afftiHcf5oiK/ETb0uXLscLeDEWqqtLuVIawd1R6cInYF8XDJ7okOdC1vfmbK83MUZIR+XlKOU/KhQi/nL/aisHJcakwLri5BS1tTbXWVTTrTQKdauZiqOTpQ/4GnZUQsCorx68GAIAaH5eFNcJiwfVoYsDcGTNhA8MPyB++0/ds69+E6vaxmNDwpnjFMHSFWvvCW7Kcmk0MKigWSpF7dYnRGwaZgdWK38im1N5Zd7HfLUp+yJ1iXMpFrVHFKlUOeHC8ysxA3z6FdJWSnrMdQJ8gx3cqL7iRd33nB/to3AUNOcCA3fJc/8hOWqzhBs9FpcXLRB4SEheiIkCe50otOGmac8Zwl1RzClo+oZbCY+QAi9/RKXCIurHaRGqdDTOhKebG6oeqr5CDqBmMxKrTckQnqq8xPLqz3SWU2521OLtsKSTAod685SpNshHfSVAn2ifox1o2uwsmqzUcBkM1tYG3/2uGPJ0OLCoR2IelDY8FCMLkdzL4RaqBJzsKNP55bujRk21YsedAy56iUaAGrtIIAqGYnVroXUzg8fCXXHUPUTyh1VUQ51CbGO7LTCLP0dPFCjrV25TqeeyJQkyHCA9Hrq5xgKjA0H6E1p9bB8WGtfbqIdeLqwaDOFB4mNu2N0o64tLrFwcAxP7Glqf6nL8lqfdGE1W0iF/LSm6hnSucVmgtSQzldZgliVNgPWaNLNNqbtJLH1WQ1yslMd155f7WB2c9VvKPtqPLvd12nOibezn8x0WTGdrT5TwVonYtO/sYnIWtyUVG9xodAGhQeNoMrkhUdDtiB1jexug/eLTKeVTkTu5hoArKMYJZhKKdCdo5Kqn1D1DKbUzMBmEmnS4LOGwlJspaRoRmEqXVYkda3vua08h2RpSZYWs1TKtY52L1ceFaGN6n0hSBLNIorSC7GcwVlgna9w14DQdh4uFNrlw8OAVwpyZbHGJHSLZVRNlspPQVYuXvTO6IXtDCx3M79cgOy08ssHqHpGt1untYfLOZ2jkmThxV3971d95TSks5qkUDPbumNYXO2wvNzFdlOKJ7dUh6GTY0cDPb5bB7hhX+sF4bjPsJyPZq2gCkibHgvNINAGhAuFNig8DJyhIWiLEjc+gZMJLlVmIqB8hFPPLSicVzGy/mdLMTKUI034VsNUsqovlI5iO1XF5JGJBciqp3/6kG0EhPc2ZU06XmL7HczpFFkWyM4WsrOlPhNbQ6TbwezuIN41OkAa9QYgmsqu0ZjbWsKFRbt8eIhoTgYmw4Gux+sajsZqCZdnJN0U20nojGuvZyixxVgOQv1AL/JkqYrJNhXKPqQLXWbU3oGqM9aaROe4issIUzrqToopa8phQjqrWW5nmEtdqp6he2uJfeqSZi3eVSp4RZBnKrBSDlSNujliXRbR8xEaMu0tLjzaTOFhoZlSs2r3ufkCOz5VB6aq9kIqPvXPAkcBVUJeWs96VK3D1PtNZlOVOUvnlmLbu03XjnLQUH72gUVqR35SaetyqUuO/luFDzKOup9GI1o76mpA8H6VQXGJolQZeFb8hDXX7Y3R6/D5W1xMtJnCBcDdfBFdnkVD1+y0JJ0K5Sj1RUEdoV7sZSRLMJWLyk11R1Qd2ROdNHtISOfOqzY5XEcDgyk0MCR1TdVXAdVylGFKT5ry0vJiLXK6oN4bqdV9YpDpHDsaYHzh0aDdhzs6EGd8thYXF21QuCCI6/Awhrx/APtgdncw3Q6LFy5T9fQ1VS8hndcU2yndg5LFnt6Jk6Wje1BG5mPnqMBmhnKYYiqnnIdTFYMNWUWxrYSpdG7Jxyok270xodztRb3IdCIUV4ek4yWyqHRWIxHIM7W973a0QDroaxelbsi3RWqz/3zB/q3FhUW7fHiY8IW3qHfYMEOVPI9iJJQVyUzrAPm4JJ3r+t8ZYbGXIRb/5XxXAaqesNzNvXy81hxMpYzHMEBVdxOySU1+UlH1DPOrHWxumD891CLlsiI/XFBc6irrcVlSXu5HNac1BO/JhqRbCAhN34uWtHTx0WYKFwArRuB6jUGSBCZTzKUdstf3yV6rKZ+7hiRCPtaORN1dcRXq3ESWYzp3JIXFZvqcWOeXE96UJjdk40InKwcpnaMy0p1T66gGKdUgJT/UWoEpLMsnR2TjpY5j+zKBVHNlQeYZLJYxQ0i2t6KYSpP+3OLiow0KFwRrVfoGTK+LGLVnk243tir1SVmrI3SOK8phEnkNdW5ICkuysD47UBUnU9io4mQzQzrVAGNK60lQhjo39N6axdZmCBixQNmUaj+ZaobglZVcbanHJ43WZJCSa5mMjwLa5cMFQbMw58piNT8wX1DdvK26C9MZyfV9sjcPcakB6+jempPOLf03F5RDr+xUKVchH5dkx0vPRQjBw6jz1KQgGy+V5mwdUlmWu3lcXnSOCupeRt3PKIcJxXZK/sahvv+yUgn5RKh3hrhBD7e7pZ+j14uiK2FZFJYOUdm6DQgXGm1QuAjYaE82dRcCNdjN56qE7K3gzbIiOV1SDXV+wZQ1plyxH7OppRypjmM6q3UOws9DZGP1l7QdTRSrQUqxm+MSIvMxmSxJTxZkR3MtUE5qyidWUmwkgjOG5LZyE2Q6V0t6vOaCXzI0iUxr1vFtTeHCog0KFwUbTsibF1EQSLVHx1CUJN9+A3N8Sn7jRNP9XubpzroMMKWqQDsj8efQopTaal0AHa3ODxeIhc6hdh+ywwUuS5g9O1Ldx0pnKNT3Uv9l6n5OcvtYlZsWS52o9HqTptddSbB5jsKa9Fr4vC0uJNqawkXDGT6KzSKktvvUBdotVC8xv3GiWgz+QjdLX4TsZ5jSxsnJMCNRXOpGWzdQGThTej7E0TwKvmhLM2Hw2ikyW1Jd3cIsKtV6PPX29d6zUo99Zewieaaybp6zEPUXyjul2lpcLLRB4SJiYz5gfdLQF+3qGns4xUym6hQ9mWJ6XZLREHdwhOztInsjfZvxDDvsQaJLhu6NiQq5+iJiIDQBLJ4crhUj00mQd+uRjtVcxpwusKMu7qkrmMlcDWWOxnB1D47GaxZwTTXnSHVus4QLjXb58CggjFuXxZqUelyvh0p/bXGzOfS6sFhiThckB6qaFPQXg++DmZWkR3MVXHnzSAevbp1iSksyq/TxUunN+f6M/NZE/SSyBKzFjGckhydKez6ZqEjMVHUXQoExHv580bYjHyG0mcJFxtvcUdes7ROjRUhQJeW6hjzXdD7zVGlj1GLuZILsbGnw2Nkie/MIO+iRHUxx3Yz85tRLw6ekh1NIDPWwQ3oyI/NzD27Q0zakV6GmRN2np7N4HJtCK0GyTX9os4WLjDYoPCrYkHPbRKQVh5+DZyOsZg+GA+0QLJZItwPe5s147wcxRpcCVp2r7HYfMytIjqbUeyOSg1MVWZkvNSD4eoLyKJY6NRlk5hqZDIBdLNpg8IigDQqPGjYuKmdrXN0sSDaKfYm2BqOe4mSqaknhIkaNZkOBkMVSR6AHPUxVaxDodZDJjKSqNXAslrHL0DSOVdGVUEjM75RkaxZP28BwoXEvDlFdEfmSiLwsIl8XkX/qtz8vIl8UkVdE5DdFJPfbO/7nV/zzz53vR3iMsdHvP3PdXtda5AuWbWP1dHCTqc4rzObY/UNtKXY7uOMT5PpNXV7gPSDKUrOKEHB6Hc0SGjUNVxRqLRcISo1jWgsQbUC48LiXQuMS+Cnn3H+Emsn+TRH5CPDPgF91zv0HwBHwC/71vwAc+e2/6l/X4jxwxgW2qYlovQmLJMYXKm00jAW0QOjbm24215FoL+3uTieaWXS992VwtTo41kDhTWIkz9c8IZrH0pRka/Fo4B2DglNM/I+Z/3LATwG/7bd/Fvg5//hj/mf88z/t/ShbnCca5Kdm9X9t/qCRVdSTKfX4hHp8stJbHJ/oW+0faM2hKHWEu65xwz7uaBw9IdjbWbOnryfTNfHWlS/EhvRcy2a88LhX1+nE+0jeAn4f+A5w7JwLzJU3gKf946eB1wH882Ng734edIsGztA93HRgcrXFlUV0u276M6jtfLGu/FSUmgkEF+qyxL15UwuJpxPs/iHue9eRLEMytao3G+pK4RjWZjqCmnObNVxo3FOh0RvEflBEdoDfBX70B92xiHwS+CRAl/4P+nYt4M6LrSGJhknW2IVhmhF0iMkQLmR1erLj05W7dG2R4UDrEIAMBzBf4E5OV61Qz5MQbzPXtIq76/G1uJB4V+Ql59wx8AXgrwA7IhKCyjPAdf/4OvAsgH9+Gzg4470+7Zx70Tn3Ykbn+zz8Fm+LxixFE662a9mEnUxXxjRrHQw/b9Gwi6OuNSBsOks3RVXu5gzVLhseCdxL9+GKzxAQkR7wM8A30eDw8/5lnwB+zz/+vP8Z//y/cxfB2vpxRWOWIlrA+/mDoPYURrUD4nb/JYmJ9QaShHoyxS5WgUF6PU+msnEA6q4MxjYwXHjcy/LhSeCzIpKgQeS3nHP/m4h8A/iciPx3wJ8Cn/Gv/wzwb0TkFeAQ+Pg5HHeLd4NAk8YHBr85DlqZJErA2fkCbI0ZDBrSal5SrWke2yQmTaZrprKbhc6W4vxo4R2DgnPuK8CHztj+XeDHz9i+AP7T+3J0Le4vbE0zZVu3d7M4P6MgWe6XAKtEcm1SMzFajNzkILBZxDTrRc+2pvBIoB2IetzwtvMUjSErz3EIj2PnwMPkGclwgKtrlYw7o4ZgF4u22/AIoqU5P47YtG57mwwCVlmC6XbXipD2ROsMoZ25+Tum211lCm1geGTQBoXHGRvB4Y71vw8WTb9LE5WUDDrjYNbmH+7ILs7YTxsgLjbaoNAiInQlmh6QwNrFbYtVvSCIp+DJUcFI9o5aQhsMHim0QaHFXZWemu3DZsdhlQXceeGvm9q0nYdHEW1QaHEnzrCLD0XI8L3JiGw+10TLZnw00XYfWqyw2Sm4gwnZkFgLmosbkCS5K5OyxaOBNii0OBtvUwc4a3mw9v0sv8iWyfjIoA0KLc7G3TKG74d3EH6nDQyPBNqaQot3h3dSetrE2yxHWlxMtJlCi3dG0FVs1gre7gLfrCm0GcIjhTZTaPHOuJe7fXN7CCItP+GRRJsptPj+sJk9tHjPoA0KLb4/3GswOEMNqsXFRhsUWvzg2Lzww9LhrMDRZhYXHm1QaHF/8E4ZQJshPDJog0KL+4OzCo3h8ebzLS402qDQ4v6jGRDOCgZt1nChIRdBU1VEbgNTYP8hHsblx3z/F+EYHvf9n/cxvM85d+WdXnQhggKAiHzZOfdiu/+Hh4d9DI/7/i/KMbTLhxYtWqyhDQotWrRYw0UKCp9u9//Q8bCP4XHfP1yAY7gwNYUWLVpcDFykTKFFixYXAA89KIjI3xSRb4nIKyLyqQe0z9dE5Ksi8pKIfNlvuyQivy8i3/bfd+/zPn9NRG6JyNca287cpyj+J39OviIiHz6n/f+yiFz35+ElEflo47l/5Pf/LRH5G/dh/8+KyBdE5Bsi8nUR+Qd++4M8B3c7hgdyHkSkKyJfEpGX/f7/qd/+vIh80e/nN0Uk99s7/udX/PPP/SD7v2c45x7aF5AA3wFeAHLgZeADD2C/rwGXN7b9D8Cn/ONPAf/sPu/zrwEfBr72TvsEPgr8H4AAHwG+eE77/2XgvznjtR/wf4sO8Lz/GyU/4P6fBD7sH4+AP/P7eZDn4G7H8EDOg/8sQ/84A77oP9tvAR/32/8V8Pf84/8a+Ff+8ceB3zyva6L59bAzhR8HXnHOfdc5VwCfAz72kI7lY8Bn/ePPAj93P9/cOfd/oYa797LPjwG/7hR/BOyIyJPnsP+74WPA55xzS+fcq8ArnOEb+i73f8M59yf+8SnqXP40D/Yc3O0Y7ob7eh78Z5n4HzP/5YCfAn7bb988B+Hc/Dbw0yIi3+/+7xUPOyg8Dbze+PkN3v6PdL/ggP9TRP5YRD7pt11zzt3wj98Crj2A47jbPh/kefn7Pj3/tcaS6Vz379PgD6F3yodyDjaOAR7QeRCRREReAm4Bv49mH8fOueqMfcT9++fHwN4Psv97wcMOCg8LP+mc+zDws8Avishfaz7pNF97oG2Zh7FP4F8CPwx8ELgB/PPz3qGIDIF/C/ySc+6k+dyDOgdnHMMDOw/Oudo590HgGTTr+NHz2tf3i4cdFK4DzzZ+fsZvO1c4567777eA30X/ODdDeuq/3zrv43ibfT6Q8+Kcu+n/SS3wr1mlxueyfxHJ0IvxN5xzv+M3P9BzcNYxPOjz4Pd5DHwB+Cvo0ihIIzb3Effvn98GDu7H/t8ODzso/L/A+331NUeLKZ8/zx2KyEBERuEx8NeBr/n9fsK/7BPA753ncXjcbZ+fB/6ur8B/BBg3Uuz7ho01+t9Cz0PY/8d99ft54P3Al37AfQnwGeCbzrlfaTz1wM7B3Y7hQZ0HEbkiIjv+cQ/4GbSu8QXg5/3LNs9BODc/D/w7n02dLx5ENfMdKrIfRavA3wH+yQPY3wtoRfll4Othn+ha7Q+BbwN/AFy6z/v9X9DUtETXjb9wt32iVer/2Z+TrwIvntP+/41//6+g/4BPNl7/T/z+vwX87H3Y/0+iS4OvAC/5r48+4HNwt2N4IOcB+A+BP/X7+Rrw3zb+J7+EFjL/V6Djt3f9z6/451847+vDOdcyGlu0aLGOh718aNGixQVDGxRatGixhjYotGjRYg1tUGjRosUa2qDQokWLNbRBoUWLFmtog0KLFi3W0AaFFi1arOH/B6QuOOMJBEExAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[239,\n",
       " 99,\n",
       " 8,\n",
       " 210,\n",
       " 201,\n",
       " 120,\n",
       " 69,\n",
       " 35,\n",
       " 250,\n",
       " 150,\n",
       " 121,\n",
       " 1,\n",
       " 13,\n",
       " 68,\n",
       " 154,\n",
       " 159,\n",
       " 226,\n",
       " 91,\n",
       " 103,\n",
       " 168,\n",
       " 128,\n",
       " 170,\n",
       " 209,\n",
       " 48,\n",
       " 50,\n",
       " 97,\n",
       " 134,\n",
       " 102,\n",
       " 122,\n",
       " 166,\n",
       " 107,\n",
       " 130,\n",
       " 138,\n",
       " 52,\n",
       " 40,\n",
       " 33,\n",
       " 20,\n",
       " 104,\n",
       " 63,\n",
       " 246,\n",
       " 192,\n",
       " 179,\n",
       " 236,\n",
       " 206,\n",
       " 147,\n",
       " 53,\n",
       " 108,\n",
       " 77,\n",
       " 125,\n",
       " 84,\n",
       " 98,\n",
       " 175,\n",
       " 116,\n",
       " 184,\n",
       " 28,\n",
       " 11,\n",
       " 81,\n",
       " 41,\n",
       " 27,\n",
       " 190,\n",
       " 44,\n",
       " 85,\n",
       " 167,\n",
       " 67,\n",
       " 26,\n",
       " 243,\n",
       " 256,\n",
       " 205,\n",
       " 113,\n",
       " 3]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item[1] for item in sorted(darkmatter_idx)][:70] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
