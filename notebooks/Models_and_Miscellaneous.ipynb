{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('../src/')\n",
    "from src import utils\n",
    "from src import generators\n",
    "import imp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_LoadWeights = '../data/trainings/train_UNETA_noaug_/vgg_1.pkl'\n",
    "mvcnn = torch.load(model_LoadWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patient_information = utils.get_PatientInfo('/home/alex/Dataset3/', test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = generators.SEPGenerator(base_DatabasePath='/home/alex/Dataset3/', \n",
    "                                channels=1,\n",
    "                                resize=296,\n",
    "                                normalization='min-max')\n",
    "test_generator = sep.generator(test_patient_information, dataset='test')       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.6014]], device='cuda:0') 8892\n",
      "tensor([[2.6014]], device='cuda:0') 9594\n",
      "tensor([[2.6014]], device='cuda:0') 9650\n",
      "tensor([[2.6014]], device='cuda:0') 9717\n",
      "tensor([[2.6014]], device='cuda:0') 9809\n",
      "tensor([[2.5456]], device='cuda:0') 9954\n",
      "tensor([[2.6014]], device='cuda:0') 10208\n",
      "tensor([[2.6014]], device='cuda:0') 10384\n",
      "tensor([[2.6014]], device='cuda:0') 10530\n",
      "tensor([[2.6014]], device='cuda:0') 10557\n",
      "tensor([[2.6014]], device='cuda:0') 10668\n",
      "tensor([[2.6014]], device='cuda:0') 10694\n",
      "tensor([[2.6014]], device='cuda:0') 10735\n",
      "tensor([[2.8682]], device='cuda:0') 10801\n",
      "tensor([[2.8682]], device='cuda:0') 10864\n",
      "tensor([[2.6014]], device='cuda:0') 10879\n",
      "tensor([[2.6014]], device='cuda:0') 10919\n",
      "tensor([[2.6014]], device='cuda:0') 11043\n",
      "tensor([[2.8682]], device='cuda:0') 11147\n",
      "tensor([[2.8682]], device='cuda:0') 11165\n",
      "tensor([[2.6014]], device='cuda:0') 11218\n",
      "tensor([[2.6014]], device='cuda:0') 11234\n",
      "tensor([[2.5456]], device='cuda:0') 11339\n",
      "tensor([[2.6014]], device='cuda:0') 11357\n",
      "tensor([[2.6014]], device='cuda:0') 11386\n",
      "tensor([[2.6014]], device='cuda:0') 11408\n",
      "tensor([[2.5456]], device='cuda:0') 11428\n",
      "tensor([[2.6014]], device='cuda:0') 11458\n",
      "tensor([[2.5456]], device='cuda:0') 11475\n",
      "tensor([[2.6014]], device='cuda:0') 11487\n",
      "tensor([[2.6014]], device='cuda:0') 11509\n",
      "tensor([[2.6014]], device='cuda:0') 11750\n",
      "tensor([[2.6014]], device='cuda:0') 11773\n",
      "tensor([[2.5456]], device='cuda:0') 11788\n",
      "tensor([[2.8682]], device='cuda:0') 11807\n",
      "tensor([[2.5456]], device='cuda:0') 11954\n",
      "tensor([[2.6014]], device='cuda:0') 11963\n",
      "tensor([[2.6014]], device='cuda:0') 11982\n",
      "tensor([[2.8123]], device='cuda:0') 12035\n",
      "tensor([[2.8682]], device='cuda:0') 12068\n",
      "tensor([[2.6014]], device='cuda:0') 12148\n",
      "tensor([[2.6014]], device='cuda:0') 12335\n",
      "tensor([[2.6014]], device='cuda:0') 12352\n",
      "tensor([[2.8682]], device='cuda:0') 12439\n",
      "tensor([[2.6014]], device='cuda:0') 12519\n",
      "tensor([[2.6014]], device='cuda:0') 12563\n",
      "tensor([[2.5456]], device='cuda:0') 13074\n",
      "tensor([[2.6014]], device='cuda:0') 13160\n",
      "tensor([[2.6014]], device='cuda:0') 13239\n",
      "tensor([[2.5456]], device='cuda:0') 13272\n",
      "tensor([[2.6014]], device='cuda:0') 13304\n",
      "tensor([[2.6014]], device='cuda:0') 13540\n",
      "tensor([[2.6014]], device='cuda:0') 13595\n",
      "tensor([[2.8682]], device='cuda:0') 13604\n",
      "tensor([[2.6014]], device='cuda:0') 13791\n",
      "tensor([[2.5456]], device='cuda:0') 13850\n",
      "tensor([[2.6014]], device='cuda:0') 13854\n",
      "tensor([[2.6014]], device='cuda:0') 13855\n",
      "tensor([[2.6014]], device='cuda:0') 13870\n",
      "tensor([[2.5456]], device='cuda:0') 13920\n",
      "tensor([[2.5456]], device='cuda:0') 13975\n",
      "tensor([[2.6014]], device='cuda:0') 13980\n",
      "tensor([[2.6014]], device='cuda:0') 14030\n",
      "tensor([[2.6014]], device='cuda:0') 14033\n",
      "tensor([[2.6014]], device='cuda:0') 14072\n",
      "tensor([[2.6014]], device='cuda:0') 14109\n",
      "tensor([[2.6014]], device='cuda:0') 14128\n",
      "tensor([[2.6014]], device='cuda:0') 14437\n",
      "tensor([[2.6014]], device='cuda:0') 14701\n",
      "tensor([[2.6014]], device='cuda:0') 14913\n",
      "tensor([[2.6014]], device='cuda:0') 14938\n",
      "tensor([[2.6014]], device='cuda:0') 15396\n",
      "tensor([[2.8682]], device='cuda:0') 15410\n",
      "tensor([[2.6014]], device='cuda:0') 15424\n",
      "tensor([[2.5456]], device='cuda:0') 15484\n",
      "tensor([[2.6014]], device='cuda:0') 15772\n",
      "tensor([[2.6014]], device='cuda:0') 16080\n",
      "tensor([[2.6014]], device='cuda:0') 16140\n",
      "tensor([[2.6014]], device='cuda:0') 16171\n",
      "tensor([[2.6014]], device='cuda:0') 16192\n",
      "tensor([[2.8682]], device='cuda:0') 16219\n",
      "tensor([[2.6014]], device='cuda:0') 16221\n",
      "tensor([[2.5456]], device='cuda:0') 16226\n",
      "tensor([[2.6014]], device='cuda:0') 16309\n",
      "tensor([[2.8682]], device='cuda:0') 16312\n",
      "tensor([[2.6014]], device='cuda:0') 16314\n",
      "tensor([[2.6014]], device='cuda:0') 16352\n",
      "tensor([[2.6014]], device='cuda:0') 16360\n",
      "tensor([[2.5456]], device='cuda:0') 16413\n",
      "tensor([[2.6014]], device='cuda:0') 16466\n",
      "tensor([[2.6014]], device='cuda:0') 16640\n",
      "tensor([[2.6014]], device='cuda:0') 16822\n",
      "tensor([[2.5456]], device='cuda:0') 16828\n",
      "tensor([[2.6014]], device='cuda:0') 17108\n",
      "tensor([[2.6014]], device='cuda:0') 18065\n",
      "tensor([[2.6014]], device='cuda:0') 18067\n",
      "tensor([[2.6014]], device='cuda:0') 18076\n",
      "tensor([[2.5456]], device='cuda:0') 18079\n",
      "tensor([[2.6014]], device='cuda:0') 18119\n",
      "tensor([[2.6014]], device='cuda:0') 18199\n",
      "tensor([[2.5456]], device='cuda:0') 18210\n",
      "tensor([[2.6014]], device='cuda:0') 18216\n",
      "tensor([[2.5456]], device='cuda:0') 18318\n",
      "tensor([[2.6014]], device='cuda:0') 18349\n",
      "tensor([[2.6014]], device='cuda:0') 18356\n",
      "tensor([[2.6014]], device='cuda:0') 18517\n",
      "tensor([[2.6014]], device='cuda:0') 18527\n",
      "tensor([[2.8682]], device='cuda:0') 18543\n",
      "tensor([[2.6014]], device='cuda:0') 18550\n",
      "tensor([[2.5456]], device='cuda:0') 18586\n",
      "tensor([[2.6014]], device='cuda:0') 18682\n",
      "tensor([[2.6014]], device='cuda:0') 18683\n",
      "tensor([[2.5456]], device='cuda:0') 18735\n",
      "tensor([[2.6014]], device='cuda:0') 18814\n",
      "tensor([[2.6014]], device='cuda:0') 18823\n",
      "tensor([[2.8682]], device='cuda:0') 19361\n",
      "tensor([[2.6014]], device='cuda:0') 19397\n",
      "tensor([[2.6014]], device='cuda:0') 19412\n",
      "tensor([[2.6014]], device='cuda:0') 19423\n",
      "tensor([[2.6014]], device='cuda:0') 19560\n",
      "tensor([[2.6014]], device='cuda:0') 19574\n",
      "tensor([[2.8682]], device='cuda:0') 19626\n",
      "tensor([[2.8682]], device='cuda:0') 19689\n",
      "tensor([[2.6014]], device='cuda:0') 19746\n",
      "tensor([[2.6014]], device='cuda:0') 19752\n",
      "tensor([[2.5456]], device='cuda:0') 19762\n",
      "tensor([[2.8682]], device='cuda:0') 19915\n",
      "tensor([[2.6014]], device='cuda:0') 20045\n",
      "tensor([[2.5456]], device='cuda:0') 20080\n",
      "tensor([[2.6014]], device='cuda:0') 20254\n",
      "tensor([[2.6014]], device='cuda:0') 20770\n",
      "tensor([[2.5456]], device='cuda:0') 20811\n",
      "tensor([[2.6014]], device='cuda:0') 20830\n",
      "tensor([[2.6014]], device='cuda:0') 20854\n",
      "tensor([[2.6014]], device='cuda:0') 20907\n",
      "tensor([[2.5456]], device='cuda:0') 20909\n",
      "tensor([[2.6014]], device='cuda:0') 20913\n",
      "tensor([[2.6014]], device='cuda:0') 21048\n",
      "tensor([[2.6014]], device='cuda:0') 21115\n",
      "tensor([[2.6014]], device='cuda:0') 21120\n",
      "tensor([[2.6014]], device='cuda:0') 21122\n",
      "tensor([[2.6014]], device='cuda:0') 21140\n",
      "tensor([[2.6014]], device='cuda:0') 21142\n",
      "tensor([[2.6014]], device='cuda:0') 21146\n",
      "tensor([[2.6014]], device='cuda:0') 21149\n",
      "tensor([[2.5456]], device='cuda:0') 21165\n",
      "tensor([[2.6014]], device='cuda:0') 21166\n",
      "tensor([[2.6014]], device='cuda:0') 21168\n",
      "tensor([[2.6014]], device='cuda:0') 21172\n",
      "tensor([[2.6014]], device='cuda:0') 21198\n",
      "tensor([[2.6014]], device='cuda:0') 21200\n",
      "tensor([[2.5456]], device='cuda:0') 21201\n",
      "tensor([[2.5456]], device='cuda:0') 21202\n",
      "tensor([[2.6014]], device='cuda:0') 21245\n",
      "tensor([[2.5456]], device='cuda:0') 21246\n",
      "tensor([[2.8682]], device='cuda:0') 21248\n",
      "tensor([[2.6014]], device='cuda:0') 21253\n",
      "tensor([[2.6014]], device='cuda:0') 21328\n",
      "tensor([[2.6014]], device='cuda:0') 21339\n",
      "tensor([[2.6014]], device='cuda:0') 21608\n",
      "tensor([[2.6014]], device='cuda:0') 21609\n",
      "tensor([[2.6014]], device='cuda:0') 21682\n",
      "tensor([[2.6014]], device='cuda:0') 21850\n",
      "tensor([[2.6014]], device='cuda:0') 21893\n",
      "tensor([[2.6014]], device='cuda:0') 21897\n",
      "tensor([[2.6014]], device='cuda:0') 22098\n",
      "tensor([[2.6014]], device='cuda:0') 22136\n",
      "tensor([[2.6014]], device='cuda:0') 22170\n",
      "tensor([[2.6014]], device='cuda:0') 22234\n",
      "tensor([[2.6014]], device='cuda:0') 22307\n",
      "tensor([[2.6014]], device='cuda:0') 22329\n",
      "tensor([[2.6014]], device='cuda:0') 22353\n",
      "tensor([[2.6014]], device='cuda:0') 22383\n",
      "tensor([[2.6014]], device='cuda:0') 22548\n",
      "tensor([[2.6014]], device='cuda:0') 22665\n",
      "tensor([[2.6014]], device='cuda:0') 22703\n",
      "tensor([[2.6014]], device='cuda:0') 22785\n",
      "tensor([[2.6014]], device='cuda:0') 23951\n",
      "tensor([[2.6014]], device='cuda:0') 24130\n",
      "tensor([[2.6014]], device='cuda:0') 24142\n",
      "tensor([[2.8682]], device='cuda:0') 24150\n",
      "tensor([[2.6014]], device='cuda:0') 24198\n",
      "tensor([[2.5456]], device='cuda:0') 24479\n",
      "tensor([[2.8682]], device='cuda:0') 24731\n",
      "tensor([[2.6014]], device='cuda:0') 24760\n",
      "tensor([[2.5456]], device='cuda:0') 24761\n",
      "tensor([[2.5456]], device='cuda:0') 24820\n",
      "tensor([[2.6014]], device='cuda:0') 24847\n",
      "tensor([[2.6014]], device='cuda:0') 24945\n",
      "tensor([[2.6014]], device='cuda:0') 25006\n",
      "tensor([[2.6014]], device='cuda:0') 25038\n",
      "tensor([[2.8682]], device='cuda:0') 25056\n",
      "tensor([[2.8682]], device='cuda:0') 25386\n",
      "tensor([[2.5456]], device='cuda:0') 25601\n",
      "tensor([[2.6014]], device='cuda:0') 25643\n",
      "tensor([[2.6014]], device='cuda:0') 25718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.6014]], device='cuda:0') 25790\n",
      "tensor([[2.6014]], device='cuda:0') 25953\n",
      "tensor([[2.6014]], device='cuda:0') 26321\n",
      "tensor([[2.6014]], device='cuda:0') 26353\n",
      "tensor([[2.6014]], device='cuda:0') 26427\n",
      "tensor([[2.5456]], device='cuda:0') 26443\n",
      "tensor([[2.6014]], device='cuda:0') 26607\n",
      "tensor([[2.8682]], device='cuda:0') 26617\n",
      "tensor([[2.6014]], device='cuda:0') 26701\n",
      "tensor([[2.6014]], device='cuda:0') 26730\n",
      "tensor([[2.6014]], device='cuda:0') 26773\n",
      "tensor([[2.6014]], device='cuda:0') 26791\n",
      "tensor([[2.6014]], device='cuda:0') 26818\n",
      "tensor([[2.8682]], device='cuda:0') 26823\n",
      "tensor([[2.6014]], device='cuda:0') 26833\n",
      "tensor([[2.6014]], device='cuda:0') 26875\n",
      "tensor([[2.6014]], device='cuda:0') 26934\n",
      "tensor([[2.6014]], device='cuda:0') 26943\n",
      "tensor([[2.6014]], device='cuda:0') 26960\n",
      "tensor([[2.6014]], device='cuda:0') 26971\n",
      "tensor([[2.6014]], device='cuda:0') 27018\n",
      "tensor([[2.8682]], device='cuda:0') 27026\n",
      "tensor([[2.6014]], device='cuda:0') 27054\n",
      "tensor([[2.6014]], device='cuda:0') 27077\n",
      "tensor([[2.8682]], device='cuda:0') 27079\n",
      "tensor([[2.6014]], device='cuda:0') 27084\n",
      "tensor([[2.8682]], device='cuda:0') 27115\n",
      "tensor([[2.6014]], device='cuda:0') 27147\n",
      "tensor([[2.8123]], device='cuda:0') 27158\n",
      "tensor([[2.6014]], device='cuda:0') 27242\n",
      "tensor([[2.6014]], device='cuda:0') 27276\n",
      "tensor([[2.6014]], device='cuda:0') 27284\n",
      "tensor([[2.6014]], device='cuda:0') 27321\n",
      "tensor([[2.5456]], device='cuda:0') 27339\n",
      "tensor([[2.6014]], device='cuda:0') 27392\n",
      "tensor([[2.6014]], device='cuda:0') 27488\n",
      "tensor([[2.6014]], device='cuda:0') 27500\n",
      "tensor([[2.5456]], device='cuda:0') 27512\n",
      "tensor([[2.6014]], device='cuda:0') 27522\n",
      "tensor([[2.6014]], device='cuda:0') 27555\n",
      "tensor([[2.8682]], device='cuda:0') 27619\n",
      "tensor([[2.6014]], device='cuda:0') 27638\n",
      "tensor([[2.6014]], device='cuda:0') 27655\n",
      "tensor([[2.6014]], device='cuda:0') 27664\n",
      "tensor([[2.6014]], device='cuda:0') 27720\n",
      "tensor([[2.6014]], device='cuda:0') 27738\n",
      "tensor([[2.6014]], device='cuda:0') 27769\n",
      "tensor([[2.6014]], device='cuda:0') 27791\n",
      "tensor([[2.6014]], device='cuda:0') 27801\n",
      "tensor([[2.6014]], device='cuda:0') 27890\n",
      "tensor([[2.6014]], device='cuda:0') 27914\n",
      "tensor([[2.6014]], device='cuda:0') 27947\n",
      "tensor([[2.6014]], device='cuda:0') 28156\n",
      "tensor([[2.6014]], device='cuda:0') 28166\n",
      "tensor([[2.5456]], device='cuda:0') 28230\n",
      "tensor([[2.6014]], device='cuda:0') 28233\n",
      "tensor([[2.6014]], device='cuda:0') 28257\n",
      "tensor([[2.6014]], device='cuda:0') 28292\n",
      "tensor([[2.8682]], device='cuda:0') 28314\n",
      "tensor([[2.6014]], device='cuda:0') 28328\n",
      "tensor([[2.6014]], device='cuda:0') 28354\n",
      "tensor([[2.6014]], device='cuda:0') 28394\n",
      "tensor([[2.6014]], device='cuda:0') 29440\n",
      "tensor([[2.6014]], device='cuda:0') 29460\n",
      "tensor([[2.8682]], device='cuda:0') 29468\n",
      "tensor([[2.6014]], device='cuda:0') 29535\n",
      "tensor([[2.6014]], device='cuda:0') 29610\n",
      "tensor([[2.6014]], device='cuda:0') 29658\n",
      "tensor([[2.6014]], device='cuda:0') 29937\n",
      "tensor([[2.6014]], device='cuda:0') 29952\n",
      "tensor([[2.5456]], device='cuda:0') 29969\n",
      "tensor([[2.6014]], device='cuda:0') 29976\n",
      "tensor([[2.6014]], device='cuda:0') 29997\n",
      "tensor([[2.6014]], device='cuda:0') 30025\n",
      "tensor([[2.6014]], device='cuda:0') 30072\n",
      "tensor([[2.6014]], device='cuda:0') 30099\n",
      "tensor([[2.6014]], device='cuda:0') 30234\n",
      "tensor([[2.6014]], device='cuda:0') 30243\n",
      "tensor([[2.6014]], device='cuda:0') 30251\n",
      "tensor([[2.6014]], device='cuda:0') 30559\n",
      "tensor([[2.6014]], device='cuda:0') 30622\n",
      "tensor([[2.6014]], device='cuda:0') 30725\n",
      "tensor([[2.6014]], device='cuda:0') 30749\n",
      "tensor([[2.6014]], device='cuda:0') 30784\n",
      "tensor([[2.5456]], device='cuda:0') 30985\n",
      "tensor([[2.6014]], device='cuda:0') 30996\n",
      "tensor([[2.6014]], device='cuda:0') 31215\n",
      "tensor([[2.6014]], device='cuda:0') 31314\n",
      "tensor([[2.6014]], device='cuda:0') 32452\n",
      "tensor([[2.6014]], device='cuda:0') 32500\n",
      "tensor([[2.6014]], device='cuda:0') 32595\n",
      "tensor([[2.8682]], device='cuda:0') 36944\n",
      "tensor([[2.6014]], device='cuda:0') 36952\n",
      "tensor([[2.6014]], device='cuda:0') 39508\n",
      "tensor([[2.6014]], device='cuda:0') 39807\n",
      "tensor([[2.6014]], device='cuda:0') 39820\n",
      "tensor([[2.6014]], device='cuda:0') 39990\n",
      "tensor([[2.6014]], device='cuda:0') 40009\n",
      "tensor([[2.5456]], device='cuda:0') 41552\n",
      "tensor([[2.6014]], device='cuda:0') 42872\n",
      "tensor([[2.6014]], device='cuda:0') 42941\n",
      "tensor([[2.6014]], device='cuda:0') 43134\n",
      "tensor([[2.6014]], device='cuda:0') 43298\n",
      "tensor([[2.6014]], device='cuda:0') 44225\n",
      "tensor([[2.6014]], device='cuda:0') 44453\n",
      "tensor([[2.6014]], device='cuda:0') 44483\n",
      "tensor([[2.8682]], device='cuda:0') 44563\n",
      "tensor([[2.6014]], device='cuda:0') 44815\n",
      "tensor([[2.5456]], device='cuda:0') 46018\n",
      "tensor([[2.5456]], device='cuda:0') 46882\n",
      "tensor([[2.6014]], device='cuda:0') 46977\n",
      "tensor([[2.6014]], device='cuda:0') 47429\n",
      "tensor([[2.6014]], device='cuda:0') 47436\n",
      "tensor([[2.5456]], device='cuda:0') 47691\n",
      "tensor([[2.6014]], device='cuda:0') 49467\n",
      "tensor([[2.6014]], device='cuda:0') 49604\n",
      "tensor([[2.6014]], device='cuda:0') 50432\n",
      "tensor([[2.6014]], device='cuda:0') 50809\n",
      "tensor([[2.6014]], device='cuda:0') 50810\n",
      "tensor([[2.8682]], device='cuda:0') 50817\n",
      "tensor([[2.8682]], device='cuda:0') 50819\n",
      "tensor([[2.6014]], device='cuda:0') 50909\n",
      "tensor([[2.6014]], device='cuda:0') 51421\n",
      "tensor([[2.8682]], device='cuda:0') 51436\n",
      "tensor([[2.6014]], device='cuda:0') 52097\n",
      "tensor([[2.6014]], device='cuda:0') 52362\n",
      "tensor([[2.6014]], device='cuda:0') 52441\n",
      "tensor([[2.6014]], device='cuda:0') 52556\n",
      "tensor([[2.6014]], device='cuda:0') 52558\n",
      "tensor([[2.6014]], device='cuda:0') 52562\n",
      "tensor([[2.6014]], device='cuda:0') 52563\n",
      "tensor([[2.6014]], device='cuda:0') 53321\n",
      "tensor([[2.6014]], device='cuda:0') 54073\n",
      "tensor([[2.6014]], device='cuda:0') 55230\n",
      "tensor([[2.6014]], device='cuda:0') 55351\n",
      "tensor([[2.5456]], device='cuda:0') 55469\n",
      "tensor([[2.6014]], device='cuda:0') 56349\n",
      "tensor([[2.8682]], device='cuda:0') 56380\n",
      "tensor([[2.6014]], device='cuda:0') 56414\n",
      "tensor([[2.6014]], device='cuda:0') 57061\n",
      "tensor([[2.6014]], device='cuda:0') 61449\n",
      "tensor([[2.6014]], device='cuda:0') 61462\n",
      "tensor([[2.6014]], device='cuda:0') 62501\n",
      "tensor([[2.6014]], device='cuda:0') 62875\n",
      "tensor([[2.6014]], device='cuda:0') 62878\n",
      "tensor([[2.6014]], device='cuda:0') 62884\n",
      "tensor([[2.6014]], device='cuda:0') 62888\n",
      "tensor([[2.5456]], device='cuda:0') 62906\n",
      "tensor([[2.6014]], device='cuda:0') 62950\n",
      "tensor([[2.6014]], device='cuda:0') 62952\n",
      "tensor([[2.6014]], device='cuda:0') 62953\n",
      "tensor([[2.8682]], device='cuda:0') 62955\n",
      "tensor([[2.6014]], device='cuda:0') 62977\n",
      "tensor([[2.6014]], device='cuda:0') 62979\n",
      "tensor([[2.6014]], device='cuda:0') 62981\n",
      "tensor([[2.6014]], device='cuda:0') 62984\n",
      "tensor([[2.8682]], device='cuda:0') 62985\n",
      "tensor([[2.6014]], device='cuda:0') 63049\n",
      "tensor([[2.6014]], device='cuda:0') 63050\n",
      "tensor([[2.6014]], device='cuda:0') 63055\n",
      "tensor([[2.5456]], device='cuda:0') 63217\n",
      "tensor([[2.6014]], device='cuda:0') 63383\n",
      "tensor([[2.6014]], device='cuda:0') 63707\n",
      "tensor([[2.6014]], device='cuda:0') 63718\n",
      "tensor([[2.8682]], device='cuda:0') 64876\n",
      "tensor([[2.6014]], device='cuda:0') 65106\n",
      "tensor([[2.6014]], device='cuda:0') 65197\n",
      "tensor([[2.6014]], device='cuda:0') 65229\n",
      "tensor([[2.5456]], device='cuda:0') 65234\n",
      "tensor([[2.6014]], device='cuda:0') 65237\n",
      "tensor([[2.6014]], device='cuda:0') 65383\n",
      "tensor([[2.6014]], device='cuda:0') 65384\n",
      "tensor([[2.8682]], device='cuda:0') 66645\n",
      "tensor([[2.8682]], device='cuda:0') 66648\n",
      "tensor([[2.6014]], device='cuda:0') 67426\n",
      "tensor([[2.6014]], device='cuda:0') 67563\n",
      "tensor([[2.6014]], device='cuda:0') 67961\n",
      "tensor([[2.6014]], device='cuda:0') 67989\n",
      "tensor([[2.8682]], device='cuda:0') 68021\n",
      "tensor([[2.6014]], device='cuda:0') 68119\n",
      "tensor([[2.5456]], device='cuda:0') 68413\n",
      "tensor([[2.6014]], device='cuda:0') 68491\n",
      "tensor([[2.6014]], device='cuda:0') 68493\n",
      "tensor([[2.6014]], device='cuda:0') 68617\n",
      "tensor([[2.6014]], device='cuda:0') 68729\n",
      "tensor([[2.5456]], device='cuda:0') 68875\n",
      "tensor([[2.6014]], device='cuda:0') 68913\n",
      "tensor([[2.6014]], device='cuda:0') 68944\n",
      "tensor([[2.6014]], device='cuda:0') 69100\n",
      "tensor([[2.6014]], device='cuda:0') 69101\n",
      "tensor([[2.8682]], device='cuda:0') 69106\n",
      "tensor([[2.6014]], device='cuda:0') 69598\n",
      "tensor([[2.6014]], device='cuda:0') 69599\n",
      "tensor([[2.6014]], device='cuda:0') 69601\n",
      "tensor([[2.6014]], device='cuda:0') 69602\n",
      "tensor([[2.6014]], device='cuda:0') 69653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.6014]], device='cuda:0') 69731\n",
      "tensor([[2.6014]], device='cuda:0') 69838\n",
      "tensor([[2.6014]], device='cuda:0') 70058\n",
      "tensor([[2.6014]], device='cuda:0') 70834\n",
      "tensor([[2.6014]], device='cuda:0') 70874\n",
      "tensor([[2.6014]], device='cuda:0') 71326\n",
      "tensor([[2.6014]], device='cuda:0') 71505\n",
      "tensor([[2.6014]], device='cuda:0') 73042\n",
      "tensor([[2.6014]], device='cuda:0') 73056\n",
      "tensor([[2.6014]], device='cuda:0') 73105\n",
      "tensor([[2.8682]], device='cuda:0') 73111\n",
      "tensor([[2.6014]], device='cuda:0') 73123\n",
      "tensor([[2.6014]], device='cuda:0') 73305\n",
      "tensor([[2.6014]], device='cuda:0') 74160\n",
      "tensor([[2.6014]], device='cuda:0') 74216\n",
      "tensor([[2.6014]], device='cuda:0') 74460\n",
      "tensor([[2.6014]], device='cuda:0') 74782\n",
      "tensor([[2.6014]], device='cuda:0') 75020\n",
      "tensor([[2.6014]], device='cuda:0') 75095\n",
      "tensor([[2.6014]], device='cuda:0') 75168\n",
      "tensor([[2.6014]], device='cuda:0') 75480\n",
      "tensor([[2.6014]], device='cuda:0') 75502\n",
      "tensor([[2.6014]], device='cuda:0') 76067\n",
      "tensor([[2.6014]], device='cuda:0') 76081\n",
      "tensor([[2.6014]], device='cuda:0') 76197\n",
      "tensor([[2.8682]], device='cuda:0') 76205\n",
      "tensor([[2.6014]], device='cuda:0') 76501\n",
      "tensor([[2.6014]], device='cuda:0') 76566\n",
      "tensor([[2.5456]], device='cuda:0') 77007\n",
      "tensor([[2.6014]], device='cuda:0') 77680\n",
      "tensor([[2.6014]], device='cuda:0') 77754\n",
      "tensor([[2.6014]], device='cuda:0') 80228\n",
      "tensor([[2.6014]], device='cuda:0') 80463\n",
      "tensor([[2.5456]], device='cuda:0') 80464\n",
      "tensor([[2.6014]], device='cuda:0') 80466\n",
      "tensor([[2.6014]], device='cuda:0') 80467\n",
      "tensor([[2.6014]], device='cuda:0') 81454\n",
      "tensor([[2.6014]], device='cuda:0') 81679\n",
      "tensor([[2.5456]], device='cuda:0') 81818\n",
      "tensor([[2.5456]], device='cuda:0') 82021\n",
      "tensor([[2.5456]], device='cuda:0') 82028\n",
      "tensor([[2.6014]], device='cuda:0') 82030\n",
      "tensor([[2.6014]], device='cuda:0') 82499\n",
      "tensor([[2.6014]], device='cuda:0') 82509\n",
      "tensor([[2.6014]], device='cuda:0') 83451\n",
      "tensor([[2.6014]], device='cuda:0') 84937\n",
      "tensor([[2.6014]], device='cuda:0') 84999\n",
      "tensor([[2.6014]], device='cuda:0') 86594\n",
      "tensor([[2.6014]], device='cuda:0') 87329\n",
      "tensor([[2.6014]], device='cuda:0') 87331\n",
      "tensor([[2.6014]], device='cuda:0') 87332\n",
      "tensor([[2.6014]], device='cuda:0') 87334\n",
      "tensor([[2.6014]], device='cuda:0') 87509\n",
      "tensor([[2.6014]], device='cuda:0') 87515\n",
      "tensor([[2.6014]], device='cuda:0') 87734\n",
      "tensor([[2.6014]], device='cuda:0') 87781\n",
      "tensor([[2.6014]], device='cuda:0') 88755\n",
      "tensor([[2.6014]], device='cuda:0') 90203\n",
      "tensor([[2.6014]], device='cuda:0') 90626\n",
      "tensor([[2.6014]], device='cuda:0') 91594\n",
      "tensor([[2.6014]], device='cuda:0') 91959\n",
      "tensor([[2.6014]], device='cuda:0') 92089\n",
      "tensor([[2.5456]], device='cuda:0') 93329\n",
      "tensor([[2.6014]], device='cuda:0') 93361\n",
      "tensor([[2.6014]], device='cuda:0') 93598\n",
      "tensor([[2.8682]], device='cuda:0') 93763\n",
      "tensor([[2.6014]], device='cuda:0') 94074\n",
      "tensor([[2.6014]], device='cuda:0') 94276\n",
      "tensor([[2.6014]], device='cuda:0') 94277\n",
      "tensor([[2.6014]], device='cuda:0') 94312\n",
      "tensor([[2.8682]], device='cuda:0') 94384\n",
      "tensor([[2.8682]], device='cuda:0') 94477\n",
      "tensor([[2.6014]], device='cuda:0') 94486\n",
      "tensor([[2.6014]], device='cuda:0') 94715\n",
      "tensor([[2.8682]], device='cuda:0') 95901\n",
      "tensor([[2.6014]], device='cuda:0') 96207\n",
      "tensor([[2.6014]], device='cuda:0') 96628\n",
      "tensor([[2.6014]], device='cuda:0') 97575\n",
      "tensor([[2.6014]], device='cuda:0') 97577\n",
      "tensor([[2.6014]], device='cuda:0') 98316\n",
      "tensor([[2.6014]], device='cuda:0') 99106\n",
      "tensor([[2.6014]], device='cuda:0') 100036\n",
      "tensor([[2.6014]], device='cuda:0') 100111\n"
     ]
    }
   ],
   "source": [
    "final = []\n",
    "with torch.no_grad():\n",
    "    for v_m, v_item in enumerate(test_generator):\n",
    "        image_3D, p_id = torch.tensor(v_item[0], device=device).float(), v_item[1]\n",
    "        if image_3D.shape[0] == 0:\n",
    "            print(p_id)\n",
    "            continue\n",
    "        output = mvcnn(image_3D, batch_size=1, mvcnn=True)\n",
    "        print(output, p_id)\n",
    "        final.append((p_id, output.to('cpu').detach().numpy()))\n",
    "        if v_m == len(test_patient_information) - 1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csvData = [[[\"Sequence_id\"],[\"EDSS\"]]] + list(map(lambda a: [[int(a[0])],[a[1][0][0]]], (final)))\n",
    "with open('AZmed_2.csv', 'w') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerows(csvData)\n",
    "csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Sequence_id'], ['EDSS']],\n",
       " [[8892], [2.601406]],\n",
       " [[9594], [2.601406]],\n",
       " [[9650], [2.601406]],\n",
       " [[9717], [2.601406]],\n",
       " [[9809], [2.601406]],\n",
       " [[9954], [2.5455647]],\n",
       " [[10208], [2.601406]],\n",
       " [[10384], [2.601406]],\n",
       " [[10530], [2.601406]],\n",
       " [[10557], [2.601406]],\n",
       " [[10668], [2.601406]],\n",
       " [[10694], [2.601406]],\n",
       " [[10735], [2.601406]],\n",
       " [[10801], [2.8681633]],\n",
       " [[10864], [2.8681633]],\n",
       " [[10879], [2.601406]],\n",
       " [[10919], [2.601406]],\n",
       " [[11043], [2.601406]],\n",
       " [[11147], [2.8681633]],\n",
       " [[11165], [2.8681633]],\n",
       " [[11218], [2.601406]],\n",
       " [[11234], [2.601406]],\n",
       " [[11339], [2.5455647]],\n",
       " [[11357], [2.601406]],\n",
       " [[11386], [2.601406]],\n",
       " [[11408], [2.601406]],\n",
       " [[11428], [2.5455647]],\n",
       " [[11458], [2.601406]],\n",
       " [[11475], [2.5455647]],\n",
       " [[11487], [2.601406]],\n",
       " [[11509], [2.601406]],\n",
       " [[11750], [2.601406]],\n",
       " [[11773], [2.601406]],\n",
       " [[11788], [2.5455647]],\n",
       " [[11807], [2.8681633]],\n",
       " [[11954], [2.5455647]],\n",
       " [[11963], [2.601406]],\n",
       " [[11982], [2.601406]],\n",
       " [[12035], [2.812322]],\n",
       " [[12068], [2.8681633]],\n",
       " [[12148], [2.601406]],\n",
       " [[12335], [2.601406]],\n",
       " [[12352], [2.601406]],\n",
       " [[12439], [2.8681633]],\n",
       " [[12519], [2.601406]],\n",
       " [[12563], [2.601406]],\n",
       " [[13074], [2.5455647]],\n",
       " [[13160], [2.601406]],\n",
       " [[13239], [2.601406]],\n",
       " [[13272], [2.5455647]],\n",
       " [[13304], [2.601406]],\n",
       " [[13540], [2.601406]],\n",
       " [[13595], [2.601406]],\n",
       " [[13604], [2.8681633]],\n",
       " [[13791], [2.601406]],\n",
       " [[13850], [2.5455647]],\n",
       " [[13854], [2.601406]],\n",
       " [[13855], [2.601406]],\n",
       " [[13870], [2.601406]],\n",
       " [[13920], [2.5455647]],\n",
       " [[13975], [2.5455647]],\n",
       " [[13980], [2.601406]],\n",
       " [[14030], [2.601406]],\n",
       " [[14033], [2.601406]],\n",
       " [[14072], [2.601406]],\n",
       " [[14109], [2.601406]],\n",
       " [[14128], [2.601406]],\n",
       " [[14437], [2.601406]],\n",
       " [[14701], [2.601406]],\n",
       " [[14913], [2.601406]],\n",
       " [[14938], [2.601406]],\n",
       " [[15396], [2.601406]],\n",
       " [[15410], [2.8681633]],\n",
       " [[15424], [2.601406]],\n",
       " [[15484], [2.5455647]],\n",
       " [[15772], [2.601406]],\n",
       " [[16080], [2.601406]],\n",
       " [[16140], [2.601406]],\n",
       " [[16171], [2.601406]],\n",
       " [[16192], [2.601406]],\n",
       " [[16219], [2.8681633]],\n",
       " [[16221], [2.601406]],\n",
       " [[16226], [2.5455647]],\n",
       " [[16309], [2.601406]],\n",
       " [[16312], [2.8681633]],\n",
       " [[16314], [2.601406]],\n",
       " [[16352], [2.601406]],\n",
       " [[16360], [2.601406]],\n",
       " [[16413], [2.5455647]],\n",
       " [[16466], [2.601406]],\n",
       " [[16640], [2.601406]],\n",
       " [[16822], [2.601406]],\n",
       " [[16828], [2.5455647]],\n",
       " [[17108], [2.601406]],\n",
       " [[18065], [2.601406]],\n",
       " [[18067], [2.601406]],\n",
       " [[18076], [2.601406]],\n",
       " [[18079], [2.5455647]],\n",
       " [[18119], [2.601406]],\n",
       " [[18199], [2.601406]],\n",
       " [[18210], [2.5455647]],\n",
       " [[18216], [2.601406]],\n",
       " [[18318], [2.5455647]],\n",
       " [[18349], [2.601406]],\n",
       " [[18356], [2.601406]],\n",
       " [[18517], [2.601406]],\n",
       " [[18527], [2.601406]],\n",
       " [[18543], [2.8681633]],\n",
       " [[18550], [2.601406]],\n",
       " [[18586], [2.5455647]],\n",
       " [[18682], [2.601406]],\n",
       " [[18683], [2.601406]],\n",
       " [[18735], [2.5455647]],\n",
       " [[18814], [2.601406]],\n",
       " [[18823], [2.601406]],\n",
       " [[19361], [2.8681633]],\n",
       " [[19397], [2.601406]],\n",
       " [[19412], [2.601406]],\n",
       " [[19423], [2.601406]],\n",
       " [[19560], [2.601406]],\n",
       " [[19574], [2.601406]],\n",
       " [[19626], [2.8681633]],\n",
       " [[19689], [2.8681633]],\n",
       " [[19746], [2.601406]],\n",
       " [[19752], [2.601406]],\n",
       " [[19762], [2.5455647]],\n",
       " [[19915], [2.8681633]],\n",
       " [[20045], [2.601406]],\n",
       " [[20080], [2.5455647]],\n",
       " [[20254], [2.601406]],\n",
       " [[20770], [2.601406]],\n",
       " [[20811], [2.5455647]],\n",
       " [[20830], [2.601406]],\n",
       " [[20854], [2.601406]],\n",
       " [[20907], [2.601406]],\n",
       " [[20909], [2.5455647]],\n",
       " [[20913], [2.601406]],\n",
       " [[21048], [2.601406]],\n",
       " [[21115], [2.601406]],\n",
       " [[21120], [2.601406]],\n",
       " [[21122], [2.601406]],\n",
       " [[21140], [2.601406]],\n",
       " [[21142], [2.601406]],\n",
       " [[21146], [2.601406]],\n",
       " [[21149], [2.601406]],\n",
       " [[21165], [2.5455647]],\n",
       " [[21166], [2.601406]],\n",
       " [[21168], [2.601406]],\n",
       " [[21172], [2.601406]],\n",
       " [[21198], [2.601406]],\n",
       " [[21200], [2.601406]],\n",
       " [[21201], [2.5455647]],\n",
       " [[21202], [2.5455647]],\n",
       " [[21245], [2.601406]],\n",
       " [[21246], [2.5455647]],\n",
       " [[21248], [2.8681633]],\n",
       " [[21253], [2.601406]],\n",
       " [[21328], [2.601406]],\n",
       " [[21339], [2.601406]],\n",
       " [[21608], [2.601406]],\n",
       " [[21609], [2.601406]],\n",
       " [[21682], [2.601406]],\n",
       " [[21850], [2.601406]],\n",
       " [[21893], [2.601406]],\n",
       " [[21897], [2.601406]],\n",
       " [[22098], [2.601406]],\n",
       " [[22136], [2.601406]],\n",
       " [[22170], [2.601406]],\n",
       " [[22234], [2.601406]],\n",
       " [[22307], [2.601406]],\n",
       " [[22329], [2.601406]],\n",
       " [[22353], [2.601406]],\n",
       " [[22383], [2.601406]],\n",
       " [[22548], [2.601406]],\n",
       " [[22665], [2.601406]],\n",
       " [[22703], [2.601406]],\n",
       " [[22785], [2.601406]],\n",
       " [[23951], [2.601406]],\n",
       " [[24130], [2.601406]],\n",
       " [[24142], [2.601406]],\n",
       " [[24150], [2.8681633]],\n",
       " [[24198], [2.601406]],\n",
       " [[24479], [2.5455647]],\n",
       " [[24731], [2.8681633]],\n",
       " [[24760], [2.601406]],\n",
       " [[24761], [2.5455647]],\n",
       " [[24820], [2.5455647]],\n",
       " [[24847], [2.601406]],\n",
       " [[24945], [2.601406]],\n",
       " [[25006], [2.601406]],\n",
       " [[25038], [2.601406]],\n",
       " [[25056], [2.8681633]],\n",
       " [[25386], [2.8681633]],\n",
       " [[25601], [2.5455647]],\n",
       " [[25643], [2.601406]],\n",
       " [[25718], [2.601406]],\n",
       " [[25790], [2.601406]],\n",
       " [[25953], [2.601406]],\n",
       " [[26321], [2.601406]],\n",
       " [[26353], [2.601406]],\n",
       " [[26427], [2.601406]],\n",
       " [[26443], [2.5455647]],\n",
       " [[26607], [2.601406]],\n",
       " [[26617], [2.8681633]],\n",
       " [[26701], [2.601406]],\n",
       " [[26730], [2.601406]],\n",
       " [[26773], [2.601406]],\n",
       " [[26791], [2.601406]],\n",
       " [[26818], [2.601406]],\n",
       " [[26823], [2.8681633]],\n",
       " [[26833], [2.601406]],\n",
       " [[26875], [2.601406]],\n",
       " [[26934], [2.601406]],\n",
       " [[26943], [2.601406]],\n",
       " [[26960], [2.601406]],\n",
       " [[26971], [2.601406]],\n",
       " [[27018], [2.601406]],\n",
       " [[27026], [2.8681633]],\n",
       " [[27054], [2.601406]],\n",
       " [[27077], [2.601406]],\n",
       " [[27079], [2.8681633]],\n",
       " [[27084], [2.601406]],\n",
       " [[27115], [2.8681633]],\n",
       " [[27147], [2.601406]],\n",
       " [[27158], [2.812322]],\n",
       " [[27242], [2.601406]],\n",
       " [[27276], [2.601406]],\n",
       " [[27284], [2.601406]],\n",
       " [[27321], [2.601406]],\n",
       " [[27339], [2.5455647]],\n",
       " [[27392], [2.601406]],\n",
       " [[27488], [2.601406]],\n",
       " [[27500], [2.601406]],\n",
       " [[27512], [2.5455647]],\n",
       " [[27522], [2.601406]],\n",
       " [[27555], [2.601406]],\n",
       " [[27619], [2.8681633]],\n",
       " [[27638], [2.601406]],\n",
       " [[27655], [2.601406]],\n",
       " [[27664], [2.601406]],\n",
       " [[27720], [2.601406]],\n",
       " [[27738], [2.601406]],\n",
       " [[27769], [2.601406]],\n",
       " [[27791], [2.601406]],\n",
       " [[27801], [2.601406]],\n",
       " [[27890], [2.601406]],\n",
       " [[27914], [2.601406]],\n",
       " [[27947], [2.601406]],\n",
       " [[28156], [2.601406]],\n",
       " [[28166], [2.601406]],\n",
       " [[28230], [2.5455647]],\n",
       " [[28233], [2.601406]],\n",
       " [[28257], [2.601406]],\n",
       " [[28292], [2.601406]],\n",
       " [[28314], [2.8681633]],\n",
       " [[28328], [2.601406]],\n",
       " [[28354], [2.601406]],\n",
       " [[28394], [2.601406]],\n",
       " [[29440], [2.601406]],\n",
       " [[29460], [2.601406]],\n",
       " [[29468], [2.8681633]],\n",
       " [[29535], [2.601406]],\n",
       " [[29610], [2.601406]],\n",
       " [[29658], [2.601406]],\n",
       " [[29937], [2.601406]],\n",
       " [[29952], [2.601406]],\n",
       " [[29969], [2.5455647]],\n",
       " [[29976], [2.601406]],\n",
       " [[29997], [2.601406]],\n",
       " [[30025], [2.601406]],\n",
       " [[30072], [2.601406]],\n",
       " [[30099], [2.601406]],\n",
       " [[30234], [2.601406]],\n",
       " [[30243], [2.601406]],\n",
       " [[30251], [2.601406]],\n",
       " [[30559], [2.601406]],\n",
       " [[30622], [2.601406]],\n",
       " [[30725], [2.601406]],\n",
       " [[30749], [2.601406]],\n",
       " [[30784], [2.601406]],\n",
       " [[30985], [2.5455647]],\n",
       " [[30996], [2.601406]],\n",
       " [[31215], [2.601406]],\n",
       " [[31314], [2.601406]],\n",
       " [[32452], [2.601406]],\n",
       " [[32500], [2.601406]],\n",
       " [[32595], [2.601406]],\n",
       " [[36944], [2.8681633]],\n",
       " [[36952], [2.601406]],\n",
       " [[39508], [2.601406]],\n",
       " [[39807], [2.601406]],\n",
       " [[39820], [2.601406]],\n",
       " [[39990], [2.601406]],\n",
       " [[40009], [2.601406]],\n",
       " [[41552], [2.5455647]],\n",
       " [[42872], [2.601406]],\n",
       " [[42941], [2.601406]],\n",
       " [[43134], [2.601406]],\n",
       " [[43298], [2.601406]],\n",
       " [[44225], [2.601406]],\n",
       " [[44453], [2.601406]],\n",
       " [[44483], [2.601406]],\n",
       " [[44563], [2.8681633]],\n",
       " [[44815], [2.601406]],\n",
       " [[46018], [2.5455647]],\n",
       " [[46882], [2.5455647]],\n",
       " [[46977], [2.601406]],\n",
       " [[47429], [2.601406]],\n",
       " [[47436], [2.601406]],\n",
       " [[47691], [2.5455647]],\n",
       " [[49467], [2.601406]],\n",
       " [[49604], [2.601406]],\n",
       " [[50432], [2.601406]],\n",
       " [[50809], [2.601406]],\n",
       " [[50810], [2.601406]],\n",
       " [[50817], [2.8681633]],\n",
       " [[50819], [2.8681633]],\n",
       " [[50909], [2.601406]],\n",
       " [[51421], [2.601406]],\n",
       " [[51436], [2.8681633]],\n",
       " [[52097], [2.601406]],\n",
       " [[52362], [2.601406]],\n",
       " [[52441], [2.601406]],\n",
       " [[52556], [2.601406]],\n",
       " [[52558], [2.601406]],\n",
       " [[52562], [2.601406]],\n",
       " [[52563], [2.601406]],\n",
       " [[53321], [2.601406]],\n",
       " [[54073], [2.601406]],\n",
       " [[55230], [2.601406]],\n",
       " [[55351], [2.601406]],\n",
       " [[55469], [2.5455647]],\n",
       " [[56349], [2.601406]],\n",
       " [[56380], [2.8681633]],\n",
       " [[56414], [2.601406]],\n",
       " [[57061], [2.601406]],\n",
       " [[61449], [2.601406]],\n",
       " [[61462], [2.601406]],\n",
       " [[62501], [2.601406]],\n",
       " [[62875], [2.601406]],\n",
       " [[62878], [2.601406]],\n",
       " [[62884], [2.601406]],\n",
       " [[62888], [2.601406]],\n",
       " [[62906], [2.5455647]],\n",
       " [[62950], [2.601406]],\n",
       " [[62952], [2.601406]],\n",
       " [[62953], [2.601406]],\n",
       " [[62955], [2.8681633]],\n",
       " [[62977], [2.601406]],\n",
       " [[62979], [2.601406]],\n",
       " [[62981], [2.601406]],\n",
       " [[62984], [2.601406]],\n",
       " [[62985], [2.8681633]],\n",
       " [[63049], [2.601406]],\n",
       " [[63050], [2.601406]],\n",
       " [[63055], [2.601406]],\n",
       " [[63217], [2.5455647]],\n",
       " [[63383], [2.601406]],\n",
       " [[63707], [2.601406]],\n",
       " [[63718], [2.601406]],\n",
       " [[64876], [2.8681633]],\n",
       " [[65106], [2.601406]],\n",
       " [[65197], [2.601406]],\n",
       " [[65229], [2.601406]],\n",
       " [[65234], [2.5455647]],\n",
       " [[65237], [2.601406]],\n",
       " [[65383], [2.601406]],\n",
       " [[65384], [2.601406]],\n",
       " [[66645], [2.8681633]],\n",
       " [[66648], [2.8681633]],\n",
       " [[67426], [2.601406]],\n",
       " [[67563], [2.601406]],\n",
       " [[67961], [2.601406]],\n",
       " [[67989], [2.601406]],\n",
       " [[68021], [2.8681633]],\n",
       " [[68119], [2.601406]],\n",
       " [[68413], [2.5455647]],\n",
       " [[68491], [2.601406]],\n",
       " [[68493], [2.601406]],\n",
       " [[68617], [2.601406]],\n",
       " [[68729], [2.601406]],\n",
       " [[68875], [2.5455647]],\n",
       " [[68913], [2.601406]],\n",
       " [[68944], [2.601406]],\n",
       " [[69100], [2.601406]],\n",
       " [[69101], [2.601406]],\n",
       " [[69106], [2.8681633]],\n",
       " [[69598], [2.601406]],\n",
       " [[69599], [2.601406]],\n",
       " [[69601], [2.601406]],\n",
       " [[69602], [2.601406]],\n",
       " [[69653], [2.601406]],\n",
       " [[69731], [2.601406]],\n",
       " [[69838], [2.601406]],\n",
       " [[70058], [2.601406]],\n",
       " [[70834], [2.601406]],\n",
       " [[70874], [2.601406]],\n",
       " [[71326], [2.601406]],\n",
       " [[71505], [2.601406]],\n",
       " [[73042], [2.601406]],\n",
       " [[73056], [2.601406]],\n",
       " [[73105], [2.601406]],\n",
       " [[73111], [2.8681633]],\n",
       " [[73123], [2.601406]],\n",
       " [[73305], [2.601406]],\n",
       " [[74160], [2.601406]],\n",
       " [[74216], [2.601406]],\n",
       " [[74460], [2.601406]],\n",
       " [[74782], [2.601406]],\n",
       " [[75020], [2.601406]],\n",
       " [[75095], [2.601406]],\n",
       " [[75168], [2.601406]],\n",
       " [[75480], [2.601406]],\n",
       " [[75502], [2.601406]],\n",
       " [[76067], [2.601406]],\n",
       " [[76081], [2.601406]],\n",
       " [[76197], [2.601406]],\n",
       " [[76205], [2.8681633]],\n",
       " [[76501], [2.601406]],\n",
       " [[76566], [2.601406]],\n",
       " [[77007], [2.5455647]],\n",
       " [[77680], [2.601406]],\n",
       " [[77754], [2.601406]],\n",
       " [[80228], [2.601406]],\n",
       " [[80463], [2.601406]],\n",
       " [[80464], [2.5455647]],\n",
       " [[80466], [2.601406]],\n",
       " [[80467], [2.601406]],\n",
       " [[81454], [2.601406]],\n",
       " [[81679], [2.601406]],\n",
       " [[81818], [2.5455647]],\n",
       " [[82021], [2.5455647]],\n",
       " [[82028], [2.5455647]],\n",
       " [[82030], [2.601406]],\n",
       " [[82499], [2.601406]],\n",
       " [[82509], [2.601406]],\n",
       " [[83451], [2.601406]],\n",
       " [[84937], [2.601406]],\n",
       " [[84999], [2.601406]],\n",
       " [[86594], [2.601406]],\n",
       " [[87329], [2.601406]],\n",
       " [[87331], [2.601406]],\n",
       " [[87332], [2.601406]],\n",
       " [[87334], [2.601406]],\n",
       " [[87509], [2.601406]],\n",
       " [[87515], [2.601406]],\n",
       " [[87734], [2.601406]],\n",
       " [[87781], [2.601406]],\n",
       " [[88755], [2.601406]],\n",
       " [[90203], [2.601406]],\n",
       " [[90626], [2.601406]],\n",
       " [[91594], [2.601406]],\n",
       " [[91959], [2.601406]],\n",
       " [[92089], [2.601406]],\n",
       " [[93329], [2.5455647]],\n",
       " [[93361], [2.601406]],\n",
       " [[93598], [2.601406]],\n",
       " [[93763], [2.8681633]],\n",
       " [[94074], [2.601406]],\n",
       " [[94276], [2.601406]],\n",
       " [[94277], [2.601406]],\n",
       " [[94312], [2.601406]],\n",
       " [[94384], [2.8681633]],\n",
       " [[94477], [2.8681633]],\n",
       " [[94486], [2.601406]],\n",
       " [[94715], [2.601406]],\n",
       " [[95901], [2.8681633]],\n",
       " [[96207], [2.601406]],\n",
       " [[96628], [2.601406]],\n",
       " [[97575], [2.601406]],\n",
       " [[97577], [2.601406]],\n",
       " [[98316], [2.601406]],\n",
       " [[99106], [2.601406]],\n",
       " [[100036], [2.601406]],\n",
       " [[100111], [2.601406]]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-37-5111cb93fa5b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-37-5111cb93fa5b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    database_path =\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "database_path = \n",
    "train_patient_information, valid_patient_information = get_PatientInfo(database_path)\n",
    "\n",
    "# Create train and valid generators\n",
    "sep = SEPGenerator(database_path, \n",
    "                                channels=channels,\n",
    "                                resize=resize,\n",
    "                                normalization=normalization)\n",
    "train_generator = sep.generator(train_patient_information)       \n",
    "valid_generator = sep.generator(valid_patient_information, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patient_information, valid_patient_information = get_PatientInfo(database_path)\n",
    "\n",
    "        # Create train and valid generators\n",
    "        sep = SEPGenerator(database_path, \n",
    "                                        channels=channels,\n",
    "                                        resize=resize,\n",
    "                                        normalization=normalization)\n",
    "        train_generator = sep.generator(train_patient_information)       \n",
    "        valid_generator = sep.generator(valid_patient_information, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for v_m, v_item in enumerate(valid_generator):\n",
    "        image_3D, label = torch.tensor(v_item[0], device=device).float(), torch.tensor(v_item[1], device=device).float()\n",
    "        if image_3D.shape[0] == 0:\n",
    "            continue\n",
    "        output = mvcnn(image_3D, batch_size, use_mvcnn)\n",
    "        total_ValidLoss += criterion(output, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Mode - CNN_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(VGG,self).__init__()\n",
    "        pad = 1\n",
    "        \n",
    "        self.cnn = nn.Sequential(nn.BatchNorm2d(1),\n",
    "                                     nn.Conv2d(1,32,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.BatchNorm2d(32),\n",
    "                                     nn.Conv2d(32,32,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2,2), \n",
    "        \n",
    "                                     nn.BatchNorm2d(32),\n",
    "                                     nn.Conv2d(32,64,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.BatchNorm2d(64),\n",
    "                                     nn.Conv2d(64,64,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2,2),\n",
    "                                     \n",
    "                                     nn.BatchNorm2d(64),\n",
    "                                     nn.Conv2d(64,128,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.BatchNorm2d(128),\n",
    "                                     nn.Conv2d(128,128,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2,2),\n",
    "        \n",
    "                                     nn.BatchNorm2d(128),\n",
    "                                     nn.Conv2d(128,256,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.BatchNorm2d(256),\n",
    "                                     nn.Conv2d(256,256,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2,2), \n",
    "        \n",
    "                                     nn.BatchNorm2d(256),\n",
    "                                     nn.Conv2d(256,256,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.BatchNorm2d(256),\n",
    "                                     nn.Conv2d(256,256,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2,2),\n",
    "                                     \n",
    "                                     nn.BatchNorm2d(256),\n",
    "                                     nn.Conv2d(256,512,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.BatchNorm2d(512),\n",
    "                                     nn.Conv2d(512,512,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2,2))\n",
    "  \n",
    "        self.fc1 = nn.Sequential(nn.Linear(8192, 1096), \n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Dropout(0.8),\n",
    "                                     nn.Linear(1096, 96),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Dropout(0.9),\n",
    "                                     nn.Linear(96, 1))\n",
    "\n",
    "        # self.fc2 = nn.Sequential(nn.Linear(8192, 4096), \n",
    "        #                              nn.ReLU(),\n",
    "        #                              nn.Dropout(0.8),\n",
    "        #                              nn.Linear(4096, 4096),\n",
    "        #                              nn.ReLU(),\n",
    "        #                              nn.Dropout(0.9),\n",
    "        #                              nn.Linear(4096, 1))\n",
    "        \n",
    "    def forward(self, x, batch_size=1, mvcnn=False):\n",
    "        \n",
    "        if mvcnn:\n",
    "            view_pool = []\n",
    "            # Assuming x has shape (x, 1, 299, 299)\n",
    "            for n, v in enumerate(x):\n",
    "                v = v.unsqueeze(0)\n",
    "                v = self.cnn(v)\n",
    "                v = v.view(v.size(0), 512 * 4 * 4)\n",
    "                view_pool.append(v)\n",
    "\n",
    "            pooled_view = view_pool[0]\n",
    "            for i in range(1, len(view_pool)):\n",
    "                pooled_view = torch.max(pooled_view, view_pool[i])\n",
    "\n",
    "            output = self.fc1(pooled_view)\n",
    "        \n",
    "        else:\n",
    "            x = self.cnn(x)\n",
    "            x = x.view(-1, 512 * 4* 4)\n",
    "            x = self.fc1(x)\n",
    "            output = F.sigmoid(x)\n",
    "    \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1          [-1, 1, 299, 299]               2\n",
      "            Conv2d-2         [-1, 32, 299, 299]             320\n",
      "              ReLU-3         [-1, 32, 299, 299]               0\n",
      "       BatchNorm2d-4         [-1, 32, 299, 299]              64\n",
      "            Conv2d-5         [-1, 32, 299, 299]           9,248\n",
      "              ReLU-6         [-1, 32, 299, 299]               0\n",
      "         MaxPool2d-7         [-1, 32, 149, 149]               0\n",
      "       BatchNorm2d-8         [-1, 32, 149, 149]              64\n",
      "            Conv2d-9         [-1, 64, 149, 149]          18,496\n",
      "             ReLU-10         [-1, 64, 149, 149]               0\n",
      "      BatchNorm2d-11         [-1, 64, 149, 149]             128\n",
      "           Conv2d-12         [-1, 64, 149, 149]          36,928\n",
      "             ReLU-13         [-1, 64, 149, 149]               0\n",
      "        MaxPool2d-14           [-1, 64, 74, 74]               0\n",
      "      BatchNorm2d-15           [-1, 64, 74, 74]             128\n",
      "           Conv2d-16          [-1, 128, 74, 74]          73,856\n",
      "             ReLU-17          [-1, 128, 74, 74]               0\n",
      "      BatchNorm2d-18          [-1, 128, 74, 74]             256\n",
      "           Conv2d-19          [-1, 128, 74, 74]         147,584\n",
      "             ReLU-20          [-1, 128, 74, 74]               0\n",
      "        MaxPool2d-21          [-1, 128, 37, 37]               0\n",
      "      BatchNorm2d-22          [-1, 128, 37, 37]             256\n",
      "           Conv2d-23          [-1, 256, 37, 37]         295,168\n",
      "             ReLU-24          [-1, 256, 37, 37]               0\n",
      "      BatchNorm2d-25          [-1, 256, 37, 37]             512\n",
      "           Conv2d-26          [-1, 256, 37, 37]         590,080\n",
      "             ReLU-27          [-1, 256, 37, 37]               0\n",
      "        MaxPool2d-28          [-1, 256, 18, 18]               0\n",
      "      BatchNorm2d-29          [-1, 256, 18, 18]             512\n",
      "           Conv2d-30          [-1, 256, 18, 18]         590,080\n",
      "             ReLU-31          [-1, 256, 18, 18]               0\n",
      "      BatchNorm2d-32          [-1, 256, 18, 18]             512\n",
      "           Conv2d-33          [-1, 256, 18, 18]         590,080\n",
      "             ReLU-34          [-1, 256, 18, 18]               0\n",
      "        MaxPool2d-35            [-1, 256, 9, 9]               0\n",
      "      BatchNorm2d-36            [-1, 256, 9, 9]             512\n",
      "           Conv2d-37            [-1, 512, 9, 9]       1,180,160\n",
      "             ReLU-38            [-1, 512, 9, 9]               0\n",
      "      BatchNorm2d-39            [-1, 512, 9, 9]           1,024\n",
      "           Conv2d-40            [-1, 512, 9, 9]       2,359,808\n",
      "             ReLU-41            [-1, 512, 9, 9]               0\n",
      "        MaxPool2d-42            [-1, 512, 4, 4]               0\n",
      "           Linear-43                 [-1, 1096]       8,979,528\n",
      "             ReLU-44                 [-1, 1096]               0\n",
      "          Dropout-45                 [-1, 1096]               0\n",
      "           Linear-46                   [-1, 96]         105,312\n",
      "             ReLU-47                   [-1, 96]               0\n",
      "          Dropout-48                   [-1, 96]               0\n",
      "           Linear-49                    [-1, 1]              97\n",
      "================================================================\n",
      "Total params: 14,980,715\n",
      "Trainable params: 14,980,715\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.34\n",
      "Forward/backward pass size (MB): 229.40\n",
      "Params size (MB): 57.15\n",
      "Estimated Total Size (MB): 286.89\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allwyn/venv36/lib/python3.6/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "model = VGG().to(device)\n",
    "summary(model, (1, 299, 299))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since patients have varying images, create single images where the channels occupy the slices of the patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new() received an invalid combination of arguments - got (NoneType, int), but expected one of:\n * (torch.device device)\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mNoneType\u001b[0m, \u001b[31;1mint\u001b[0m)\n * (object data, torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mNoneType\u001b[0m, \u001b[31;1mint\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-92239081e971>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmvcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMVCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-52dbad35b7d3>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_classes)\u001b[0m\n\u001b[1;32m     68\u001b[0m                                      \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                                      \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                                      nn.Linear(4096, num_classes))\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmvcnn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv36/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: new() received an invalid combination of arguments - got (NoneType, int), but expected one of:\n * (torch.device device)\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mNoneType\u001b[0m, \u001b[31;1mint\u001b[0m)\n * (object data, torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mNoneType\u001b[0m, \u001b[31;1mint\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "mvcnn = MVCNN().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(mvcnn.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/alex/Dataset 1/Dataset - 1.xlsx'\n",
    "df = pd.read_excel(file_path, sheet_name='Feuil1')\n",
    "\n",
    "edss = df['EDSS'].tolist()\n",
    "p_id = df['Sequence_id'].tolist()\n",
    "channels = 1\n",
    "resize = 299\n",
    "normalization = 'min-max'\n",
    "\n",
    "patient_information = [(p_id[i], edss[i]) for i in range(df.shape[0])]\n",
    "train_patient_information = patient_information[:int(0.9*len(patient_information))]\n",
    "valid_patient_information = patient_information[int(0.9*len(patient_information)):]\n",
    "base_DatabasePath = '/home/alex/Dataset 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_inst = generators.SEPGenerator(base_DatabasePath, \n",
    "                                                channels=channels,\n",
    "                                                resize=resize,\n",
    "                                                normalization=normalization)\n",
    "\n",
    "train_generator = generator_inst.generator(train_patient_information)\n",
    "valid_generator = generator_inst.generator(valid_patient_information)\n",
    "\n",
    "#dataloader = torch.utils.data.DataLoader(train_generator, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On_Going_Epoch : 1 \t | Iteration : 50 \t | Training Loss : 4511.05859375\n",
      "On_Going_Epoch : 1 \t | Iteration : 100 \t | Training Loss : 2339.1357421875\n",
      "tensor(7.8825, device='cuda:0')\n",
      "tensor(7.8826, device='cuda:0')\n",
      "tensor(8.5348, device='cuda:0')\n",
      "tensor(10.2445, device='cuda:0')\n",
      "tensor(18.1271, device='cuda:0')\n",
      "tensor(18.1641, device='cuda:0')\n",
      "tensor(19.9259, device='cuda:0')\n",
      "tensor(20.5781, device='cuda:0')\n",
      "tensor(20.6151, device='cuda:0')\n",
      "tensor(28.4977, device='cuda:0')\n",
      "tensor(203.7557, device='cuda:0')\n",
      "tensor(211.6382, device='cuda:0')\n",
      "tensor(970.9899, device='cuda:0')\n",
      "tensor(985.4875, device='cuda:0')\n",
      "tensor(999.9852, device='cuda:0')\n",
      "tensor(1000.0223, device='cuda:0')\n",
      "tensor(1000.0593, device='cuda:0')\n",
      "tensor(1820.6040, device='cuda:0')\n",
      "tensor(1831.5441, device='cuda:0')\n",
      "tensor(1842.4841, device='cuda:0')\n",
      "tensor(1853.4242, device='cuda:0')\n",
      "tensor(1864.3643, device='cuda:0')\n",
      "tensor(1864.4012, device='cuda:0')\n",
      "tensor(1864.4382, device='cuda:0')\n",
      "tensor(1872.3208, device='cuda:0')\n",
      "tensor(1926.3999, device='cuda:0')\n",
      "tensor(1960.1279, device='cuda:0')\n",
      "tensor(1993.8560, device='cuda:0')\n",
      "tensor(2176.1489, device='cuda:0')\n",
      "tensor(2197.5427, device='cuda:0')\n",
      "tensor(2212.0405, device='cuda:0')\n",
      "tensor(2226.5383, device='cuda:0')\n",
      "tensor(2241.0361, device='cuda:0')\n",
      "tensor(2241.0732, device='cuda:0')\n",
      "tensor(2244.3406, device='cuda:0')\n",
      "tensor(2278.0686, device='cuda:0')\n",
      "tensor(2311.7966, device='cuda:0')\n",
      "tensor(2345.5247, device='cuda:0')\n",
      "tensor(2345.5618, device='cuda:0')\n",
      "tensor(2497.3787, device='cuda:0')\n",
      "tensor(2498.9541, device='cuda:0')\n",
      "tensor(2502.2214, device='cuda:0')\n",
      "tensor(2542.0071, device='cuda:0')\n",
      "tensor(2581.7927, device='cuda:0')\n",
      "tensor(2905.2920, device='cuda:0')\n",
      "tensor(6808.9893, device='cuda:0')\n",
      "tensor(6835.3154, device='cuda:0')\n",
      "tensor(6837.0254, device='cuda:0')\n",
      "Epoch : 1 \t | Training Loss : 2339.1357421875 \t | Validation Loss : 142.4380340576172 \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exception' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/JFRDataChallenge/src/generators.py\u001b[0m in \u001b[0;36m__extract_DCMImage\u001b[0;34m(self, dcm_path)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydicom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdcmread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdcm_path\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# Read dcm file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpixel_array\u001b[0m                                 \u001b[0;31m# Exctact image from dcm files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv36/lib/python3.6/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mdcmread\u001b[0;34m(fp, defer_size, stop_before_pixels, force, specific_tags)\u001b[0m\n\u001b[1;32m    879\u001b[0m         dataset = read_partial(fp, stop_when, defer_size=defer_size,\n\u001b[0;32m--> 880\u001b[0;31m                                force=force, specific_tags=specific_tags)\n\u001b[0m\u001b[1;32m    881\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv36/lib/python3.6/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mread_partial\u001b[0;34m(fileobj, stop_when, defer_size, force, specific_tags)\u001b[0m\n\u001b[1;32m    757\u001b[0m                                \u001b[0mstop_when\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_when\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefer_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m                                specific_tags=specific_tags)\n\u001b[0m\u001b[1;32m    759\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv36/lib/python3.6/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mread_dataset\u001b[0;34m(fp, is_implicit_VR, is_little_endian, bytelength, stop_when, defer_size, parent_encoding, specific_tags)\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mraw_data_elements\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_data_element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-6f8289f3e3b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtotal_TrainLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mt_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mimage_3D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/JFRDataChallenge/src/generators.py\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m(self, patient_InfoDatabase, max_slices, dark_matter, shuffle)\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mdcm_image\u001b[0m               \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__extract_DCMImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_dcm_FilePath\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;31m# extract image from .dcm file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0mpreproc_image\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreproc_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdcm_image\u001b[0m\u001b[0;34m)\u001b[0m                                                 \u001b[0;31m# preprocess image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mtransform_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreproc_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformation\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# transform the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/JFRDataChallenge/src/generators.py\u001b[0m in \u001b[0;36m__extract_DCMImage\u001b[0;34m(self, dcm_path)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mexcept\u001b[0m \u001b[0mexception\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exception' is not defined"
     ]
    }
   ],
   "source": [
    "total_loss = 0\n",
    "train_iterations = 100\n",
    "valid_iterations = len(valid_patient_information)\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_TrainLoss = 0\n",
    "\n",
    "    for t_m, t_item in enumerate(train_generator):\n",
    "\n",
    "        image_3D, label = torch.tensor(t_item[0], device=device).float(), torch.tensor(t_item[1], device=device).float()\n",
    "        output = mvcnn(image_3D, 1)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_TrainLoss += loss\n",
    "\n",
    "        if not (t_m+1)%50:\n",
    "            print(\"On_Going_Epoch : {} \\t | Iteration : {} \\t | Training Loss : {}\".format(epoch+1, t_m+1, total_TrainLoss/(t_m+1)))\n",
    "\n",
    "        if (t_m+1) == train_iterations:\n",
    "            total_ValidLoss = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for v_m, v_item in enumerate(valid_generator):\n",
    "                    image_3D, label = torch.tensor(v_item[0], device=device).float(), torch.tensor(v_item[1], device=device).float()\n",
    "                    output = mvcnn(image_3D, 1)\n",
    "                    total_ValidLoss += criterion(output, label)\n",
    "                    print(total_ValidLoss)\n",
    "                    if (v_m + 1) == valid_iterations:\n",
    "                        break\n",
    "                    \n",
    "            print(\"Epoch : {} \\t | Training Loss : {} \\t | Validation Loss : {} \".format(epoch+1, total_TrainLoss/(t_m+1), total_ValidLoss/(v_m+1)) )                   \n",
    "\n",
    "            torch.save(mvcnn, './' + 'vgg_' + str(epoch) + '.pkl')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_ValidLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./vgg_9'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "c = torch.randn(90, 512, 4, 4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n"
     ]
    }
   ],
   "source": [
    "#torch.randn(90, 1, 299, 299)\n",
    "for n,v in enumerate(c):\n",
    "    \n",
    "    v = v.view(1, 512*4*4).to(device)\n",
    "    print(n)\n",
    "    if n:\n",
    "        pooled_view = torch.max(pooled_view, v).to(device)\n",
    "    else:\n",
    "        pooled_view = v.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(image, transformation='original', angle=30):\n",
    "    \"\"\"\n",
    "    Function to generate images based on the requested transfomations\n",
    "    Args:\n",
    "    - image             (nd.array)  : input image array\n",
    "    - transformation    (str)       : image transformation to be effectuated\n",
    "    - angle \t\t(int)\t    : rotation angle if transformation is a rotation\n",
    "    Returns:\n",
    "    - trans_image       (nd.array)  : transformed image array\n",
    "    \"\"\"\n",
    "\n",
    "    def rotateImage(image, angle):\n",
    "        \"\"\"\n",
    "        Function to rotate an image at its center\n",
    "        \"\"\"\n",
    "        image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "        rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "        result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "        return result\n",
    "    \n",
    "    # Image transformations\n",
    "    if transformation == 'original':\n",
    "        trans_image = image\n",
    "    elif transformation == 'flip_v':\n",
    "        trans_image = cv2.flip(image, 0)\n",
    "    elif transformation == 'flip_h':\n",
    "        trans_image = cv2.flip(image, 1)\n",
    "    elif transformation == 'flip_vh':\n",
    "        trans_image = cv2.flip(image, -1)\n",
    "    elif transformation == 'rot_c':\n",
    "        trans_image = rotateImage(image, -angle)\n",
    "    elif transformation == 'rot_ac':\n",
    "        trans_image = rotateImage(image, angle)\n",
    "    else:\n",
    "        raise ValueError(\"In valid transformation value passed : {}\".format(transformation))\n",
    "\n",
    "    return trans_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The agumenter ought to be able to do the following:\n",
    "- Get list of patient paths and their respective scores (make sure to do the validation and test splits before)\n",
    "    - Select a random augmentation (flag='test')\n",
    "    - Select a patient path and his/her corresponding score\n",
    "    - With each .dcm file do following: \n",
    "        - read image\n",
    "        - normalized image\n",
    "        - resize image\n",
    "        - get percentage of white matter (%, n) and append to list\n",
    "        - transform image\n",
    "        - store in an array\n",
    "    - yield image_3D (top 70 images with white matter), label\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SEP_generator(object):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 resize,\n",
    "                 normalization,\n",
    "                 transformations)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "class ImageBaseAug(object):\n",
    "    def __init__(self):\n",
    "        sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "        self.seq = iaa.Sequential(\n",
    "            [\n",
    "                # Blur each image with varying strength using\n",
    "                # gaussian blur (sigma between 0 and 3.0),\n",
    "                # average/uniform blur (kernel size between 2x2 and 7x7)\n",
    "                # median blur (kernel size between 3x3 and 11x11).\n",
    "                iaa.OneOf([\n",
    "                    iaa.GaussianBlur((0, 3.0)),\n",
    "                    iaa.AverageBlur(k=(2, 7)),\n",
    "                    iaa.MedianBlur(k=(3, 11)),\n",
    "                ]),\n",
    "                # Sharpen each image, overlay the result with the original\n",
    "                # image using an alpha between 0 (no sharpening) and 1\n",
    "                # (full sharpening effect).\n",
    "                sometimes(iaa.Sharpen(alpha=(0, 0.5), lightness=(0.75, 1.5))),\n",
    "                # Add gaussian noise to some images.\n",
    "                sometimes(iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)),\n",
    "                # Add a value of -5 to 5 to each pixel.\n",
    "                sometimes(iaa.Add((-5, 5), per_channel=0.5)),\n",
    "                # Change brightness of images (80-120% of original value).\n",
    "                sometimes(iaa.Multiply((0.8, 1.2), per_channel=0.5)),\n",
    "                # Improve or worsen the contrast of images.\n",
    "                sometimes(iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5)),\n",
    "            ],\n",
    "            # do all of the above augmentations in random order\n",
    "            random_order=True\n",
    "        )\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        seq_det = self.seq.to_deterministic()\n",
    "        image, label = sample['image'], sample['label']\n",
    "        image = seq_det.augment_images([image])[0]\n",
    "        return {'image': image, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )   \n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class=1):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = double_conv(1, 32)\n",
    "        self.dconv_down2 = double_conv(32, 64)\n",
    "        self.dconv_down3 = double_conv(64, 128)\n",
    "        self.dconv_down4 = double_conv(128, 256)       \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
    "        \n",
    "        self.dconv_up3 = double_conv(128 + 256, 128)\n",
    "        self.dconv_up2 = double_conv(64 + 128, 64)\n",
    "        self.dconv_up1 = double_conv(32 + 64, 32)\n",
    "        \n",
    "        self.conv_last = nn.Sequential(nn.BatchNorm2d(32),\n",
    "                                     nn.MaxPool2d(2,2))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)   \n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "        \n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "        \n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv2], dim=1)       \n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.upsample(x)        \n",
    "        x = torch.cat([x, conv1], dim=1)   \n",
    "        \n",
    "        x = self.dconv_up1(x)\n",
    "        \n",
    "        out = self.conv_last(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def attention_block():\n",
    "    \n",
    "    return nn.Sequential(\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(1, 1, 1, padding=0),\n",
    "        nn.BatchNorm2d(1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "\n",
    "def double_conv(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm2d(in_channels),\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "        nn.ReLU(inplace=True))\n",
    "\n",
    "\n",
    "def one_conv(in_channels, padding=0):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm2d(in_channels),\n",
    "        nn.Conv2d(in_channels, 1, 1, padding=padding))\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = double_conv(1, 32)\n",
    "        self.dconv_down2 = double_conv(32, 64)\n",
    "        self.dconv_down3 = double_conv(64, 128)\n",
    "        self.dconv_down4 = double_conv(128, 256)        \n",
    "\n",
    "        self.maxpool     = nn.MaxPool2d(2)\n",
    "        self.upsample    = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        \n",
    "        self.oneconv     = one_conv\n",
    "        self.attention   = attention_block()\n",
    "        \n",
    "        self.oneconvx3 = one_conv(128)\n",
    "        self.oneconvg3 = one_conv(256)\n",
    "        self.dconv_up3 = double_conv(128 + 256, 128)\n",
    "        \n",
    "        self.oneconvx2 = one_conv(64)\n",
    "        self.oneconvg2 = one_conv(128)\n",
    "        self.dconv_up2 = double_conv(64 + 128, 64)\n",
    "        \n",
    "        \n",
    "        self.conv_last = nn.Sequential(nn.BatchNorm2d(64),\n",
    "                                     nn.Conv2d(64,32,3,padding=0),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2,2),\n",
    "                                     nn.BatchNorm2d(32),\n",
    "                                     nn.Conv2d(32,8,3,padding=0),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2,2))\n",
    "        \n",
    "        self.fc1 = nn.Sequential(nn.Linear(9800, 1096), \n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Dropout(0.8),\n",
    "                                     nn.Linear(1096, 96),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Dropout(0.9),\n",
    "                                     nn.Linear(96, 1))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        conv1 = self.dconv_down1(x) # 1 -> 32 filters\n",
    "        x = self.maxpool(conv1)\n",
    "\n",
    "        conv2 = self.dconv_down2(x) # 32 -> 64 filters\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x) # 64 -> 128 filters\n",
    "        x = self.maxpool(conv3)   \n",
    "        \n",
    "        x = self.dconv_down4(x)     # 128 -> 256 filters\n",
    "        \n",
    "        x = self.upsample(x)        \n",
    "        _g = self.oneconvg3(x)\n",
    "        _x = self.oneconvx3(conv3)\n",
    "        _xg = _g + _x\n",
    "        psi = self.attention(_xg)\n",
    "        conv3 = conv3*psi\n",
    "        x = torch.cat([x, conv3], dim=1) \n",
    "        \n",
    "        x = self.dconv_up3(x)      # 128 + 256 -> 128 filters\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        _g = self.oneconvg2(x)\n",
    "        _x = self.oneconvx2(conv2)\n",
    "        _xg = _g + _x\n",
    "        psi = self.attention(_xg) \n",
    "        conv2 = conv2*psi\n",
    "        x = torch.cat([x, conv2], dim=1)       \n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        \n",
    "#         x = self.upsample(x)\n",
    "#         _g = self.oneconvg1(x)\n",
    "#         _x = self.oneconvx1(conv1)\n",
    "#         _xg = _g + _x\n",
    "#         psi = self.attention(_xg)\n",
    "#         conv1 = conv1*psi\n",
    "#         x = torch.cat([x, conv1], dim=1)   \n",
    "        \n",
    "#         x = self.dconv_up1(x)\n",
    "        \n",
    "        x = self.conv_last(x)\n",
    "        x = x.view(-1, 35*35*8)\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1          [-1, 1, 296, 296]               2\n",
      "            Conv2d-2         [-1, 32, 296, 296]             320\n",
      "              ReLU-3         [-1, 32, 296, 296]               0\n",
      "       BatchNorm2d-4         [-1, 32, 296, 296]              64\n",
      "            Conv2d-5         [-1, 32, 296, 296]           9,248\n",
      "              ReLU-6         [-1, 32, 296, 296]               0\n",
      "         MaxPool2d-7         [-1, 32, 148, 148]               0\n",
      "       BatchNorm2d-8         [-1, 32, 148, 148]              64\n",
      "            Conv2d-9         [-1, 64, 148, 148]          18,496\n",
      "             ReLU-10         [-1, 64, 148, 148]               0\n",
      "      BatchNorm2d-11         [-1, 64, 148, 148]             128\n",
      "           Conv2d-12         [-1, 64, 148, 148]          36,928\n",
      "             ReLU-13         [-1, 64, 148, 148]               0\n",
      "        MaxPool2d-14           [-1, 64, 74, 74]               0\n",
      "      BatchNorm2d-15           [-1, 64, 74, 74]             128\n",
      "           Conv2d-16          [-1, 128, 74, 74]          73,856\n",
      "             ReLU-17          [-1, 128, 74, 74]               0\n",
      "      BatchNorm2d-18          [-1, 128, 74, 74]             256\n",
      "           Conv2d-19          [-1, 128, 74, 74]         147,584\n",
      "             ReLU-20          [-1, 128, 74, 74]               0\n",
      "        MaxPool2d-21          [-1, 128, 37, 37]               0\n",
      "      BatchNorm2d-22          [-1, 128, 37, 37]             256\n",
      "           Conv2d-23          [-1, 256, 37, 37]         295,168\n",
      "             ReLU-24          [-1, 256, 37, 37]               0\n",
      "      BatchNorm2d-25          [-1, 256, 37, 37]             512\n",
      "           Conv2d-26          [-1, 256, 37, 37]         590,080\n",
      "             ReLU-27          [-1, 256, 37, 37]               0\n",
      "         Upsample-28          [-1, 256, 74, 74]               0\n",
      "      BatchNorm2d-29          [-1, 256, 74, 74]             512\n",
      "           Conv2d-30            [-1, 1, 74, 74]             257\n",
      "      BatchNorm2d-31          [-1, 128, 74, 74]             256\n",
      "           Conv2d-32            [-1, 1, 74, 74]             129\n",
      "             ReLU-33            [-1, 1, 74, 74]               0\n",
      "           Conv2d-34            [-1, 1, 74, 74]               2\n",
      "      BatchNorm2d-35            [-1, 1, 74, 74]               2\n",
      "          Sigmoid-36            [-1, 1, 74, 74]               0\n",
      "      BatchNorm2d-37          [-1, 384, 74, 74]             768\n",
      "           Conv2d-38          [-1, 128, 74, 74]         442,496\n",
      "             ReLU-39          [-1, 128, 74, 74]               0\n",
      "      BatchNorm2d-40          [-1, 128, 74, 74]             256\n",
      "           Conv2d-41          [-1, 128, 74, 74]         147,584\n",
      "             ReLU-42          [-1, 128, 74, 74]               0\n",
      "         Upsample-43        [-1, 128, 148, 148]               0\n",
      "      BatchNorm2d-44        [-1, 128, 148, 148]             256\n",
      "           Conv2d-45          [-1, 1, 148, 148]             129\n",
      "      BatchNorm2d-46         [-1, 64, 148, 148]             128\n",
      "           Conv2d-47          [-1, 1, 148, 148]              65\n",
      "             ReLU-48          [-1, 1, 148, 148]               0\n",
      "           Conv2d-49          [-1, 1, 148, 148]               2\n",
      "      BatchNorm2d-50          [-1, 1, 148, 148]               2\n",
      "          Sigmoid-51          [-1, 1, 148, 148]               0\n",
      "      BatchNorm2d-52        [-1, 192, 148, 148]             384\n",
      "           Conv2d-53         [-1, 64, 148, 148]         110,656\n",
      "             ReLU-54         [-1, 64, 148, 148]               0\n",
      "      BatchNorm2d-55         [-1, 64, 148, 148]             128\n",
      "           Conv2d-56         [-1, 64, 148, 148]          36,928\n",
      "             ReLU-57         [-1, 64, 148, 148]               0\n",
      "      BatchNorm2d-58         [-1, 64, 148, 148]             128\n",
      "           Conv2d-59         [-1, 32, 146, 146]          18,464\n",
      "             ReLU-60         [-1, 32, 146, 146]               0\n",
      "        MaxPool2d-61           [-1, 32, 73, 73]               0\n",
      "      BatchNorm2d-62           [-1, 32, 73, 73]              64\n",
      "           Conv2d-63            [-1, 8, 71, 71]           2,312\n",
      "             ReLU-64            [-1, 8, 71, 71]               0\n",
      "        MaxPool2d-65            [-1, 8, 35, 35]               0\n",
      "           Linear-66                 [-1, 1096]      10,741,896\n",
      "             ReLU-67                 [-1, 1096]               0\n",
      "          Dropout-68                 [-1, 1096]               0\n",
      "           Linear-69                   [-1, 96]         105,312\n",
      "             ReLU-70                   [-1, 96]               0\n",
      "          Dropout-71                   [-1, 96]               0\n",
      "           Linear-72                    [-1, 1]              97\n",
      "================================================================\n",
      "Total params: 12,782,303\n",
      "Trainable params: 12,782,303\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.33\n",
      "Forward/backward pass size (MB): 454.16\n",
      "Params size (MB): 48.76\n",
      "Estimated Total Size (MB): 503.25\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # PyTorch v0.4.0\n",
    "model = UNet(1).to(device)\n",
    "summary(model, (1, 296, 296))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trails (Pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.0976e+22, 1.8515e+28, 4.1988e+07],\n",
      "        [3.0357e+32, 2.7224e+20, 7.7782e+31],\n",
      "        [4.7429e+30, 1.3818e+31, 1.7225e+22],\n",
      "        [1.4602e-19, 1.8617e+25, 1.1835e+22],\n",
      "        [4.3066e+21, 6.3828e+28, 1.4603e-19]])\n",
      "tensor([[0.3337, 0.6211, 0.9639],\n",
      "        [0.1094, 0.2283, 0.4058],\n",
      "        [0.6591, 0.8595, 0.0782],\n",
      "        [0.7474, 0.8065, 0.0429],\n",
      "        [0.4577, 0.5123, 0.5054]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([[5.5000, 3.0000]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 1.6513, -0.3198, -1.5212],\n",
      "        [-1.4167, -0.5110, -1.1456],\n",
      "        [ 0.9274,  2.0594, -1.2510],\n",
      "        [ 0.0256, -0.2712, -0.4079],\n",
      "        [-0.0939, -1.1903,  1.3387]])\n"
     ]
    }
   ],
   "source": [
    "## TENSORS\n",
    "\n",
    "# create an 'un-initialized' matrix\n",
    "x = torch.empty(5, 3)\n",
    "print(x)\n",
    "\n",
    "# construct a randomly 'initialized' matrix\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "\n",
    "# construct a matrix filled with zeros an dtype=long\n",
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)\n",
    "\n",
    "# construct a tensor from data\n",
    "x = torch.tensor([[5.5, 3]])\n",
    "print(x)\n",
    "\n",
    "# Create a tensor based on existing tensor\n",
    "x = x.new_ones(5, 3, dtype=torch.double)\n",
    "print(x)\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.3659, -0.1678, -0.7175],\n",
      "        [-0.5564, -0.1421, -0.5350],\n",
      "        [ 1.0469,  3.0384, -0.9379],\n",
      "        [ 0.9468,  0.2249,  0.0415],\n",
      "        [ 0.0893, -0.8271,  1.6718]])\n",
      "tensor([[ 2.3659, -0.1678, -0.7175],\n",
      "        [-0.5564, -0.1421, -0.5350],\n",
      "        [ 1.0469,  3.0384, -0.9379],\n",
      "        [ 0.9468,  0.2249,  0.0415],\n",
      "        [ 0.0893, -0.8271,  1.6718]])\n",
      "tensor([[ 2.3659, -0.1678, -0.7175],\n",
      "        [-0.5564, -0.1421, -0.5350],\n",
      "        [ 1.0469,  3.0384, -0.9379],\n",
      "        [ 0.9468,  0.2249,  0.0415],\n",
      "        [ 0.0893, -0.8271,  1.6718]])\n",
      "tensor([[0.7146, 0.1521, 0.8037],\n",
      "        [0.8603, 0.3689, 0.6106],\n",
      "        [0.1195, 0.9790, 0.3132],\n",
      "        [0.9212, 0.4961, 0.4493],\n",
      "        [0.1832, 0.3632, 0.3331]])\n",
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
      "tensor([1.0785])\n",
      "1.0785350799560547\n"
     ]
    }
   ],
   "source": [
    "## OPERATIONS\n",
    "\n",
    "# Addition syntax 1\n",
    "y = torch.rand(5, 3)\n",
    "print(x + y)\n",
    "\n",
    "# Addition syntax 2\n",
    "print(torch.add(x, y))\n",
    "\n",
    "# Addtion output towards a tensor\n",
    "result = torch.empty(5,3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)\n",
    "\n",
    "# Addition in place\n",
    "y.add(x)\n",
    "print(y)\n",
    "\n",
    "# Any operation that mutates a tensor in-place is post-fixed with an _.\n",
    "x.copy_(y)\n",
    "x.t_()\n",
    "\n",
    "# Resizing tensors\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1,8)\n",
    "print(x.size(), y.size(), z.size())\n",
    "\n",
    "# Use get value off a one element tensor\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## NUMPY BRIDGE\n",
    "\n",
    "# Torch tensor to numpy array\n",
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "\n",
    "# Numpy array to torch tensor\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0785], device='cuda:0')\n",
      "tensor([2.0785], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## USING CUDA\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")           # Cuda device object\n",
    "    y = torch.ones_like(x, device=device)   # Directly creates a tensor on GPU\n",
    "    x = x.to(device)                        # \n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAUTO-GRAD\\n- The autograd package provides automatic differntation for all\\nopeations on tensors. \\n- A define-by-run framework i.e backprop defined by how code \\nis run and every single iteration can be different.\\n\\nTENSOR\\n- torch.tensor is the central class of the 'torch' package.\\n- If  one sets attribute '.requires_grad()' as 'True', all \\noperations on it are tracked. \\n- When computations are finished one can call'backward()' \\nand have all the gradients computed.\\n- Gradient of a tensor is accumulated into '.grad' attribute.\\n- To stop tensor from tracking history, call '.detach()' to detach \\nit from computation history and prevent future computation \\nfrom being tracked\\n- To prevent tacking histroy and using memory, wrap the code \\nblock in 'with torch.no_grad()'. Helpful when evaluating a model\\ncause model has trainable parameters with 'requires_grad=True'\\n- 'Function' class is very important for autograd implementation\\n- 'Tensor' and 'Function' are interconnected and buid up an acyclic\\ngraph that encodes a complete history of computation.\\n- Each tensor has a '.grad_fn' attribute that references a 'Function'\\nthat has created the 'Tensor' (except for tensors created by user)\\n- To compute derivates, '.backward()' is called on a Tensor. If \\ntensor is a scalar, no arguments ought to be passed to '.backward()'\\nif not, a 'gradient' argument ought to be specified.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "AUTO-GRAD\n",
    "- The autograd package provides automatic differntation for all\n",
    "opeations on tensors. \n",
    "- A define-by-run framework i.e backprop defined by how code \n",
    "is run and every single iteration can be different.\n",
    "\n",
    "TENSOR\n",
    "- torch.tensor is the central class of the 'torch' package.\n",
    "- If  one sets attribute '.requires_grad()' as 'True', all \n",
    "operations on it are tracked. \n",
    "- When computations are finished one can call'backward()' \n",
    "and have all the gradients computed.\n",
    "- Gradient of a tensor is accumulated into '.grad' attribute.\n",
    "- To stop tensor from tracking history, call '.detach()' to detach \n",
    "it from computation history and prevent future computation \n",
    "from being tracked\n",
    "- To prevent tacking histroy and using memory, wrap the code \n",
    "block in 'with torch.no_grad()'. Helpful when evaluating a model\n",
    "cause model has trainable parameters with 'requires_grad=True'\n",
    "- 'Function' class is very important for autograd implementation\n",
    "- 'Tensor' and 'Function' are interconnected and buid up an acyclic\n",
    "graph that encodes a complete history of computation.\n",
    "- Each tensor has a '.grad_fn' attribute that references a 'Function'\n",
    "that has created the 'Tensor' (except for tensors created by user)\n",
    "- To compute derivates, '.backward()' is called on a Tensor. If \n",
    "tensor is a scalar, no arguments ought to be passed to '.backward()'\n",
    "if not, a 'gradient' argument ought to be specified.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n",
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n",
      "tensor([ -388.7856,   198.8780, -1300.0267], grad_fn=<MulBackward0>)\n",
      "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "## TENSORS\n",
    "\n",
    "# Create tenor to track all operations\n",
    "x = torch.ones(2,2, requires_grad=True)\n",
    "print(x)\n",
    "y = x + 2\n",
    "print(y)\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z, out)\n",
    "\n",
    "## GRADIENTS\n",
    "\n",
    "# Peforming backprop on 'out'\n",
    "out.backward()\n",
    "print(x.grad)\n",
    "\n",
    "# An example of vector-Jacobian product\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "print(y)\n",
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "print(x.grad)\n",
    "\n",
    "# Stop autograd from tracking history on Tensors \n",
    "# with .requires_grad=True \n",
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "with torch.no_grad():\n",
    "    print((x**2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-847c9ce0eed7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not callable"
     ]
    }
   ],
   "source": [
    "image.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.5959, -1.3052, -0.6488,  ..., -1.0006, -1.8247,  1.6126],\n",
       "          [-1.0831,  1.6789, -0.2507,  ...,  1.9883,  0.0440, -1.0205],\n",
       "          [ 1.3978, -0.5599,  0.9209,  ...,  1.3029,  1.1875, -3.1398],\n",
       "          ...,\n",
       "          [-0.0280, -1.8147,  0.7449,  ..., -1.1217, -1.8393, -0.7728],\n",
       "          [-0.6970, -0.3968,  0.6772,  ..., -1.6072,  0.3949,  0.0676],\n",
       "          [-0.9794,  0.6049, -0.0923,  ...,  0.6333, -1.1131,  0.2632]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n## NEURAL NETWORKS\\n\\n- Can be constructed using 'torch.nn' package\\n- 'nn' depends on 'autograd' to define models and differentiate\\nthem. \\n- 'nn.Module' contains layers and a method forward(input) that \\nreturns the 'output'.\\n- Training procedure:\\n    - Define neural network that has some learnable parameter\\n    - Iterate over a dataset of inputs\\n    - Process input through the network\\n    - Compute loss\\n    - Propagate gradients back into the network's parameters\\n    - Update weights\\n\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "## NEURAL NETWORKS\n",
    "\n",
    "- Can be constructed using 'torch.nn' package\n",
    "- 'nn' depends on 'autograd' to define models and differentiate\n",
    "them. \n",
    "- 'nn.Module' contains layers and a method forward(input) that \n",
    "returns the 'output'.\n",
    "- Training procedure:\n",
    "    - Define neural network that has some learnable parameter\n",
    "    - Iterate over a dataset of inputs\n",
    "    - Process input through the network\n",
    "    - Compute loss\n",
    "    - Propagate gradients back into the network's parameters\n",
    "    - Update weights\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        \n",
    "        # An affine operation \n",
    "        self.fc1 = nn.Linear(16*6*6, 128)\n",
    "        self.fc2 = nn.Linear(128, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def num_flat_features(self, x):\n",
    "        \n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "            \n",
    "net = Net()\n",
    "print(net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
