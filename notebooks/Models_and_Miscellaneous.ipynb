{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append('../')\n",
    "from src import utils\n",
    "import imp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2,3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Mode - CNN_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MVCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(MVCNN,self).__init__()\n",
    "        pad = 1\n",
    "        \n",
    "        self.cnn = nn.Sequential(nn.BatchNorm2d(1),\n",
    "                                     nn.Conv2d(1,32,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.BatchNorm2d(32),\n",
    "                                     nn.Conv2d(32,32,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2,2), \n",
    "        \n",
    "                                     nn.BatchNorm2d(32),\n",
    "                                     nn.Conv2d(32,64,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.BatchNorm2d(64),\n",
    "                                     nn.Conv2d(64,64,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2,2),\n",
    "                                     \n",
    "                                     nn.BatchNorm2d(64),\n",
    "                                     nn.Conv2d(64,128,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.BatchNorm2d(128),\n",
    "                                     nn.Conv2d(128,128,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2,2),\n",
    "        \n",
    "                                     nn.BatchNorm2d(128),\n",
    "                                     nn.Conv2d(128,256,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.BatchNorm2d(256),\n",
    "                                     nn.Conv2d(256,256,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2,2), \n",
    "        \n",
    "                                     nn.BatchNorm2d(256),\n",
    "                                     nn.Conv2d(256,256,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.BatchNorm2d(256),\n",
    "                                     nn.Conv2d(256,256,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2,2),\n",
    "                                     \n",
    "                                     nn.BatchNorm2d(256),\n",
    "                                     nn.Conv2d(256,512,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.BatchNorm2d(512),\n",
    "                                     nn.Conv2d(512,512,3,padding=pad),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.MaxPool2d(2,2))\n",
    "  \n",
    "        self.fc = nn.Sequential(nn.Linear(8192, 1024), \n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Dropout(0.8),\n",
    "                                     nn.Linear(1024, 96),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Dropout(0.9),\n",
    "                                     nn.Linear(96, 1))\n",
    "        \n",
    "    def forward(self, x, batch_size, pool=True):\n",
    "        \n",
    "        if pool:\n",
    "            view_pool = []\n",
    "            # Assuming x has shape (x, 1, 299, 299)\n",
    "            for n, v in enumerate(x):\n",
    "\n",
    "                v = v.unsqueeze(0)\n",
    "                v = self.cnn(v)\n",
    "                v = v.view(v.size(0), 512 * 4* 4)\n",
    "                view_pool.append(v)\n",
    "\n",
    "            pooled_view = view_pool[0]\n",
    "            for i in range(1, len(view_pool)):\n",
    "                pooled_view = torch.max(pooled_view, view_pool[i])\n",
    "\n",
    "            output = self.fc(pooled_view)\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since patients have varying images, create single images where the channels occupy the slices of the patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net1 = MVCNN().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net1.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/alex/Dataset 1/Dataset - 1.xlsx'\n",
    "df = pd.read_excel(file_path, sheet_name='Feuil1')\n",
    "\n",
    "edss = df['EDSS'].tolist()\n",
    "p_id = df['Sequence_id'].tolist()\n",
    "channels = 1\n",
    "resize = 299\n",
    "normalization = 'min-max'\n",
    "\n",
    "patient_information = [(p_id[i], edss[i]) for i in range(df.shape[0])]\n",
    "train_patient_information = patient_information[:int(0.9*len(patient_information))]\n",
    "valid_patient_information = patient_information[int(0.9*len(patient_information)):]\n",
    "base_DatabasePath = '/home/alex/Dataset 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inst = utils.SEP_generator(train_patient_information, base_DatabasePath, \n",
    "                                           channels=channels,\n",
    "                                           resize=resize,\n",
    "                                           normalization=normalization)\n",
    "\n",
    "valid_inst = utils.SEP_generator(valid_patient_information, base_DatabasePath, \n",
    "                                           channels=channels,\n",
    "                                           resize=resize,\n",
    "                                           normalization=normalization)\n",
    "train_generator = train_inst.generator()\n",
    "valid_generator = valid_inst.generator()\n",
    "\n",
    "#dataloader = torch.utils.data.DataLoader(train_generator, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allwyn/venv36/lib/python3.6/site-packages/torch/nn/modules/loss.py:443: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# Pass tensor throught the network\n",
    "#dataset = [torch.randn(20, 1, 299, 299), torch.randn(100, 1, 299, 299), torch.randn(50, 1, 299, 299), torch.randn(50, 1, 299, 299)]\n",
    "#labels = [torch.randn(1), torch.randn(1), torch.randn(1), torch.randn(1)]\n",
    "\n",
    "total_loss = 0\n",
    "for m, item in enumerate(train_generator):\n",
    "    \n",
    "    image_3D, label = torch.tensor(item[0], device=device).float(), torch.tensor(item[1], device=device).float()\n",
    "    output = net1(image_3D, 1)\n",
    "    loss = criterion(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    total_loss += loss\n",
    "    \n",
    "        \n",
    "    if not m % 50:\n",
    "        valid_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for item in valid_generator:\n",
    "                image_3D, label = torch.tensor(item[0], device=device).float(), torch.tensor(item[1], device=device).float()\n",
    "                output = net1(image_3D, 1)\n",
    "                valid_loss += criterion(output, label)\n",
    "            \n",
    "        print(\"Iteration : {} | train_loss : {} | valid_loss : {}\".format(m, total_loss/(m+1), valid_loss/48))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "c = torch.randn(90, 512, 4, 4).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n"
     ]
    }
   ],
   "source": [
    "#torch.randn(90, 1, 299, 299)\n",
    "for n,v in enumerate(c):\n",
    "    \n",
    "    v = v.view(1, 512*4*4).to(device)\n",
    "    print(n)\n",
    "    if n:\n",
    "        pooled_view = torch.max(pooled_view, v).to(device)\n",
    "    else:\n",
    "        pooled_view = v.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(image, transformation='original', angle=30):\n",
    "    \"\"\"\n",
    "    Function to generate images based on the requested transfomations\n",
    "    Args:\n",
    "    - image             (nd.array)  : input image array\n",
    "    - transformation    (str)       : image transformation to be effectuated\n",
    "    - angle \t\t(int)\t    : rotation angle if transformation is a rotation\n",
    "    Returns:\n",
    "    - trans_image       (nd.array)  : transformed image array\n",
    "    \"\"\"\n",
    "\n",
    "    def rotateImage(image, angle):\n",
    "        \"\"\"\n",
    "        Function to rotate an image at its center\n",
    "        \"\"\"\n",
    "        image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "        rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "        result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "        return result\n",
    "    \n",
    "    # Image transformations\n",
    "    if transformation == 'original':\n",
    "        trans_image = image\n",
    "    elif transformation == 'flip_v':\n",
    "        trans_image = cv2.flip(image, 0)\n",
    "    elif transformation == 'flip_h':\n",
    "        trans_image = cv2.flip(image, 1)\n",
    "    elif transformation == 'flip_vh':\n",
    "        trans_image = cv2.flip(image, -1)\n",
    "    elif transformation == 'rot_c':\n",
    "        trans_image = rotateImage(image, -angle)\n",
    "    elif transformation == 'rot_ac':\n",
    "        trans_image = rotateImage(image, angle)\n",
    "    else:\n",
    "        raise ValueError(\"In valid transformation value passed : {}\".format(transformation))\n",
    "\n",
    "    return trans_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The agumenter ought to be able to do the following:\n",
    "- Get list of patient paths and their respective scores (make sure to do the validation and test splits before)\n",
    "    - Select a random augmentation (flag='test')\n",
    "    - Select a patient path and his/her corresponding score\n",
    "    - With each .dcm file do following: \n",
    "        - read image\n",
    "        - normalized image\n",
    "        - resize image\n",
    "        - get percentage of white matter (%, n) and append to list\n",
    "        - transform image\n",
    "        - store in an array\n",
    "    - yield image_3D (top 70 images with white matter), label\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SEP_generator(object):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 resize,\n",
    "                 normalization,\n",
    "                 transformations)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "class ImageBaseAug(object):\n",
    "    def __init__(self):\n",
    "        sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "        self.seq = iaa.Sequential(\n",
    "            [\n",
    "                # Blur each image with varying strength using\n",
    "                # gaussian blur (sigma between 0 and 3.0),\n",
    "                # average/uniform blur (kernel size between 2x2 and 7x7)\n",
    "                # median blur (kernel size between 3x3 and 11x11).\n",
    "                iaa.OneOf([\n",
    "                    iaa.GaussianBlur((0, 3.0)),\n",
    "                    iaa.AverageBlur(k=(2, 7)),\n",
    "                    iaa.MedianBlur(k=(3, 11)),\n",
    "                ]),\n",
    "                # Sharpen each image, overlay the result with the original\n",
    "                # image using an alpha between 0 (no sharpening) and 1\n",
    "                # (full sharpening effect).\n",
    "                sometimes(iaa.Sharpen(alpha=(0, 0.5), lightness=(0.75, 1.5))),\n",
    "                # Add gaussian noise to some images.\n",
    "                sometimes(iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)),\n",
    "                # Add a value of -5 to 5 to each pixel.\n",
    "                sometimes(iaa.Add((-5, 5), per_channel=0.5)),\n",
    "                # Change brightness of images (80-120% of original value).\n",
    "                sometimes(iaa.Multiply((0.8, 1.2), per_channel=0.5)),\n",
    "                # Improve or worsen the contrast of images.\n",
    "                sometimes(iaa.ContrastNormalization((0.5, 2.0), per_channel=0.5)),\n",
    "            ],\n",
    "            # do all of the above augmentations in random order\n",
    "            random_order=True\n",
    "        )\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        seq_det = self.seq.to_deterministic()\n",
    "        image, label = sample['image'], sample['label']\n",
    "        image = seq_det.augment_images([image])[0]\n",
    "        return {'image': image, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trails (Pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.0976e+22, 1.8515e+28, 4.1988e+07],\n",
      "        [3.0357e+32, 2.7224e+20, 7.7782e+31],\n",
      "        [4.7429e+30, 1.3818e+31, 1.7225e+22],\n",
      "        [1.4602e-19, 1.8617e+25, 1.1835e+22],\n",
      "        [4.3066e+21, 6.3828e+28, 1.4603e-19]])\n",
      "tensor([[0.3337, 0.6211, 0.9639],\n",
      "        [0.1094, 0.2283, 0.4058],\n",
      "        [0.6591, 0.8595, 0.0782],\n",
      "        [0.7474, 0.8065, 0.0429],\n",
      "        [0.4577, 0.5123, 0.5054]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([[5.5000, 3.0000]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 1.6513, -0.3198, -1.5212],\n",
      "        [-1.4167, -0.5110, -1.1456],\n",
      "        [ 0.9274,  2.0594, -1.2510],\n",
      "        [ 0.0256, -0.2712, -0.4079],\n",
      "        [-0.0939, -1.1903,  1.3387]])\n"
     ]
    }
   ],
   "source": [
    "## TENSORS\n",
    "\n",
    "# create an 'un-initialized' matrix\n",
    "x = torch.empty(5, 3)\n",
    "print(x)\n",
    "\n",
    "# construct a randomly 'initialized' matrix\n",
    "x = torch.rand(5, 3)\n",
    "print(x)\n",
    "\n",
    "# construct a matrix filled with zeros an dtype=long\n",
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)\n",
    "\n",
    "# construct a tensor from data\n",
    "x = torch.tensor([[5.5, 3]])\n",
    "print(x)\n",
    "\n",
    "# Create a tensor based on existing tensor\n",
    "x = x.new_ones(5, 3, dtype=torch.double)\n",
    "print(x)\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.3659, -0.1678, -0.7175],\n",
      "        [-0.5564, -0.1421, -0.5350],\n",
      "        [ 1.0469,  3.0384, -0.9379],\n",
      "        [ 0.9468,  0.2249,  0.0415],\n",
      "        [ 0.0893, -0.8271,  1.6718]])\n",
      "tensor([[ 2.3659, -0.1678, -0.7175],\n",
      "        [-0.5564, -0.1421, -0.5350],\n",
      "        [ 1.0469,  3.0384, -0.9379],\n",
      "        [ 0.9468,  0.2249,  0.0415],\n",
      "        [ 0.0893, -0.8271,  1.6718]])\n",
      "tensor([[ 2.3659, -0.1678, -0.7175],\n",
      "        [-0.5564, -0.1421, -0.5350],\n",
      "        [ 1.0469,  3.0384, -0.9379],\n",
      "        [ 0.9468,  0.2249,  0.0415],\n",
      "        [ 0.0893, -0.8271,  1.6718]])\n",
      "tensor([[0.7146, 0.1521, 0.8037],\n",
      "        [0.8603, 0.3689, 0.6106],\n",
      "        [0.1195, 0.9790, 0.3132],\n",
      "        [0.9212, 0.4961, 0.4493],\n",
      "        [0.1832, 0.3632, 0.3331]])\n",
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n",
      "tensor([1.0785])\n",
      "1.0785350799560547\n"
     ]
    }
   ],
   "source": [
    "## OPERATIONS\n",
    "\n",
    "# Addition syntax 1\n",
    "y = torch.rand(5, 3)\n",
    "print(x + y)\n",
    "\n",
    "# Addition syntax 2\n",
    "print(torch.add(x, y))\n",
    "\n",
    "# Addtion output towards a tensor\n",
    "result = torch.empty(5,3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)\n",
    "\n",
    "# Addition in place\n",
    "y.add(x)\n",
    "print(y)\n",
    "\n",
    "# Any operation that mutates a tensor in-place is post-fixed with an _.\n",
    "x.copy_(y)\n",
    "x.t_()\n",
    "\n",
    "# Resizing tensors\n",
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1,8)\n",
    "print(x.size(), y.size(), z.size())\n",
    "\n",
    "# Use get value off a one element tensor\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## NUMPY BRIDGE\n",
    "\n",
    "# Torch tensor to numpy array\n",
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "\n",
    "# Numpy array to torch tensor\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.0785], device='cuda:0')\n",
      "tensor([2.0785], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## USING CUDA\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")           # Cuda device object\n",
    "    y = torch.ones_like(x, device=device)   # Directly creates a tensor on GPU\n",
    "    x = x.to(device)                        # \n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAUTO-GRAD\\n- The autograd package provides automatic differntation for all\\nopeations on tensors. \\n- A define-by-run framework i.e backprop defined by how code \\nis run and every single iteration can be different.\\n\\nTENSOR\\n- torch.tensor is the central class of the 'torch' package.\\n- If  one sets attribute '.requires_grad()' as 'True', all \\noperations on it are tracked. \\n- When computations are finished one can call'backward()' \\nand have all the gradients computed.\\n- Gradient of a tensor is accumulated into '.grad' attribute.\\n- To stop tensor from tracking history, call '.detach()' to detach \\nit from computation history and prevent future computation \\nfrom being tracked\\n- To prevent tacking histroy and using memory, wrap the code \\nblock in 'with torch.no_grad()'. Helpful when evaluating a model\\ncause model has trainable parameters with 'requires_grad=True'\\n- 'Function' class is very important for autograd implementation\\n- 'Tensor' and 'Function' are interconnected and buid up an acyclic\\ngraph that encodes a complete history of computation.\\n- Each tensor has a '.grad_fn' attribute that references a 'Function'\\nthat has created the 'Tensor' (except for tensors created by user)\\n- To compute derivates, '.backward()' is called on a Tensor. If \\ntensor is a scalar, no arguments ought to be passed to '.backward()'\\nif not, a 'gradient' argument ought to be specified.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "AUTO-GRAD\n",
    "- The autograd package provides automatic differntation for all\n",
    "opeations on tensors. \n",
    "- A define-by-run framework i.e backprop defined by how code \n",
    "is run and every single iteration can be different.\n",
    "\n",
    "TENSOR\n",
    "- torch.tensor is the central class of the 'torch' package.\n",
    "- If  one sets attribute '.requires_grad()' as 'True', all \n",
    "operations on it are tracked. \n",
    "- When computations are finished one can call'backward()' \n",
    "and have all the gradients computed.\n",
    "- Gradient of a tensor is accumulated into '.grad' attribute.\n",
    "- To stop tensor from tracking history, call '.detach()' to detach \n",
    "it from computation history and prevent future computation \n",
    "from being tracked\n",
    "- To prevent tacking histroy and using memory, wrap the code \n",
    "block in 'with torch.no_grad()'. Helpful when evaluating a model\n",
    "cause model has trainable parameters with 'requires_grad=True'\n",
    "- 'Function' class is very important for autograd implementation\n",
    "- 'Tensor' and 'Function' are interconnected and buid up an acyclic\n",
    "graph that encodes a complete history of computation.\n",
    "- Each tensor has a '.grad_fn' attribute that references a 'Function'\n",
    "that has created the 'Tensor' (except for tensors created by user)\n",
    "- To compute derivates, '.backward()' is called on a Tensor. If \n",
    "tensor is a scalar, no arguments ought to be passed to '.backward()'\n",
    "if not, a 'gradient' argument ought to be specified.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n",
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n",
      "tensor([ -388.7856,   198.8780, -1300.0267], grad_fn=<MulBackward0>)\n",
      "tensor([2.0480e+02, 2.0480e+03, 2.0480e-01])\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "## TENSORS\n",
    "\n",
    "# Create tenor to track all operations\n",
    "x = torch.ones(2,2, requires_grad=True)\n",
    "print(x)\n",
    "y = x + 2\n",
    "print(y)\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z, out)\n",
    "\n",
    "## GRADIENTS\n",
    "\n",
    "# Peforming backprop on 'out'\n",
    "out.backward()\n",
    "print(x.grad)\n",
    "\n",
    "# An example of vector-Jacobian product\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "print(y)\n",
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "print(x.grad)\n",
    "\n",
    "# Stop autograd from tracking history on Tensors \n",
    "# with .requires_grad=True \n",
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "with torch.no_grad():\n",
    "    print((x**2).requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-847c9ce0eed7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not callable"
     ]
    }
   ],
   "source": [
    "image.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.5959, -1.3052, -0.6488,  ..., -1.0006, -1.8247,  1.6126],\n",
       "          [-1.0831,  1.6789, -0.2507,  ...,  1.9883,  0.0440, -1.0205],\n",
       "          [ 1.3978, -0.5599,  0.9209,  ...,  1.3029,  1.1875, -3.1398],\n",
       "          ...,\n",
       "          [-0.0280, -1.8147,  0.7449,  ..., -1.1217, -1.8393, -0.7728],\n",
       "          [-0.6970, -0.3968,  0.6772,  ..., -1.6072,  0.3949,  0.0676],\n",
       "          [-0.9794,  0.6049, -0.0923,  ...,  0.6333, -1.1131,  0.2632]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n## NEURAL NETWORKS\\n\\n- Can be constructed using 'torch.nn' package\\n- 'nn' depends on 'autograd' to define models and differentiate\\nthem. \\n- 'nn.Module' contains layers and a method forward(input) that \\nreturns the 'output'.\\n- Training procedure:\\n    - Define neural network that has some learnable parameter\\n    - Iterate over a dataset of inputs\\n    - Process input through the network\\n    - Compute loss\\n    - Propagate gradients back into the network's parameters\\n    - Update weights\\n\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "## NEURAL NETWORKS\n",
    "\n",
    "- Can be constructed using 'torch.nn' package\n",
    "- 'nn' depends on 'autograd' to define models and differentiate\n",
    "them. \n",
    "- 'nn.Module' contains layers and a method forward(input) that \n",
    "returns the 'output'.\n",
    "- Training procedure:\n",
    "    - Define neural network that has some learnable parameter\n",
    "    - Iterate over a dataset of inputs\n",
    "    - Process input through the network\n",
    "    - Compute loss\n",
    "    - Propagate gradients back into the network's parameters\n",
    "    - Update weights\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Convolutional Layers\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        \n",
    "        # An affine operation \n",
    "        self.fc1 = nn.Linear(16*6*6, 128)\n",
    "        self.fc2 = nn.Linear(128, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def num_flat_features(self, x):\n",
    "        \n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "            \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[-0.2323, -0.2449, -0.2866],\n",
       "           [-0.1146,  0.0728,  0.2426],\n",
       "           [-0.0343, -0.0685, -0.3318]]],\n",
       " \n",
       " \n",
       "         [[[-0.2328,  0.0704,  0.2253],\n",
       "           [-0.1530, -0.0996,  0.2698],\n",
       "           [ 0.2488, -0.3037, -0.2377]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1622, -0.2684,  0.2374],\n",
       "           [ 0.0469,  0.3276,  0.0163],\n",
       "           [-0.3135, -0.2353,  0.0664]]],\n",
       " \n",
       " \n",
       "         [[[ 0.3103, -0.2125,  0.0187],\n",
       "           [-0.1651, -0.1872,  0.2033],\n",
       "           [ 0.0383, -0.2781, -0.0507]]],\n",
       " \n",
       " \n",
       "         [[[-0.1093, -0.0654,  0.1340],\n",
       "           [-0.3097,  0.1266, -0.1893],\n",
       "           [ 0.0642,  0.1337, -0.2085]]],\n",
       " \n",
       " \n",
       "         [[[-0.1382,  0.3026, -0.3094],\n",
       "           [-0.2960,  0.0430,  0.1208],\n",
       "           [-0.1313, -0.1435, -0.1754]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2984,  0.2190, -0.1588, -0.0237, -0.3073,  0.2563],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 5.0677e-02, -7.0059e-03,  1.2598e-01],\n",
       "           [-6.8708e-02, -1.1695e-02,  1.0934e-01],\n",
       "           [ 8.5356e-02,  8.8093e-02,  2.3657e-02]],\n",
       " \n",
       "          [[ 3.5343e-02,  8.5800e-02,  4.0235e-02],\n",
       "           [-1.0251e-01,  4.1901e-02,  3.3277e-02],\n",
       "           [-1.8783e-02,  1.0008e-01,  1.0457e-01]],\n",
       " \n",
       "          [[-1.1562e-01, -1.2782e-01,  6.0216e-02],\n",
       "           [-1.0805e-01,  1.0134e-01, -6.0400e-02],\n",
       "           [ 6.2367e-02,  1.0473e-02,  4.7283e-02]],\n",
       " \n",
       "          [[ 9.8647e-02,  3.3933e-02, -1.2275e-01],\n",
       "           [ 9.9141e-02,  5.5291e-02, -1.0286e-01],\n",
       "           [-6.5298e-02,  3.4106e-02, -1.2872e-01]],\n",
       " \n",
       "          [[ 1.1609e-01,  1.3096e-01, -1.2101e-01],\n",
       "           [-1.8285e-02,  9.0087e-02,  1.3035e-02],\n",
       "           [ 7.6760e-02,  4.2259e-02, -3.5746e-02]],\n",
       " \n",
       "          [[-7.8460e-02, -1.1147e-01,  5.5694e-02],\n",
       "           [ 4.2177e-02, -1.0834e-01,  1.3013e-01],\n",
       "           [ 4.3505e-02, -2.2817e-02, -5.9212e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 8.9866e-02, -1.3675e-02,  4.2399e-02],\n",
       "           [ 8.1415e-02,  1.0176e-01, -4.8715e-02],\n",
       "           [-5.5192e-02, -1.0516e-01,  9.3510e-02]],\n",
       " \n",
       "          [[-6.4511e-03,  4.1209e-02, -1.2695e-01],\n",
       "           [ 6.5402e-02,  4.2608e-02,  8.3386e-03],\n",
       "           [ 5.0690e-02,  8.7353e-02, -4.9614e-02]],\n",
       " \n",
       "          [[ 1.2287e-01,  7.3029e-04,  4.9661e-02],\n",
       "           [ 1.3460e-01, -1.1223e-01, -1.3450e-01],\n",
       "           [ 7.9590e-02, -1.1647e-01, -1.1250e-01]],\n",
       " \n",
       "          [[-3.5949e-02, -7.2334e-02,  9.7394e-02],\n",
       "           [-9.3889e-02, -8.6084e-02,  1.1556e-01],\n",
       "           [ 1.0713e-01, -9.5371e-02, -1.2734e-01]],\n",
       " \n",
       "          [[ 2.5443e-02,  9.3968e-03, -1.6298e-02],\n",
       "           [ 2.0422e-02, -1.1049e-01,  3.8863e-02],\n",
       "           [ 2.6462e-03, -3.5771e-02, -3.8682e-03]],\n",
       " \n",
       "          [[-8.4029e-02, -1.3128e-02,  4.6753e-02],\n",
       "           [-2.5356e-02,  1.0490e-01,  2.7658e-02],\n",
       "           [ 1.2821e-01, -4.4079e-02,  2.2260e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 4.4288e-02, -1.1133e-02, -1.6846e-02],\n",
       "           [-8.8196e-02, -3.7915e-02, -7.9137e-02],\n",
       "           [-1.9844e-02,  1.2614e-01,  2.1225e-02]],\n",
       " \n",
       "          [[-8.7153e-02,  1.0362e-01,  8.5783e-02],\n",
       "           [ 4.2241e-02, -6.5613e-02,  4.4175e-02],\n",
       "           [-1.2573e-01,  1.0048e-01, -7.0435e-02]],\n",
       " \n",
       "          [[-5.1451e-02, -7.8574e-02,  9.2554e-02],\n",
       "           [ 3.5050e-02,  8.2833e-02, -1.2620e-01],\n",
       "           [-1.7440e-02,  7.2521e-02,  9.6820e-02]],\n",
       " \n",
       "          [[ 1.2787e-01, -3.8891e-02,  2.6664e-02],\n",
       "           [ 9.4598e-02, -6.4243e-02,  4.9233e-02],\n",
       "           [ 2.9556e-02,  5.7823e-02, -9.3619e-02]],\n",
       " \n",
       "          [[-1.0877e-01,  6.0811e-02, -4.3056e-02],\n",
       "           [ 1.0397e-02, -1.3402e-01,  5.0004e-02],\n",
       "           [-6.7294e-02, -5.8732e-02,  9.5499e-02]],\n",
       " \n",
       "          [[-3.1827e-02, -7.6012e-02,  8.1954e-02],\n",
       "           [-1.8342e-02, -1.1787e-01, -6.3469e-02],\n",
       "           [-7.7043e-02,  4.1834e-02, -2.5755e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.0324e-01, -1.0692e-01, -1.8144e-02],\n",
       "           [ 9.2271e-03,  6.8801e-02, -7.9206e-04],\n",
       "           [ 3.7765e-02, -1.3412e-01, -7.9073e-02]],\n",
       " \n",
       "          [[ 2.8056e-02,  4.4513e-03, -1.3417e-02],\n",
       "           [ 3.3560e-02, -3.2798e-02, -5.0256e-02],\n",
       "           [ 6.0082e-02,  7.2572e-02, -1.0778e-01]],\n",
       " \n",
       "          [[ 9.9453e-02, -3.2227e-02,  1.2189e-01],\n",
       "           [-5.4900e-02, -9.8429e-02, -9.6943e-02],\n",
       "           [-3.9690e-02, -8.4047e-02, -4.8242e-02]],\n",
       " \n",
       "          [[ 8.0768e-02, -4.7462e-03,  1.1920e-01],\n",
       "           [ 2.9423e-02, -6.2966e-02,  2.3959e-02],\n",
       "           [-1.0216e-02, -1.0689e-02, -6.7494e-02]],\n",
       " \n",
       "          [[-1.1826e-01, -1.9751e-02,  9.6605e-02],\n",
       "           [ 6.1158e-03, -9.8206e-02,  1.1485e-02],\n",
       "           [-3.1351e-02, -9.3071e-02, -2.3761e-02]],\n",
       " \n",
       "          [[ 1.2871e-01,  4.4970e-02,  3.4212e-02],\n",
       "           [ 3.7320e-02, -4.4461e-02,  1.0974e-01],\n",
       "           [-2.1259e-02,  1.1357e-01, -9.1831e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.2543e-01,  1.0812e-01, -2.9979e-02],\n",
       "           [ 6.3051e-02, -1.2248e-01, -1.2886e-01],\n",
       "           [ 3.2365e-05, -7.5357e-02,  1.3676e-03]],\n",
       " \n",
       "          [[ 1.3418e-01, -9.6795e-02,  1.0443e-01],\n",
       "           [-2.9344e-03,  9.1968e-02, -3.8967e-02],\n",
       "           [ 1.1719e-01, -1.1143e-01, -6.5353e-02]],\n",
       " \n",
       "          [[-1.0607e-01,  3.5183e-02,  5.2084e-02],\n",
       "           [ 6.3845e-02,  5.8421e-02, -5.9610e-02],\n",
       "           [ 1.1303e-01,  1.2018e-01, -1.1633e-01]],\n",
       " \n",
       "          [[-5.1220e-02, -9.3407e-02,  2.2942e-02],\n",
       "           [ 1.1722e-01,  8.3131e-02, -1.1630e-01],\n",
       "           [-4.8341e-02,  3.3950e-02, -1.3156e-01]],\n",
       " \n",
       "          [[ 4.5607e-02, -2.0505e-03,  8.6989e-02],\n",
       "           [-8.9246e-02,  5.0506e-02, -1.3067e-01],\n",
       "           [-1.2369e-02,  1.0685e-01, -5.7137e-03]],\n",
       " \n",
       "          [[ 6.7140e-03,  9.4750e-02,  1.3118e-01],\n",
       "           [-8.1159e-02,  4.6466e-03,  3.0833e-02],\n",
       "           [-5.3341e-02,  4.6939e-02, -1.0097e-01]]],\n",
       " \n",
       " \n",
       "         [[[-7.4202e-02, -2.2915e-02,  1.1638e-01],\n",
       "           [ 6.2923e-03,  9.4744e-02,  1.5566e-03],\n",
       "           [ 4.4014e-03, -4.4594e-02, -1.0213e-01]],\n",
       " \n",
       "          [[ 1.0920e-01, -6.6726e-02, -4.0483e-02],\n",
       "           [ 1.1281e-02, -5.2111e-02,  9.3913e-04],\n",
       "           [ 2.3376e-02, -9.8804e-04,  6.4026e-02]],\n",
       " \n",
       "          [[ 1.2293e-01,  6.9748e-02, -6.1644e-02],\n",
       "           [ 1.2266e-01,  1.0219e-01,  5.5179e-02],\n",
       "           [-1.0250e-01,  8.0548e-02, -6.5759e-02]],\n",
       " \n",
       "          [[ 1.0126e-01, -1.7483e-02, -7.6261e-02],\n",
       "           [ 8.5605e-02, -7.9225e-02, -5.3478e-02],\n",
       "           [ 1.1626e-01,  9.8868e-02,  1.0645e-01]],\n",
       " \n",
       "          [[ 1.6967e-02,  1.7661e-02, -7.3789e-02],\n",
       "           [-1.0260e-01, -2.3413e-02, -9.7209e-02],\n",
       "           [ 9.6753e-02,  1.1587e-01,  8.2934e-03]],\n",
       " \n",
       "          [[-6.9221e-02,  4.8992e-03, -1.6911e-03],\n",
       "           [-5.7334e-02, -9.8769e-02, -3.4438e-02],\n",
       "           [ 1.1318e-01, -4.0737e-02,  1.1218e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.7093e-02,  5.9818e-02, -1.2317e-01],\n",
       "           [-1.1194e-02,  3.1023e-02, -8.8556e-04],\n",
       "           [ 2.2283e-02, -5.4551e-02, -6.6703e-02]],\n",
       " \n",
       "          [[-1.1339e-01, -3.6911e-02,  6.3602e-02],\n",
       "           [ 1.1359e-01,  4.2459e-02, -9.8496e-02],\n",
       "           [-4.2377e-02,  5.9902e-02,  1.0108e-01]],\n",
       " \n",
       "          [[ 7.8722e-02, -1.6140e-02,  1.1092e-02],\n",
       "           [-6.5572e-02, -7.4538e-02,  1.2886e-01],\n",
       "           [ 5.3450e-02,  6.8772e-02,  4.4029e-02]],\n",
       " \n",
       "          [[-9.5221e-02, -4.9372e-03, -7.0891e-02],\n",
       "           [-4.9979e-02, -1.0890e-01,  1.2093e-02],\n",
       "           [-9.8347e-02, -1.5342e-02,  1.2492e-01]],\n",
       " \n",
       "          [[ 5.0384e-02,  5.7323e-02,  3.6806e-02],\n",
       "           [-1.8906e-02,  1.0045e-01, -2.0887e-02],\n",
       "           [-2.9929e-02, -1.1949e-01,  2.9443e-03]],\n",
       " \n",
       "          [[ 1.3011e-01,  8.5083e-02, -9.2143e-02],\n",
       "           [-1.2865e-01,  8.4350e-04, -1.3391e-01],\n",
       "           [ 1.0460e-01,  2.7664e-02,  8.6602e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 6.8172e-02,  7.1116e-02,  7.5417e-02],\n",
       "           [-1.2855e-01, -4.1635e-02,  1.1367e-01],\n",
       "           [-1.3590e-01, -1.2686e-01, -1.0454e-01]],\n",
       " \n",
       "          [[-1.2493e-01,  2.4598e-02, -7.5786e-02],\n",
       "           [-5.3796e-03,  5.1973e-02,  9.1519e-02],\n",
       "           [-2.4136e-02, -1.2708e-01, -1.3515e-01]],\n",
       " \n",
       "          [[-8.5956e-02,  6.9122e-02, -2.4102e-02],\n",
       "           [-1.3152e-01, -4.0719e-02, -1.2839e-01],\n",
       "           [-2.5968e-02,  9.1037e-02, -1.3553e-01]],\n",
       " \n",
       "          [[-6.4655e-02, -2.3611e-02, -5.0629e-03],\n",
       "           [-1.0141e-01, -9.8850e-02, -3.9673e-03],\n",
       "           [ 7.7350e-02, -1.1521e-01, -1.0210e-01]],\n",
       " \n",
       "          [[-4.5495e-02,  1.7019e-02,  1.1969e-01],\n",
       "           [ 6.6003e-02,  8.3824e-02,  8.9536e-02],\n",
       "           [-7.0403e-02,  8.6154e-02, -1.2006e-01]],\n",
       " \n",
       "          [[ 1.7452e-02,  2.5404e-02, -9.3191e-02],\n",
       "           [-8.2743e-02,  1.2791e-02,  2.6185e-02],\n",
       "           [-5.3506e-02,  6.1667e-02,  4.5171e-02]]],\n",
       " \n",
       " \n",
       "         [[[-8.6245e-02,  8.3401e-02,  3.1066e-02],\n",
       "           [ 1.3508e-02, -9.8324e-02, -1.1112e-01],\n",
       "           [ 1.0109e-01,  1.0952e-01, -6.6852e-02]],\n",
       " \n",
       "          [[ 7.0986e-02, -2.6133e-02, -1.4540e-02],\n",
       "           [-1.0860e-01, -1.2459e-01, -6.9826e-02],\n",
       "           [-1.2481e-01, -5.7419e-02, -7.5938e-02]],\n",
       " \n",
       "          [[ 5.9534e-02, -8.3661e-03, -8.0395e-02],\n",
       "           [ 6.6728e-02, -1.0573e-01, -3.0892e-02],\n",
       "           [-7.1364e-02, -2.9114e-02, -4.3751e-02]],\n",
       " \n",
       "          [[ 1.0073e-01,  4.2678e-02, -9.9324e-02],\n",
       "           [-1.0965e-01,  1.5529e-02,  1.3545e-01],\n",
       "           [ 9.6430e-02,  8.9465e-02, -1.2305e-01]],\n",
       " \n",
       "          [[ 1.3555e-01, -4.7653e-02, -7.5783e-02],\n",
       "           [ 9.2733e-02,  5.6043e-02, -3.0358e-03],\n",
       "           [ 1.1098e-01,  6.8892e-02,  6.9102e-02]],\n",
       " \n",
       "          [[ 1.2795e-01, -1.2694e-01,  6.6125e-02],\n",
       "           [-8.7669e-02, -8.1497e-02, -7.7170e-02],\n",
       "           [-3.6409e-02,  4.4003e-02,  1.6329e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.1474e-01, -9.5133e-02, -7.1940e-02],\n",
       "           [-4.3974e-02,  1.9977e-02,  1.2374e-01],\n",
       "           [ 1.2142e-01, -1.3340e-01, -7.8477e-02]],\n",
       " \n",
       "          [[-3.9066e-03, -5.1585e-02,  1.2476e-01],\n",
       "           [-5.8531e-02, -1.0125e-01,  6.1029e-02],\n",
       "           [-1.1530e-01,  6.5650e-02, -1.2309e-01]],\n",
       " \n",
       "          [[-1.1189e-01,  7.2549e-02, -6.6518e-02],\n",
       "           [-4.3009e-04, -9.6248e-02,  2.6542e-04],\n",
       "           [ 3.3452e-02, -1.0639e-02, -3.8961e-02]],\n",
       " \n",
       "          [[-7.7812e-02, -4.2023e-02,  6.0354e-02],\n",
       "           [ 7.5043e-02,  1.3367e-02,  7.3270e-03],\n",
       "           [-9.3137e-02, -3.0136e-02,  1.0763e-01]],\n",
       " \n",
       "          [[-1.2620e-01, -1.2378e-02, -5.8109e-02],\n",
       "           [ 7.7335e-02,  1.2369e-01, -1.0825e-01],\n",
       "           [-2.5342e-02,  5.6346e-02, -9.3716e-03]],\n",
       " \n",
       "          [[-3.8192e-02,  2.3217e-03, -1.3381e-02],\n",
       "           [ 1.0059e-01,  1.3571e-01,  5.8859e-02],\n",
       "           [-7.4427e-02,  9.3367e-02,  1.2881e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 3.2590e-02,  6.4496e-03, -8.8185e-02],\n",
       "           [ 6.8915e-02, -8.2533e-02,  5.0870e-02],\n",
       "           [ 1.8932e-02,  3.5037e-03, -9.9120e-02]],\n",
       " \n",
       "          [[-9.0856e-02, -1.0427e-01,  2.1469e-02],\n",
       "           [-4.2588e-02, -8.1355e-03,  3.0959e-02],\n",
       "           [ 4.5268e-02,  9.5205e-02,  1.2931e-01]],\n",
       " \n",
       "          [[ 1.3182e-01,  2.7778e-03,  8.2869e-02],\n",
       "           [-4.0744e-02, -4.6075e-03, -7.6832e-02],\n",
       "           [-1.6563e-02, -7.7690e-02, -8.5096e-02]],\n",
       " \n",
       "          [[-6.1972e-02, -2.3258e-02, -8.9495e-02],\n",
       "           [-1.0460e-02, -1.2923e-01,  1.2195e-02],\n",
       "           [ 3.3663e-02, -1.2670e-01, -1.1414e-01]],\n",
       " \n",
       "          [[-4.4403e-02,  2.7649e-02,  1.1171e-01],\n",
       "           [ 9.6757e-02, -6.5990e-02, -9.9527e-02],\n",
       "           [ 6.9867e-02,  1.2035e-01, -2.4514e-02]],\n",
       " \n",
       "          [[-9.2715e-02,  6.5514e-02,  8.5359e-02],\n",
       "           [-3.8310e-02,  3.7347e-03,  2.6944e-02],\n",
       "           [-8.6540e-03,  1.7884e-02, -4.5517e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.3403e-01,  1.2425e-01, -9.6135e-02],\n",
       "           [-9.5450e-02,  2.1220e-02,  1.1061e-01],\n",
       "           [-5.8931e-02,  6.2115e-02,  2.3354e-02]],\n",
       " \n",
       "          [[ 1.2031e-01,  1.3601e-01,  8.6819e-02],\n",
       "           [-8.0729e-02, -6.6756e-02,  6.5286e-03],\n",
       "           [-9.7196e-02, -1.8831e-02,  8.5729e-02]],\n",
       " \n",
       "          [[ 1.3351e-01, -8.3688e-02,  1.2977e-01],\n",
       "           [-4.4937e-02, -1.0815e-01, -6.7634e-02],\n",
       "           [ 2.2112e-02,  1.2544e-01,  1.5766e-02]],\n",
       " \n",
       "          [[ 6.7129e-02,  5.4678e-02,  1.3254e-01],\n",
       "           [ 3.8362e-02,  7.6426e-02, -7.9170e-02],\n",
       "           [ 1.2075e-01, -1.0000e-01, -7.0553e-02]],\n",
       " \n",
       "          [[ 7.6140e-02, -5.8494e-02,  1.0831e-01],\n",
       "           [ 2.0384e-02,  8.3657e-02,  5.7968e-02],\n",
       "           [-9.4595e-02, -6.3552e-02, -5.5863e-02]],\n",
       " \n",
       "          [[ 6.2199e-02, -1.1925e-01,  6.3086e-02],\n",
       "           [ 1.1441e-02,  4.4917e-02, -1.5430e-02],\n",
       "           [ 9.5200e-02,  1.4095e-02,  3.0177e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 8.3197e-02, -8.9163e-02,  5.2861e-02],\n",
       "           [-6.7959e-02, -1.4142e-02, -8.9195e-02],\n",
       "           [-1.8395e-02,  1.0678e-01,  1.1417e-02]],\n",
       " \n",
       "          [[-5.7739e-02,  5.6376e-02, -8.6604e-02],\n",
       "           [-2.5989e-02,  3.0727e-02, -1.3107e-02],\n",
       "           [-1.2315e-01, -1.2329e-01,  1.0545e-01]],\n",
       " \n",
       "          [[ 2.7866e-02,  7.9189e-02, -9.4072e-02],\n",
       "           [ 2.8545e-02,  1.0528e-01,  8.4278e-02],\n",
       "           [-7.4636e-02,  1.3131e-01,  2.4488e-02]],\n",
       " \n",
       "          [[ 1.3452e-01,  5.7057e-02,  2.9416e-02],\n",
       "           [-3.9325e-02,  5.8016e-02,  1.1291e-01],\n",
       "           [-7.7780e-02,  8.9286e-02,  8.4746e-02]],\n",
       " \n",
       "          [[-1.7593e-02,  9.8178e-02, -8.1899e-03],\n",
       "           [ 9.7410e-02,  4.3882e-04,  1.1667e-01],\n",
       "           [ 2.7000e-02,  6.7770e-02, -1.2625e-01]],\n",
       " \n",
       "          [[-7.0586e-02, -3.2327e-02, -6.5452e-02],\n",
       "           [ 7.3590e-02, -6.6263e-03,  2.5401e-03],\n",
       "           [ 8.2093e-02,  7.4595e-03,  1.0516e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 9.7235e-02, -3.5810e-02,  1.0159e-01],\n",
       "           [-2.1013e-02, -6.4958e-02, -5.2283e-02],\n",
       "           [ 2.8656e-02, -1.1786e-01,  1.1373e-01]],\n",
       " \n",
       "          [[-7.2538e-02, -6.8093e-02,  1.0754e-01],\n",
       "           [-4.9739e-02,  1.0711e-01,  1.6838e-02],\n",
       "           [-9.4187e-02,  6.0704e-02, -2.6398e-02]],\n",
       " \n",
       "          [[ 1.0893e-01, -2.4366e-02, -1.1429e-01],\n",
       "           [ 7.6843e-02, -2.8448e-02, -1.1462e-01],\n",
       "           [-8.0136e-03,  2.4406e-02, -5.0574e-02]],\n",
       " \n",
       "          [[ 1.2997e-01, -8.8817e-02, -1.2123e-01],\n",
       "           [ 2.2068e-02, -7.0485e-02, -8.2768e-02],\n",
       "           [ 1.1658e-01,  6.4940e-02,  8.4461e-02]],\n",
       " \n",
       "          [[ 7.8588e-02, -8.3426e-02,  1.3328e-01],\n",
       "           [ 6.4958e-02,  2.9859e-02, -4.6384e-02],\n",
       "           [-1.1415e-02, -8.2749e-02,  3.5654e-02]],\n",
       " \n",
       "          [[ 8.4803e-02, -1.0131e-01, -6.5937e-02],\n",
       "           [ 4.1671e-02, -1.2863e-01, -3.4415e-02],\n",
       "           [ 1.3212e-01, -7.5758e-02,  8.4648e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.1131e-01,  4.6475e-02, -2.1738e-02],\n",
       "           [ 4.6435e-02,  6.8189e-03, -6.9435e-02],\n",
       "           [-8.7066e-02, -1.3097e-01, -1.3598e-01]],\n",
       " \n",
       "          [[-9.8882e-02, -2.3478e-02, -1.0694e-01],\n",
       "           [-1.3534e-01,  7.0492e-02,  1.0954e-01],\n",
       "           [ 1.1095e-01,  1.0074e-01,  6.4609e-03]],\n",
       " \n",
       "          [[-8.0681e-02,  7.0255e-02, -1.1718e-01],\n",
       "           [-1.1329e-01,  1.1351e-01,  1.2830e-02],\n",
       "           [-4.4354e-02,  4.7222e-02,  3.2928e-02]],\n",
       " \n",
       "          [[ 7.3529e-02, -1.7808e-02,  4.5901e-02],\n",
       "           [ 3.3151e-02, -1.1857e-01, -7.9140e-03],\n",
       "           [ 6.1218e-02,  3.2154e-02, -2.2320e-02]],\n",
       " \n",
       "          [[-9.6191e-02, -2.0720e-02, -7.0684e-02],\n",
       "           [ 9.1742e-02, -1.0270e-01,  6.6208e-02],\n",
       "           [ 6.8274e-02,  6.7086e-02,  7.8010e-02]],\n",
       " \n",
       "          [[-8.2397e-02, -1.3201e-01, -9.1560e-02],\n",
       "           [-7.6929e-02,  5.8333e-03,  8.3993e-02],\n",
       "           [-1.8500e-02,  1.2551e-01,  1.2407e-02]]],\n",
       " \n",
       " \n",
       "         [[[-7.6399e-02,  2.9177e-02,  3.0598e-02],\n",
       "           [-6.0404e-02,  7.7427e-02,  8.4198e-03],\n",
       "           [-1.1329e-01, -1.1051e-02, -3.2964e-02]],\n",
       " \n",
       "          [[ 1.1835e-01,  7.9650e-02, -1.3317e-01],\n",
       "           [ 3.4938e-03,  1.2881e-01,  9.0918e-02],\n",
       "           [-6.1714e-02, -9.1292e-02, -8.7525e-02]],\n",
       " \n",
       "          [[-2.1953e-03,  2.1589e-02,  7.5277e-02],\n",
       "           [-1.1467e-01, -1.1076e-01,  9.2585e-03],\n",
       "           [-7.8942e-02,  7.4926e-02,  8.9980e-02]],\n",
       " \n",
       "          [[-1.4577e-02, -1.2941e-01, -1.3362e-01],\n",
       "           [-9.8392e-02,  9.2981e-02, -3.0608e-02],\n",
       "           [ 8.4951e-02,  5.6254e-02,  2.8894e-02]],\n",
       " \n",
       "          [[-1.2375e-01,  2.6504e-02, -6.4677e-02],\n",
       "           [-1.0755e-01,  5.3256e-02, -2.4231e-02],\n",
       "           [ 2.4829e-02,  8.7724e-02, -1.9183e-02]],\n",
       " \n",
       "          [[ 1.3206e-01,  7.9942e-02,  8.1519e-02],\n",
       "           [ 1.0054e-01,  7.4570e-02,  6.3062e-02],\n",
       "           [-5.7720e-02,  5.3729e-02, -1.0196e-01]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0629,  0.0833, -0.1094, -0.1266,  0.1209, -0.0210, -0.0764,  0.0994,\n",
       "          0.0624, -0.0343,  0.0199,  0.0023,  0.0815,  0.0068, -0.0844,  0.1048],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-3.4460e-02, -3.1237e-02,  3.2563e-02,  ..., -3.0982e-02,\n",
       "           7.0512e-03,  9.0388e-03],\n",
       "         [-4.3852e-03,  2.8116e-02,  2.0799e-02,  ..., -3.9396e-02,\n",
       "          -7.9644e-03,  3.3868e-02],\n",
       "         [-3.6996e-02, -1.2014e-05,  1.4957e-02,  ..., -3.7597e-02,\n",
       "           1.1264e-02,  6.2808e-03],\n",
       "         ...,\n",
       "         [ 3.0903e-02, -2.1472e-02, -5.0272e-03,  ...,  4.6019e-03,\n",
       "           2.9418e-02, -1.9054e-02],\n",
       "         [-4.8765e-03, -6.3021e-04,  2.9659e-02,  ..., -4.2267e-03,\n",
       "           3.5933e-02, -3.6643e-02],\n",
       "         [-1.2638e-03, -3.6584e-02, -1.1511e-02,  ..., -3.1438e-02,\n",
       "           8.8240e-03,  7.7171e-03]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0278, -0.0384,  0.0320,  0.0036,  0.0324, -0.0011, -0.0376, -0.0373,\n",
       "         -0.0322, -0.0256,  0.0101,  0.0189, -0.0319, -0.0281,  0.0196,  0.0336,\n",
       "          0.0161,  0.0027,  0.0244,  0.0029, -0.0266,  0.0272, -0.0085,  0.0300,\n",
       "          0.0126, -0.0310, -0.0316,  0.0363, -0.0295, -0.0355, -0.0172,  0.0304,\n",
       "         -0.0049, -0.0108,  0.0219,  0.0284,  0.0316,  0.0130, -0.0304,  0.0088,\n",
       "         -0.0019,  0.0321, -0.0084, -0.0117,  0.0289,  0.0201, -0.0148, -0.0359,\n",
       "          0.0237,  0.0116, -0.0395,  0.0109, -0.0157, -0.0386,  0.0079,  0.0004,\n",
       "          0.0185,  0.0298, -0.0398, -0.0360, -0.0329, -0.0073,  0.0108,  0.0223,\n",
       "          0.0237, -0.0267, -0.0360,  0.0275,  0.0290,  0.0087,  0.0082, -0.0285,\n",
       "         -0.0203, -0.0167,  0.0201,  0.0039,  0.0227,  0.0216, -0.0347, -0.0198,\n",
       "          0.0365, -0.0059, -0.0350,  0.0009, -0.0245, -0.0311,  0.0246, -0.0191,\n",
       "         -0.0309,  0.0242,  0.0201, -0.0396, -0.0185,  0.0314,  0.0025, -0.0272,\n",
       "          0.0342,  0.0016, -0.0078, -0.0295,  0.0091, -0.0393,  0.0357, -0.0369,\n",
       "         -0.0307,  0.0399,  0.0145, -0.0094,  0.0073,  0.0310,  0.0181,  0.0397,\n",
       "          0.0134, -0.0400, -0.0231, -0.0273,  0.0140, -0.0248,  0.0020, -0.0119,\n",
       "         -0.0353,  0.0232, -0.0083, -0.0053,  0.0109,  0.0361, -0.0355,  0.0087],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0538,  0.0446, -0.0454,  ..., -0.0602, -0.0864, -0.0287],\n",
       "         [ 0.0529, -0.0616,  0.0152,  ..., -0.0770,  0.0724, -0.0047],\n",
       "         [ 0.0732,  0.0773,  0.0585,  ...,  0.0774,  0.0466, -0.0204],\n",
       "         ...,\n",
       "         [ 0.0619, -0.0850, -0.0428,  ..., -0.0539, -0.0132, -0.0160],\n",
       "         [ 0.0531,  0.0751,  0.0636,  ...,  0.0342, -0.0324,  0.0199],\n",
       "         [-0.0869, -0.0487, -0.0754,  ...,  0.0459,  0.0436,  0.0855]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0117,  0.0528, -0.0818,  0.0512,  0.0528,  0.0528, -0.0630, -0.0013,\n",
       "         -0.0298, -0.0693,  0.0212,  0.0100,  0.0713,  0.0030, -0.0860,  0.0193,\n",
       "         -0.0140,  0.0350, -0.0835,  0.0686,  0.0642,  0.0429,  0.0297,  0.0148,\n",
       "          0.0309,  0.0240, -0.0125, -0.0149, -0.0555, -0.0595, -0.0325,  0.0358,\n",
       "          0.0831, -0.0844, -0.0163,  0.0026,  0.0708,  0.0728,  0.0489,  0.0187,\n",
       "          0.0071, -0.0250, -0.0850,  0.0716,  0.0874,  0.0812,  0.0861,  0.0279,\n",
       "         -0.0407,  0.0631,  0.0866, -0.0219, -0.0218,  0.0503,  0.0089, -0.0883,\n",
       "         -0.0226, -0.0211,  0.0159,  0.0252, -0.0671, -0.0490,  0.0764,  0.0229,\n",
       "         -0.0556,  0.0860,  0.0616,  0.0283,  0.0624,  0.0241,  0.0766,  0.0869,\n",
       "         -0.0839, -0.0017, -0.0778, -0.0574,  0.0124, -0.0503,  0.0354, -0.0210,\n",
       "         -0.0447, -0.0643,  0.0404, -0.0630], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 2.2471e-02,  5.1913e-02,  2.1445e-02,  3.8549e-02,  6.6405e-02,\n",
       "           5.4470e-02,  3.3684e-03,  1.0888e-01, -2.0764e-02, -1.0115e-01,\n",
       "           2.3744e-02,  8.5670e-02, -3.8348e-02, -4.6471e-02, -8.2935e-02,\n",
       "          -4.9388e-02, -2.4305e-02,  7.5483e-02, -8.0920e-02,  8.0953e-04,\n",
       "          -1.0262e-02,  1.5403e-02, -6.3578e-02, -4.8863e-02, -1.0231e-01,\n",
       "           6.8085e-02, -7.6927e-02,  3.0900e-02,  4.1488e-03,  2.7587e-02,\n",
       "           2.8296e-02, -1.7715e-02,  4.1103e-02, -5.7465e-02, -6.5199e-02,\n",
       "           9.7490e-02,  4.4215e-02,  2.9443e-02, -1.1407e-03,  8.8414e-02,\n",
       "           5.6601e-02,  1.0266e-01,  4.3837e-02,  2.5547e-02, -6.1302e-02,\n",
       "          -7.9849e-02,  2.9247e-02, -7.1102e-03, -3.4043e-02, -5.3798e-02,\n",
       "          -2.2694e-02, -1.8206e-02,  3.0547e-06,  1.0268e-01, -1.5478e-02,\n",
       "          -4.3101e-02, -4.4714e-02, -4.8606e-02, -1.2352e-02, -6.5770e-03,\n",
       "          -9.7107e-02,  6.9239e-02,  9.6643e-02, -7.4844e-02,  9.9958e-02,\n",
       "           6.4974e-03,  5.0112e-02, -2.3131e-02,  3.6227e-02, -1.0308e-02,\n",
       "           9.5811e-02,  9.3209e-02,  7.9550e-02,  3.1073e-02,  4.0399e-02,\n",
       "           4.7882e-03, -1.0815e-01, -1.0711e-01,  1.0521e-01, -7.3132e-02,\n",
       "          -2.1229e-02,  1.9402e-02,  6.6231e-02,  4.7909e-02],\n",
       "         [ 8.5375e-02,  5.2760e-02, -2.7306e-02, -1.7024e-03,  1.8398e-02,\n",
       "           2.1834e-02, -5.7708e-02, -7.4290e-02, -5.2661e-02,  8.1045e-02,\n",
       "          -9.6415e-02,  5.0656e-02,  2.5158e-02, -8.5377e-02, -5.1232e-03,\n",
       "           1.1909e-02,  9.4411e-02,  3.2326e-02, -8.7600e-02,  9.4281e-02,\n",
       "           1.3903e-02, -2.2879e-02, -6.5229e-02,  6.5901e-02, -9.0636e-02,\n",
       "          -1.4861e-02,  5.2488e-02,  9.7005e-02,  4.8277e-02,  4.2573e-02,\n",
       "           3.1578e-02,  6.4337e-02,  4.2650e-02,  1.6391e-02,  4.2735e-02,\n",
       "           9.0867e-02,  4.2335e-02, -5.2954e-02, -1.4391e-02, -1.7345e-02,\n",
       "          -1.0692e-01,  9.7673e-02,  7.3393e-02, -3.1346e-02, -1.3487e-02,\n",
       "          -7.3486e-02, -7.0565e-02, -3.8590e-02, -6.9765e-02,  9.7058e-02,\n",
       "          -6.5031e-03, -8.9672e-02, -6.9440e-02, -6.4875e-04,  7.0040e-02,\n",
       "          -6.9802e-02, -1.0185e-01, -1.5614e-02, -5.1543e-02, -5.6824e-02,\n",
       "           8.5023e-02,  4.0171e-02,  1.0585e-01, -2.3178e-02, -2.3256e-02,\n",
       "          -9.6643e-02,  6.0632e-03, -2.1820e-02, -7.6304e-02, -5.7729e-02,\n",
       "          -3.4441e-02, -7.6699e-02, -5.9325e-02,  3.9778e-02, -3.3389e-02,\n",
       "          -2.2263e-03,  1.8624e-02, -9.8534e-02, -3.3689e-02,  8.4132e-02,\n",
       "          -5.2844e-02, -1.0324e-01,  1.1850e-02, -1.0216e-01],\n",
       "         [ 9.5913e-02, -9.4385e-03, -1.0471e-01, -8.7327e-02, -9.9339e-02,\n",
       "          -2.5430e-02,  8.2544e-02,  7.1679e-02,  4.7262e-02, -8.8388e-02,\n",
       "           1.9147e-02,  8.8955e-02,  8.2329e-02,  3.0970e-02,  2.7289e-02,\n",
       "          -1.4847e-02,  5.8958e-02,  7.7990e-02,  9.8464e-02, -4.5166e-02,\n",
       "          -2.3275e-02, -8.8904e-03,  9.7745e-02, -1.7626e-02,  7.6103e-02,\n",
       "           7.1216e-02,  7.8042e-02,  8.2760e-02,  6.7225e-02, -1.3383e-02,\n",
       "           2.3514e-02,  3.0534e-02,  2.5931e-02, -1.0185e-01,  9.4210e-02,\n",
       "          -1.2600e-02, -7.8335e-02,  6.9334e-02,  9.9303e-03, -7.2512e-02,\n",
       "          -1.0832e-01,  2.1772e-02,  2.5353e-02,  7.7941e-02,  9.0982e-02,\n",
       "          -7.0343e-02,  1.0022e-01,  1.9562e-02,  3.2548e-02, -2.3769e-02,\n",
       "           1.0497e-01,  2.5819e-03,  8.1001e-02,  4.2366e-02,  9.4409e-02,\n",
       "           1.4560e-02, -3.2515e-02, -9.0691e-02, -9.5946e-02,  8.6136e-02,\n",
       "          -1.0527e-01,  3.4020e-03, -1.9192e-02, -5.3631e-02, -7.4770e-02,\n",
       "          -1.0052e-01,  6.9377e-02, -8.5394e-03,  7.6282e-02,  6.5076e-02,\n",
       "          -7.6005e-02,  6.5704e-02, -2.5069e-02, -1.5905e-02, -1.0521e-01,\n",
       "          -8.3958e-02,  3.3666e-02,  1.9177e-02,  1.0525e-01,  2.4816e-02,\n",
       "           6.6416e-02, -8.6203e-03,  7.1068e-02, -7.4564e-02],\n",
       "         [ 6.4200e-02, -1.5210e-03, -2.3213e-02, -8.7832e-02,  3.0533e-02,\n",
       "           9.9848e-02, -2.0492e-02,  9.0690e-02,  4.3599e-02, -9.1908e-02,\n",
       "          -1.1705e-02, -6.0372e-02, -4.7652e-02, -4.1403e-02, -4.8416e-02,\n",
       "          -3.7678e-02, -2.8518e-02,  1.0442e-01, -6.7777e-02,  8.3431e-02,\n",
       "           5.6746e-02, -3.7980e-02, -3.0380e-02,  2.4074e-02,  2.1109e-02,\n",
       "          -5.0548e-02, -9.4986e-02,  4.0530e-02, -1.0011e-01, -4.2586e-02,\n",
       "           7.8721e-02, -1.5337e-02,  7.3632e-02,  9.8233e-02, -1.2413e-02,\n",
       "          -6.8360e-02, -9.4982e-03, -2.5169e-02,  5.1581e-02, -1.3797e-02,\n",
       "           8.4682e-02, -5.5275e-02,  6.1848e-02,  6.2847e-02, -7.0526e-02,\n",
       "           8.7223e-02, -8.2129e-02, -5.9675e-02, -2.6585e-02, -1.1536e-02,\n",
       "           6.5164e-02,  5.6901e-03, -7.3319e-02,  1.5612e-02, -9.5779e-02,\n",
       "           2.5136e-02,  4.3362e-02,  6.0402e-02, -1.1131e-02, -1.7714e-02,\n",
       "          -2.9092e-02,  1.2687e-02,  5.9566e-03,  3.7162e-02, -1.2682e-02,\n",
       "           7.5038e-02, -2.5425e-02, -8.0818e-02, -4.0374e-02,  6.7540e-02,\n",
       "           3.9898e-02, -3.3309e-02,  4.4232e-02, -6.7806e-02,  2.3395e-02,\n",
       "          -1.0869e-01,  9.5670e-02, -2.4117e-02, -8.2839e-02, -8.7247e-02,\n",
       "           1.2804e-02, -2.6953e-02, -5.0961e-02, -4.9031e-02],\n",
       "         [ 8.5564e-02,  7.9346e-02, -1.4050e-04,  2.2765e-02,  1.9030e-02,\n",
       "           4.7810e-02, -3.0615e-02, -9.2810e-02, -3.7900e-02,  2.7877e-02,\n",
       "          -8.2024e-02, -2.0819e-03,  4.4147e-02,  1.1396e-02, -1.6456e-02,\n",
       "           1.7524e-02, -1.0243e-01,  6.5692e-02,  7.8648e-02, -3.7204e-02,\n",
       "           9.3380e-02,  7.3594e-02,  7.9224e-02,  2.5334e-02, -1.0178e-01,\n",
       "          -4.3294e-02,  1.2551e-02,  5.5266e-02, -3.0946e-02,  7.6733e-02,\n",
       "          -6.2562e-02,  8.8645e-02,  1.4065e-02,  1.2202e-02, -1.3598e-02,\n",
       "           5.7762e-02, -5.9006e-02,  7.8954e-02,  3.4596e-02,  1.0667e-01,\n",
       "           3.1955e-02,  9.7381e-02, -2.9386e-02, -6.3983e-02,  1.1778e-02,\n",
       "           4.6166e-02, -5.6063e-02,  8.4528e-03, -1.9790e-02, -2.6810e-02,\n",
       "           2.0825e-02,  6.4371e-02,  4.5211e-02,  4.1211e-02, -3.5133e-03,\n",
       "          -1.0015e-01,  8.2125e-02, -7.7954e-02, -6.2507e-02,  7.1349e-02,\n",
       "           4.9507e-02,  9.9202e-02,  2.8033e-02, -8.6350e-02, -6.4850e-02,\n",
       "           6.3768e-02,  2.9349e-02,  1.9289e-02, -2.7875e-02, -9.3744e-02,\n",
       "           7.2152e-02, -9.6252e-02,  5.7357e-02, -1.6192e-02, -1.7359e-02,\n",
       "          -1.0121e-01,  5.9265e-02,  6.3001e-04,  8.8132e-02,  2.9540e-02,\n",
       "           4.2117e-03, -1.9464e-02, -8.8252e-02, -2.6295e-02],\n",
       "         [ 1.8391e-02, -8.8715e-02,  1.0830e-01, -1.6493e-02,  8.1463e-02,\n",
       "          -8.5146e-02,  5.3596e-02,  1.0751e-01, -3.2042e-02, -1.1753e-02,\n",
       "          -1.4572e-03,  7.6193e-02,  4.6544e-02,  6.1691e-02, -9.5896e-02,\n",
       "           9.0509e-03, -4.7000e-02,  3.3188e-02, -6.3493e-02,  7.5243e-02,\n",
       "          -8.8240e-02, -7.7111e-02,  9.9434e-02,  3.1790e-02,  4.4317e-02,\n",
       "           9.1715e-02, -3.4997e-03, -3.1550e-02, -1.9661e-02, -1.0065e-01,\n",
       "           2.4107e-02,  1.9480e-02, -1.2023e-02,  1.0590e-01, -1.3442e-02,\n",
       "          -4.4965e-02, -9.2721e-02, -1.9616e-02,  1.0523e-01, -8.0834e-02,\n",
       "           1.0189e-01, -9.2507e-02, -5.0330e-02,  1.0666e-01, -1.2121e-02,\n",
       "           4.8981e-02, -1.8661e-02,  1.5877e-02,  9.2737e-03, -9.1709e-02,\n",
       "           9.1289e-02, -4.8634e-02, -1.0116e-01, -5.6269e-02,  6.7687e-03,\n",
       "           8.2345e-03, -8.9448e-02,  1.1936e-02, -6.2071e-02, -1.1753e-03,\n",
       "           6.5258e-02,  4.3018e-02,  8.8777e-02,  9.0500e-02, -8.0602e-02,\n",
       "          -6.1172e-02,  2.7465e-02, -7.2513e-02,  5.2423e-02, -6.9472e-02,\n",
       "          -2.0346e-02,  1.1280e-02, -1.0038e-01,  3.3842e-02, -2.2306e-02,\n",
       "          -4.4038e-02, -1.6887e-03, -1.8865e-02, -9.4898e-02, -6.2127e-02,\n",
       "           4.3937e-02, -1.9065e-02,  8.4172e-02,  2.2195e-02],\n",
       "         [-5.2950e-02, -7.8314e-02,  3.4961e-02,  5.1324e-02, -3.5925e-02,\n",
       "           9.5326e-02,  9.3310e-02, -5.2764e-03,  2.0867e-03,  1.9864e-02,\n",
       "           4.6179e-02,  5.6199e-02,  3.5045e-02, -9.4480e-02,  3.3300e-02,\n",
       "          -4.1561e-02, -3.6381e-02,  6.5066e-02,  3.4312e-02, -5.1597e-02,\n",
       "          -1.7743e-02,  4.3955e-03,  7.9888e-02,  7.2104e-02,  8.4464e-02,\n",
       "           2.0932e-02,  5.2501e-02, -1.2182e-02, -3.8258e-02,  8.9967e-02,\n",
       "          -8.8679e-02, -9.4639e-02,  4.4629e-02, -6.6730e-02, -2.1572e-02,\n",
       "          -1.6268e-02, -4.3135e-02,  7.7435e-02, -2.5762e-02, -9.0533e-03,\n",
       "          -7.6210e-02,  5.8971e-02,  5.1196e-02,  4.8812e-02, -1.0201e-01,\n",
       "          -2.5298e-02,  5.9076e-02, -4.8079e-04, -6.6993e-02, -1.6946e-02,\n",
       "          -6.6879e-02,  4.2864e-02, -6.9516e-02,  7.9694e-02, -7.3207e-03,\n",
       "           4.4930e-02,  9.0680e-03,  7.7129e-02, -9.3400e-02,  7.5584e-02,\n",
       "           4.0523e-02,  6.1011e-02, -4.3119e-02,  2.0370e-02,  4.1596e-02,\n",
       "          -5.7682e-02, -8.0439e-02, -1.8839e-03, -5.1417e-02, -3.8789e-02,\n",
       "           5.2363e-02, -8.0564e-02, -8.7909e-02,  1.5393e-02, -5.2487e-02,\n",
       "           9.8718e-02,  2.1108e-02,  6.8429e-02,  3.5981e-02, -1.0793e-01,\n",
       "          -4.3157e-02, -9.7418e-02, -9.3391e-02, -4.1320e-02],\n",
       "         [-4.8369e-02,  1.0536e-01, -8.6245e-02, -3.8817e-02,  9.5102e-02,\n",
       "           3.4587e-02, -6.2847e-02,  1.0237e-01, -9.7050e-02, -9.2000e-02,\n",
       "          -1.7028e-02, -4.3520e-02,  4.5756e-02,  6.3733e-02, -9.8057e-02,\n",
       "           6.6173e-02, -3.0368e-02,  2.9811e-02, -2.0812e-02,  9.4994e-03,\n",
       "          -2.7319e-03, -6.4039e-02, -2.3647e-02, -1.0738e-01,  1.4213e-02,\n",
       "          -2.7082e-02,  2.0421e-03,  3.2480e-02,  2.2629e-03,  6.7076e-02,\n",
       "           7.3873e-02, -1.8039e-02, -6.8881e-02,  2.7730e-02, -5.8673e-02,\n",
       "           7.9415e-02, -1.7914e-02, -1.0455e-01,  6.0234e-02, -2.2588e-02,\n",
       "           8.0195e-02, -6.6958e-02, -1.8439e-02, -3.2383e-02,  9.0794e-02,\n",
       "           1.0521e-01, -5.5895e-02,  7.8505e-02, -6.3715e-02, -9.6810e-02,\n",
       "           4.1508e-02,  7.3770e-02, -1.1686e-02, -2.3164e-02,  5.0300e-03,\n",
       "           3.2547e-02,  1.0188e-02,  9.0333e-02, -8.8786e-03, -9.7072e-02,\n",
       "          -1.0096e-01, -5.5323e-02,  5.5019e-02, -9.3221e-02,  5.6459e-02,\n",
       "          -6.9756e-02, -4.8363e-02, -2.2039e-02, -4.3112e-02, -9.0672e-02,\n",
       "          -4.2034e-02, -5.2281e-02,  5.1083e-02,  9.5876e-02,  2.1687e-03,\n",
       "           6.8286e-02,  8.9094e-02,  2.8003e-02, -3.8652e-03,  9.9632e-02,\n",
       "          -2.5917e-02, -5.4809e-03, -5.2130e-02, -6.6744e-02],\n",
       "         [-5.6614e-02, -7.4746e-02, -1.9168e-02, -2.0895e-02,  2.7569e-02,\n",
       "          -9.3548e-02, -8.5227e-02,  3.4705e-03,  5.9150e-02,  8.7670e-02,\n",
       "          -6.6330e-02,  3.6895e-02,  4.1939e-02,  2.5958e-02, -1.9840e-02,\n",
       "          -9.1629e-02, -6.9388e-02, -7.0818e-02,  8.7928e-02, -6.2827e-02,\n",
       "           5.1205e-02,  5.7799e-02, -4.4447e-02, -9.0482e-02, -5.3692e-02,\n",
       "          -8.9813e-02,  3.7867e-02, -4.9197e-02,  9.8756e-02,  3.8474e-02,\n",
       "           3.1408e-03, -4.0083e-02, -3.5042e-02, -9.1161e-02,  7.7862e-02,\n",
       "           8.4348e-02, -2.6935e-02, -5.3951e-03, -8.9932e-02, -2.6386e-02,\n",
       "           4.0589e-02,  8.0740e-02,  9.8063e-02,  8.9354e-02, -3.8232e-02,\n",
       "           2.1150e-02, -6.1736e-02, -6.7244e-02,  2.4530e-02, -6.8627e-02,\n",
       "          -2.9529e-02, -4.1388e-03, -9.6257e-02, -1.0752e-01,  1.0898e-02,\n",
       "           4.7047e-02,  1.0894e-01,  5.4280e-02,  7.2350e-02,  9.0557e-02,\n",
       "           1.0478e-01, -4.2303e-02,  2.1031e-03,  6.0066e-02,  1.9577e-02,\n",
       "           2.6306e-02,  4.9684e-03, -6.7448e-02, -1.0171e-01, -1.0546e-03,\n",
       "           2.1576e-02, -1.2149e-02,  8.8664e-02,  7.6305e-03,  1.8351e-02,\n",
       "          -1.9650e-02,  3.5120e-02,  3.7435e-02,  7.4893e-02,  7.2678e-02,\n",
       "          -8.4293e-02,  5.9953e-02,  8.7291e-02,  5.2177e-02],\n",
       "         [-6.7438e-02,  1.0572e-01,  9.8764e-03,  2.9686e-02,  8.5882e-02,\n",
       "          -2.8908e-02,  9.2932e-02,  6.3082e-02,  5.8963e-02, -6.5558e-02,\n",
       "          -8.5089e-02,  2.0406e-03, -1.4812e-02, -6.0931e-02,  6.5314e-02,\n",
       "           1.0688e-02, -8.4089e-02,  6.9356e-02,  1.0655e-01,  7.9482e-02,\n",
       "           2.6835e-02, -9.1708e-02,  9.3114e-02,  6.6377e-02, -5.9897e-02,\n",
       "           8.5362e-02, -5.7642e-02, -2.7873e-02,  1.0137e-01,  4.9767e-02,\n",
       "          -6.2788e-02,  2.8014e-02, -5.1206e-02, -3.7316e-02,  7.9190e-03,\n",
       "           6.4699e-02, -9.7783e-02, -7.6092e-02, -5.0980e-02,  1.0330e-02,\n",
       "           1.6876e-02,  8.8380e-02, -2.0583e-02, -8.6538e-02,  2.0815e-02,\n",
       "           3.7040e-02, -6.0141e-02,  3.0331e-02,  3.7953e-02, -1.6102e-02,\n",
       "           9.2513e-03,  8.3211e-02, -2.2993e-02,  8.0281e-02,  1.0394e-01,\n",
       "          -4.6456e-02, -2.9503e-02,  9.2203e-02,  1.6465e-02, -8.0580e-02,\n",
       "           2.4731e-02, -3.6463e-02,  6.7385e-02,  2.6044e-02,  3.9683e-02,\n",
       "           6.2882e-02,  5.0262e-05, -4.3689e-02,  8.4745e-02,  3.5989e-02,\n",
       "          -1.0103e-01, -8.2279e-02,  9.3759e-02,  6.1091e-02, -1.3357e-02,\n",
       "          -2.7223e-02, -1.0313e-01, -4.1304e-02,  3.6326e-03,  1.0650e-02,\n",
       "           4.5726e-02,  4.8171e-02, -3.0646e-03, -8.2409e-02]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0151,  0.0046,  0.0671,  0.0669,  0.0528,  0.0052, -0.0330,  0.0811,\n",
       "         -0.0213,  0.0367], requires_grad=True)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0743, -0.0684, -0.0404,  0.1276,  0.0089, -0.1240,  0.0720, -0.0330,\n",
      "         -0.1403,  0.0009]], grad_fn=<AddmmBackward>)\n",
      "tensor(0.7660, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Pass tensor throught the network\n",
    "input = torch.randn(1,1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)\n",
    "\n",
    "# Zero gradient buffer of all parameters and backprops with random gradient \n",
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))\n",
    "\n",
    "# Calculating loss\n",
    "output = net(input)\n",
    "target = torch.randn(10)\n",
    "target = target.view(1, -1)\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(output, target)\n",
    "print(loss)\n",
    "\n",
    "# Backprop\n",
    "#loss.backward()\n",
    "print(loss.grad_fn)\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU\n",
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "loss.backward()\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.305\n",
      "[1,  4000] loss: 2.304\n",
      "[1,  6000] loss: 2.304\n",
      "[1,  8000] loss: 2.304\n",
      "[1, 10000] loss: 2.305\n",
      "[1, 12000] loss: 2.304\n",
      "[2,  2000] loss: 2.304\n",
      "[2,  4000] loss: 2.305\n",
      "[2,  6000] loss: 2.304\n",
      "[2,  8000] loss: 2.304\n",
      "[2, 10000] loss: 2.305\n",
      "[2, 12000] loss: 2.304\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 1]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4]\n",
    "random.shuffle(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python36",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
